
\documentclass[12pt]{book}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{mathrsfs}

\usepackage{enumitem}
%\usepackage[shortlabels]{enumerate}
\usepackage{tikz-cd}
\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{amscd}
\usepackage{makeidx}
\usepackage{enumitem}
\title{measure}
\author{Aidan Backus}
\date{December 2019}


\newcommand{\NN}{\mathbb{N}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\DD}{\mathbb{D}}

\newcommand{\Torus}{\mathbb{T}}

\newcommand{\AAA}{\mathcal A}
\newcommand{\BB}{\mathcal B}
\newcommand{\HH}{\mathcal H}

\newcommand{\Grp}{\mathbf{Grp}}
\newcommand{\Open}{\mathbf{Open}}
\newcommand{\Vect}{\mathbf{Vect}}
\newcommand{\Set}{\mathbf{Set}}

\newcommand{\Cau}{\mathbf{Cau}}
\newcommand{\ISF}{\mathbf{ISF}}
\newcommand{\Simp}{\mathbf{Simp}}
\newcommand{\Sch}{\mathscr S}

\DeclareMathOperator{\atanh}{atanh}
\DeclareMathOperator{\sech}{sech}
\DeclareMathOperator{\sinc}{sinc}
\DeclareMathOperator{\dom}{dom}

\DeclareMathOperator{\card}{card}
\DeclareMathOperator{\coker}{coker}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\Gal}{Gal}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\rank}{rank}

\newcommand{\dbar}{\overline\partial}

\def\Xint#1{\mathchoice
{\XXint\displaystyle\textstyle{#1}}%
{\XXint\textstyle\scriptstyle{#1}}%
{\XXint\scriptstyle\scriptscriptstyle{#1}}%
{\XXint\scriptscriptstyle\scriptscriptstyle{#1}}%
\!\int}
\def\XXint#1#2#3{{\setbox0=\hbox{$#1{#2#3}{\int}$ }
\vcenter{\hbox{$#2#3$ }}\kern-.6\wd0}}
\def\ddashint{\Xint=}
\def\dashint{\Xint-}

\renewcommand{\Re}{\operatorname{Re}}
\renewcommand{\Im}{\operatorname{Im}}
\newcommand{\dfn}[1]{\emph{#1}\index{#1}}

\usepackage[backend=bibtex,style=alphabetic,maxcitenames=50,maxnames=50]{biblatex}
\addbibresource{clopen_analysis.bib}
\renewbibmacro{in:}{}
\DeclareFieldFormat{pages}{#1}

\usepackage{color}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true, % make the links colored
    linkcolor=blue, % color TOC links in blue
    urlcolor=red, % color URLs in red
    linktoc=all % 'all' will create links for everything in the TOC
    %Ning added hyperlinks to the table of contents 6/17/19
}

\theoremstyle{definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{sublemma}[theorem]{Sublemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{axiomx}[theorem]{Axiom}
%\newtheorem{theoremxx}[theorem]{Theorem}
\newtheorem{conjecture}[theorem]{Conjecture}
%\newtheorem{definitionx}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}

\newtheorem{subsec}[theorem]{}

%\newtheorem{examplex}[theorem]{Example}
%\newtheorem{exercisex}{Exercise}[chapter]
\newtheorem{problem}[theorem]{Problem}

\newtheorem{axiom}[theorem]{Axiom}
\newtheorem{theoremx}[theorem]{Theorem}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}[theorem]{Exercise}

%\newenvironment{axiom}
%  {\pushQED{\qed}\renewcommand{\qedsymbol}{$\diamondsuit$}\axiomx}
%  {\popQED\endexamplex}
%
%\newenvironment{definition}
%  {\pushQED{\qed}\renewcommand{\qedsymbol}{$\diamondsuit$}\definitionx}
%  {\popQED\endexamplex}
%
%\newenvironment{example}
%  {\pushQED{\qed}\renewcommand{\qedsymbol}{$\diamondsuit$}\examplex}
%  {\popQED\endexamplex}
%
%  \newenvironment{exercise}
%    {\pushQED{\qed}\renewcommand{\qedsymbol}{$\diamondsuit$}\exercisex}
%    {\popQED\endexamplex}
%
%  \newenvironment{theoremx}
%        {\pushQED{\qed}\renewcommand{\qedsymbol}{$\diamondsuit$}\theoremxx}
%        {\popQED\endexamplex}

\makeindex

\begin{document}

\maketitle

\tableofcontents

\chapter{Constructing the Lebesgue measure}
\label{measureChapter}
A measure is a rule by which we assign ``size" to certain sets.
The notion of a measure generalizes a handful of familiar notions, which we now review.
\begin{example}
\label{examples of measures}
If $X$ is a set, we will define a measure known as the \dfn{counting measure} $\mu$ of $X$, by declaring that for every finite subset $Y \subseteq X$, $\mu(Y)$ is the cardinality of $Y$ (i.e. the number of elements of $Y$).

We define the \dfn{Lebesgue measure}\footnote{Named after Henri Lebesgue (1875-1941), a French mathematician who introduced measure theory in his book \emph{Int√©grale, longueur, aire} (\emph{Integral, length, area}).}
$\mu$ on boxes $[a_1, b_1] \times \cdots \times [a_d, b_d] \subseteq \RR^d$ by declaring that
$$\mu([a_1, b_1] \times \cdots \times [a_d, b_d]) = (b_1 - a_1)(b_2 - a_2)\cdots(b_d - a_d).$$
When $d = 1$ this is just the familiar notion of the length of a line segment; when $d = 2$ this is the area of a rectangle; when $d = 3$ this is the volume of a rectangular prism.

In probability theory, one is concerned with sets of ``outcomes"; the sets are known as ``events". Given an event $E$ in a sample space $X$, we define $\mu(E)$ to be the probability that $\mu$ occurs. Thus $\mu(X) = 1$.
\end{example}

\begin{subsec}
In all of the above examples, $\mu$ has the property that if $Y_1, \dots, Y_n$ is a collection of disjoint sets (thus $Y_i \cap Y_j = \emptyset$ whenever $i \neq j$), then
$$\mu\bigcup_i Y_i = \sum_i \mu(Y_i).$$
In fact this can be made to be true not just for finite, but countable, collections of disjoint sets.
So it will be natural to require that the domain of our measure $\mu$ be closed under taking countable unions.
\end{subsec}

\section{Algebras of sets}
Encouraged by the introduction, we study sets $R$, whose elements are sets, such that $R$ is closed under operations similar to countable union.
This will seem obnoxious and abstract at first, but I ask for your patience; it won't take long to get through this section.

\begin{definition}
By a \dfn{ring} $R$ we mean a nonempty set, whose elements are sets, such that if $X, Y \in R$ then the union $X \cup Y$ and set difference $X \setminus Y$ are both in $R$.
\end{definition}

\begin{subsec}
Let $R$ be a ring.
One easily checks that if $X_1, \dots, X_n \in R$ then $X_1 \cup \cdots \cup X_n \in R$ and $X_1 \cap \cdots \cap X_n \in R$ (this follows by induction, because $X \cap Y = X \setminus (X \setminus Y)$).
Moreover, since $R$ is nonempty, say $X \in R$, $X \setminus X \in R$, so $R$ contains the empty set.
\end{subsec}

\begin{definition}
Let $X$ be a set. By an \dfn{algebra} in $X$ we mean a ring such that $X \in R$ and for every $Y \in R$, $Y \subseteq X$.
\end{definition}

\begin{definition}
By a \dfn{$\sigma$-ring}\footnote{Here $\sigma$ should be thought of as meaning ``countable".} $R$ we mean a ring which is closed under countable unions, thus for every sequence $(X_n)_n$ of sets in $R$, $\bigcup_n X_n \in R$.

We define a \dfn{$\sigma$-algebra} in a set $X$ to be a $\sigma$-ring which is an algebra in $X$.
\end{definition}

\begin{subsec}
Let $R$ be a $\sigma$-ring.
In proofs it will frequently be useful to replace sequences of sets in $R$ with sequences of disjoint sets, without leaving $R$.
The below lemma allows us to accomplish this.
\end{subsec}

\begin{lemma}
Let $\Sigma$ be a $\sigma$-ring.
Let $(E_n)_n$ be a sequence of sets in $\Sigma$. Then there is a sequence of disjoint sets $(F_n)_n$ in $\Sigma$ such that $F_n \subseteq E_n$ and
$$\bigcup_{n=1}^\infty E_n = \bigcup_{n=1}^\infty F_n.$$
\end{lemma}
\begin{proof}
Let $F_1 = E_1$ and for $n \geq 2$,
$$F_n = E_n \setminus \bigcup_{i=1}^{n-1} F_i.$$
Then clearly the $F_n$ are disjoint and have the same union as the $E_n$.
\end{proof}

\begin{exercise}
Let $X$ be a set.
Show that the power set $2^X$ -- that is, the set of all subsets of $X$ -- is a $\sigma$-algebra, as is $\{\emptyset, X\}$.
\end{exercise}

\begin{exercise}
Let $R$ be the set of bounded subsets of $\RR$.
Show that $R$ is a ring, but neither an algebra in $\RR$ nor a $\sigma$-ring.
\end{exercise}

\begin{exercise}
Recall the algebraic definition of a ring: a set equipped with an addition and a multiplication satisfying certain axioms.
Show that every ring (in our sense) is an algebraic ring, where addition and multiplication are replaced by symmetric difference and intersection, respectively.
\end{exercise}

\begin{exercise}
Let $\Sigma$ be an infinite $\sigma$-ring. Show that $\Sigma$ has cardinality at least that of $2^\NN$, the power set of the natural numbers.
(Hint: let $\Sigma_0 = \Sigma$. Choose $X_n \in \Sigma_n$ appropriately and let $\Sigma_{n+1} = \{Y \in \Sigma_n: X \cap Y = \emptyset\}$. If done correctly, you should be able to find an injective function $F: 2^\NN \to \Sigma$ such that $F(\{n\}) = X_n$).
\end{exercise}

\section{The Borel $\sigma$-algebra}
We now consider certain $\sigma$-algebras that are built up by a process similar to the notion of ``generators and relations" from algebra.

\begin{lemma}
\label{intersection of rings is ring}
The intersection of a nonempty set of rings (resp. $\sigma$-rings, algebras, or $\sigma$-algebras) is a ring (resp. $\sigma$-ring, etc.)
\end{lemma}
\begin{proof}
We prove this for a set of rings (the other cases are similar). Let $\mathcal R$ be a set of rings and let $R$ be its intersection.
If $X, Y \in R$ then for every $S \in \mathcal R$, $X, Y \in S$ so $X \cup Y \in S$ and $X \setminus Y \in S$.
Therefore $X \cup Y, X \setminus Y \in R$.
\end{proof}

\begin{subsec}
Whenever we refer to a ``smallest" set $X$ with a property $P$, we mean that for every set $Y$ with property $P$, $X \subseteq Y$.
\end{subsec}

\begin{lemma}
If $\mathcal C$ is a set of sets, there is a smallest ($\sigma$)-ring containing $\mathcal C$. If in fact $\mathcal C$ is a collection of subsets of a set $X$, there is a smallest ($\sigma$)-algebra containing $\mathcal C$.
\end{lemma}
\begin{proof}
In the case of a ($\sigma$)-ring, let $X$ be the union of all elements of $\mathcal C$.
We now prove this claim for the case of a ring; the other cases are similar.

The power set $2^X = \{Y: Y \subseteq X\}$ is clearly a ring which contains every element of $\mathcal C$.
Let $\mathcal R$ be the set of all rings that contain every element of $\mathcal C$; since $2^X \in \mathcal R$, $\mathcal R$ is nonempty.
By Lemma \ref{intersection of rings is ring}, the intersection $R$ of $\mathcal R$ is a ring.
But for every $C \in \mathcal C$, $C \in R$ since $C$ is in every element of $\mathcal R$.
Therefore $R$ contains $\mathcal C$.
\end{proof}

\begin{definition}
The smallest $\sigma$-algebra containing every element of a set $\mathcal C$ is called the \dfn{$\sigma$-algebra generated by} $\mathcal C$.
We denote it by $\sigma(\mathcal C)$.
\end{definition}

\begin{subsec}
The advantage of defining a $\sigma$-algebra by referring to its generators is that it is easy to show that every element of the $\sigma$-algebra has a given property.
This is quite easy to prove, as the following lemma shows, but so very useful.
\end{subsec}

\begin{lemma}
\label{generators and relations}
Let $X$ be a set, and let $P$ be a property that subsets of $X$ can have.
Assume that $\mathcal C$ is a set whose elements are subsets of $X$, and every element of $\mathcal C$ has property $P$.
If the set of all subsets of $X$ with property $P$ is a $\sigma$-algebra, then every element of $\sigma(\mathcal C)$ has property $P$.
\end{lemma}
\begin{proof}
Let $\Sigma$ be the $\sigma$-algebra of all subsets of $X$ with property $P$.
Then $\Sigma$ contains $\sigma(\mathcal C)$.
\end{proof}

\begin{subsec}
We now come across the most important example of a $\sigma$-algebra.
If the reader is unfamiliar with topological spaces, in the below definition it suffices to take $X = \RR^d$, and $\mathcal T$ the set of all unions of open balls in $\RR^d$, as this will be the most important case.
\end{subsec}

\begin{definition}
Let $X$ be a topological space.
Let $\mathcal T$ be the topology of $X$, the set of all open subsets of $X$.
We define the \dfn{Borel $\sigma$-algebra}\footnote{Named after √âmile Borel (1871-1956), a French probabilist who introduced many of the key ideas of measure theory.}
$\mathcal B$ of $X$ by $\mathcal B = \sigma(\mathcal T)$.
A \dfn{Borel set} in $X$ is an element of $\mathcal B$.
\end{definition}

\begin{subsec}
Let $X$ be a topological space.
It follows from the definition that every open or closed subset of $X$ is Borel, but also that countable unions of complements of countable unions of complements of countable unions of complements of ... of open sets of $X$ is Borel.
However, some Borel sets can be even more complicated than that.
\end{subsec}

\begin{lemma}
Let $X$ be a topological space.
Assume that $P$ is a property that subsets of $X$ can have, and that every open set has property $P$.
If the set of subsets of $X$ with property $P$ is a $\sigma$-algebra, then every Borel set has property $P$.
\end{lemma}
\begin{proof}
By Lemma \ref{generators and relations}.
\end{proof}

\begin{subsec}
When is a set Borel? If $X = \NN$, then every set is open and so every set is Borel.
But it is not so obvious how to check whether a subset of $\RR^d$ is Borel.
Certainly any set you will ever ``naturally" encounter is Borel, but not every subset of $\RR^d$ is Borel.
\end{subsec}

\begin{lemma}
\label{Borel sigma algebra}
There exists a subset of $\RR^d$ which is not Borel.
In fact, the set of Borel subsets of $\RR^d$ has strictly lower cardinality than the set of all subsets of $\RR^d$.
\end{lemma}
\begin{proof}[Proof (omit on first reading)]
Let $\Sigma_1 = \mathcal T$ be the topology of $\RR^d$.
Given $\Sigma_\alpha$, $\alpha$ a countable ordinal (see Definition \ref{ordinal dfn}), let $\Pi_\alpha$ be the set of all complements of elements of $\Sigma_\alpha$.
Let $\Sigma_{\alpha+1}$ be the set of countable unions of elements of $\Pi_\alpha$.
If $\beta < \omega_1$ is not equal to $\alpha+1$ for any $\alpha$, let $\Sigma_\beta = \bigcup_{\alpha < \beta} \Sigma_\alpha$.
Therefore $\Sigma_\alpha$ and $\Pi_\alpha$ are defined for all $\alpha < \omega_1$ by transfinite recursion (see the remarks after Theorem \ref{transfinite induction}).
We note that $\Sigma_0$ has cardinality $\beth_1$ by Theorem \ref{cardinality of topology}.

Now the mapping $A \mapsto A^c$ is a bijection $\Sigma_\alpha \to \Pi_\alpha$.
Moreover if $\Pi_\alpha$ has cardinality $\beth_1$ (see Definition \ref{beth dfn}) then so does $\Sigma_{\alpha+1}$, since each element of $\Sigma_{\alpha+1}$ can be expressed in terms of a countable number of elements of $\Pi_\alpha$, and $\beth_1 \times \beth_1 \times \cdots$ has cardinality $\beth_1$ by Theorem \ref{cardinal arithmetic trivial}.
Finally if $\beta$ is a countable limit ordinal and for every $\alpha < \beta$, $\Sigma_\alpha$ is countable, then $\Sigma_\beta$ is a countable union of sets of cardinality $\beth_1$, hence has cardinality $\beth_1$ by Theorem \ref{cardinal arithmetic trivial}.
It follows by induction that for every countable ordinal $\alpha$, $\Sigma_\alpha$ has cardinality $\beth_1$.

Now every Borel set is in $\Sigma_\alpha$ for some $\alpha$, since it was obtained by applying countable union and complement countably many times to an open set, and thus is in $\Sigma_{\omega_1} = \bigcup_{\alpha < \omega_1} \Sigma_\alpha$.
But $\Sigma_{\omega_1}$ is a union of $\aleph_1$ many sets of cardinality $\beth_1$, so has cardinality $\beth_1$ by Theorem \ref{cardinal arithmetic trivial},
since $\aleph_1 \leq \beth_1$ (which follows by Zermelo's well-ordering theorem \ref{well-ordering theorem}).
Therefore $\Sigma_{\omega_1}$ is the set of all Borel sets, and has cardinality $\beth_1$.

But $\Sigma_{\omega_1}$ is a subset of the power set $2^\RR$, which has cardinality $\beth_2$. Thus there is an element of $2^\RR$ which is not Borel.
\end{proof}

\begin{exercise}
Show that the set of half-open intervals $[a, b)$ generates the Borel $\sigma$-algebra of $\RR$.
\end{exercise}

\begin{exercise}
Show that the set of compact subsets of $\RR^d$ generates the Borel $\sigma$-algebra of $\RR^d$.
Show that there exists a metric space $X$, such that the set of compact subsets of $X$ does not generate the Borel $\sigma$-algebra of $X$. (Hint: Cardinality!)
\end{exercise}

\begin{exercise}
\label{Jordan content 1}
Let us say that a bounded subset $A$ of $\RR$ has \dfn{Jordan content} if the indicator function $1_A$ of $A$ is Riemann integrable.
Here $1_A(x) = 1$ if $x \in A$ and $1_A(x) = 0$ otherwise.
Show that $\QQ$ is Borel, but does not have Jordan content.
Later we will show that every set with Jordan content is Borel, and that it is reasonable to define the length of any Borel set.
So our definitions will generalize those that one learned in a first course in real analysis.
\end{exercise}


\section{The definition of a measure}
We are almost ready to define a measure.
Throughout this section, the reader should refer back to Example \ref{examples of measures} frequently, as the point of the definitions in this section is to generalize those concepts.

\begin{subsec}
Let $(-\infty, \infty]$ denote the set of real numbers, plus another point $\infty$ which is greater than any real number.
We define addition on $[0, \infty]$ by requiring that $\infty + a = \infty$ for any $a \in \RR$.
We do not define addition on $[-\infty, \infty]$, which would include $-\infty$, because the expression $\infty - \infty$ makes no sense.
\end{subsec}

%\begin{definition}
%Let $B$ be a Banach space or $(-\infty, \infty]$, and let $\mathcal C$ be a collection of sets
%We say that a function $\mu: \mathcal C \to B$ such that for every disjoint sequence of sets $(X_n)_n$ in $\Sigma$ such that $\bigcup_n X_n %\in \mathcal C$,
%$$\mu\bigcup_n X_n = \sum_{n=1}^\infty \mu(X_n),$$
%is called a \dfn{$\sigma$-additive fuction}.
%\end{definition}
%Here the infinite sum is meant in the sense of (\ref{banach space series}) if $B$ is a Banach space.

\begin{definition}
Let $\mathcal C$ be a collection of sets.
A function $\mu: \mathcal C \to [0, \infty]$ such that for every disjoint sequence of sets $(X_n)_n$ in $\Sigma$ such that $\bigcup_n X_n \in \mathcal C$,
$$\mu\bigcup_n X_n = \sum_{n=1}^\infty \mu(X_n),$$
is called a \dfn{$\sigma$-additive fuction}.
\end{definition}

\begin{definition}
A \dfn{measure} is a $\sigma$-additive function defined on a $\sigma$-algebra $\Sigma$ on a set $X$ which is not identically $\infty$.
If we wish to emphasize that the codomain of a measure is $[0, \infty]$, we will call it a \dfn{positive measure}.

We call elements of $\Sigma$ \dfn{measurable sets} and call $(X, \Sigma)$ a \dfn{measurable space}.
If $\mu$ is a measure on $\Sigma$, we call $(X, \Sigma, \mu)$ a \dfn{measured space}.

If the image of $\mu$ is $[0, 1]$, we say that $\mu$ is a \dfn{probability measure}.
\end{definition}

\begin{lemma}
\label{empty set is null}
For any measure $\mu$, $\mu(\emptyset) = 0$.
\end{lemma}
\begin{proof}
Since $\mu$ is a measure, there is a measurable set $Y$ such that $\mu(Y) \neq \infty$.
Then $Y = Y \cup \emptyset$ and $Y \cap \emptyset = \emptyset$, so
$$\mu(Y) = \mu(Y) + \mu(\emptyset).$$
Therefore $\mu(\emptyset) = 0$.
\end{proof}

\begin{example}
The examples in Example \ref{examples of measures} are $\sigma$-additive.
However, they are not all defined on $\sigma$-algebras; for example, the union of two boxes $\prod_i [a_i, b_i]$ is not a box.
Counting measure is defined on the $\sigma$-algebra of every subset of $X$, so counting measure is actually a measure.

In fact, it is not yet clear that there are any interesting measures other than counting measure!
We'll have to do a lot of work before we'll be ready to introduce other examples of measures.
\end{example}

\begin{theorem}
TODO: Continuity of measure
\end{theorem}

\begin{subsec}
We now introduce an important class of $\sigma$-additive functions defined for certain subsets of $\RR$, known as Stieltjes premeasures\footnote{Named after Thomas Stieltjes (1856-1894), who introduced the Riemann-Stieltjes integral, a weighted version of the Riemann integral that inspired the notion of a Stieltjes premeasure.}.
Eventually we will modify their definition so that they are defined for every Borel subset of $\RR$.
Since the Borel sets form a $\sigma$-algebra, this will define a measure on the Borel sets, known as a Stieltjes measure.
\end{subsec}

\begin{subsec}
Recall that a function $f$ on an interval $I$ is said to be ``left-continuous" if for every $x \in I$,
$$f(x) = \lim_{\varepsilon \to 0^+} f(x - \varepsilon).$$
Here the limit is taken over \emph{positive} $\varepsilon$, and so ignores the behavior of $f$ to the right of $x$.
Clearly any continuous function is left-continuous.
One can also define right-continuous functions by ignoring the behavior of $f$ to the left of $x$ instead.
\end{subsec}

\begin{example}
The \dfn{Heaviside step function}\footnote{Named after Oliver Heaviside (1850-1925), an engineer who introduced an early version of the ``distributional calculus" used to solve differential equations. Mathematicians did not consider the distributional calculus rigorous until the 1950s, however.}
$$H(x) = \begin{cases}
0, & x \leq 0\\
1, & x > 0
\end{cases}$$
is a useful example of a left-continuous function which is not continuous.
Clearly the derivative $H'(x)$ exists if $x \neq 0$, and in that case $H'(x) = 0$.
We want to say that $H'(0) = \infty$ in some suitable sense, and in fact that for any $\varepsilon > 0$,
$$\int_{-\infty}^\infty H'(x)~dx = \int_{-\varepsilon}^\varepsilon H'(x)~dx = 1.$$
Of course we can't do that, because the limit that would define $H'(0)$ does not exist.
TODO: Draw a picture.
\end{example}

\begin{definition}
Let $f: \RR \to \RR$ be a nondecreasing, left-continuous function.
Define
$$\mu_f([a, b)) = f(b) - f(a).$$
We call $\mu_f$ the \dfn{Stieltjes premeasure} of $f$.
\end{definition}

\begin{subsec}
A nondecreasing function can only be discontinuous on a countable set (Exercise \ref{nondecreasing exercise}).
Thus we can turn a nondecreasing function $f$ into a left-continuous function $g$ by declaring that if $f$ is continuous at $x$ then $g(x) = f(x)$, and otherwise setting
$$g(x) = \lim_{\varepsilon \to 0} f(x - \varepsilon).$$
Henceforth we will talk about Stieltjes premeasures of any nondecreasing function, knowing that we may have to redefine them on a countable set in order that the definition make sense.
\end{subsec}

\begin{example}
If $f(x) = x$, then the Stieltjes premeasure of an interval $[a, b)$ under $f$ is just its length $b - a$.
This premeasure is known as the \dfn{Lebesgue premeasure}.
It will be by far the most important premeasure that we study.
If the following theory ever seems too abstract, try it out on the Lebesgue premeasure!
\end{example}

\begin{example}
The Stieltjes premeasure of a differentiable function $f$ can be thought of as ``weighted length"; $\mu_f([a, b)) > b - a$ provided that $f' > 1$ on $b - a$, and $\mu_f([a, b)) < b - a$ if $f' < 1$.
This is just an expression of the fundamental theorem of calculus: if $f$ is differentiable then
$$\mu_f([a, b)) = f(b) - f(a) = \int_a^b f'(x)~dx.$$
Since $f$ is nondecreasing, $f' \geq 0$.
This is our first clue that there is some connection between integration and measure theory.
\end{example}

\begin{example}
The Stieltjes premeasure of the Heaviside function $H$ will allow us to make some sense of our previous waffling about its derivative.
If $0 \notin [a, b)$ then $\mu_H([a, b)) = 0$.
Otherwise, $a \leq 0 < b$ and $H(b) = 1$, $H(a) = 0$; thus $\mu_H([a, b)) = 1$.
If one instead considers a finite set $X = \{x_1, \dots, x_n\}$ and
$$f(x) = \sum_{j=1}^n H(x - x_j),$$
then $\mu_f([a, b))$ is the cardinality of $X \cap [a, b)$.
\end{example}

\begin{theorem}
Every Stieltjes premeasure is $\sigma$-additive.
In particular, Lebesgue premeasure is $\sigma$-additive.
\end{theorem}
\begin{proof}
Let $\mu_f$ be a Stieltjes premeasure.
Let $E_n = [a_n, b_n)$, assume that the $E_n$ are disjoint, and let $E = \bigcup_n E_n$.
Suppose that $E = [a, b)$. We must show
\begin{equation}
\label{SPM sum}
f(b) - f(a) = \sum_{n=1}^\infty f(b_n) - f(a_n).
\end{equation}
To do so, we first note that since $f$ is nondecreasing, the quantities $\mu_f([a_n, b_n))$ are positive, so the sum in (\ref{SPM sum}) converges absolutely.
Thus we may rearrange the order of the summands without affecting the value of the sum, so we can assume that $a_n \leq a_{n+1}$ for every $n$, by reordering the intervals $E_n$.
Since the intervals are disjoint it follows that $b_n \leq a_{n+1}$.

We now prove
$$\mu_f(E) \geq \sum_{n=1}^\infty \mu_f(E_n).$$
To do this, we fix an $N$ and show that
\begin{equation}
\label{SPM sum bound 1}
f(b) - f(a) \geq \sum_{n=1}^N f(b_n) - f(a_n).
\end{equation}
Now $b \geq b_n$ and $a \leq a_n$, so $f(b) - f(a) \geq f(b_N) - f(a_1)$, but
$$\sum_{n=1}^N f(b_n) - f(a_n) = f(b_N) - f(a_1) + \sum_{n=1}^{N-1} f(b_n) - f(a_{n+1}).$$
But $b_n \leq a_{n+1}$ so $f(b_n) \leq f(a_{n+1})$, so
$$\sum_{n=1}^{N-1} f(b_n) - f(a_{n+1}) \leq 0.$$
Therefore
$$\sum_{n=1}^N f(b_n) - f(a_n) \leq f(b_N) - f(a_1) \leq f(b) - f(a).$$
This proves (\ref{SPM sum bound 1}).

Conversely, we must show that
$$\mu_f(E) \leq \sum_{n=1}^\infty \mu_f(E_n).$$
It suffices to show that for every $\varepsilon > 0$,
\begin{equation}
\label{SPM sum bound 2}
f(b) - f(a) \leq \varepsilon + \sum_{n=1}^\infty f(b_n) - f(a_n).
\end{equation}
Now choose $b' < b$ such that $f(b') \geq f(b) - \varepsilon/2$ and for each $n$ choose $a_n' < a_n$ such that $f(a_n') \geq f(a_n) - \varepsilon/2^{n+1}$.
Such $a_n'$ and $b'$ exist because $f$ is left-continuous.
Now
$$[a_n', b'] \subseteq [a, b) = \bigcup_{n=1}^\infty [a_n, b_n) \subseteq \bigcup_{n=1}^\infty (a_n', b_n).$$
Therefore the $(a_n', b_n)$ are an open cover of $[a_n', b]$, so by the Heine-Borel theorem there is an $N$ such that
$$[a_n', b'] \subseteq \bigcup_{n=1}^N (a_n', b_n).$$
If any interval is superfluous, we now discard it.
Then the way we ordered the intervals, $a_{n+1}' \leq b_n$.
TODO: Draw a picture.
Moreover, $a_1' \leq a$ and $b' \leq b_N$. Then
\begin{align*}
f(b) - f(a) &\leq f(b') - f(a) + \frac{\varepsilon}{2}\\
& \leq f(b_N) - f(a_1') + \frac{\varepsilon}{2}\\
& \leq f(b_N) - f(a_1') + \frac{\varepsilon}{2} + \sum_{n=1}^{N-1} f(b_n) - f(a_{n+1}')\\
& \leq \frac{\varepsilon}{2} + \sum_{n=1}^N f(b_n) - f(a_n')\\
& \leq \frac{\varepsilon}{2} + \sum_{n=1}^N f(b_n) - f(a_n) + \frac{\varepsilon}{2^{n+1}}\\
& \leq \varepsilon + \sum_{n=1}^N f(b_n) - f(a_n)
\end{align*}
where we used Zeno's paradox
\begin{equation}
\label{zeno}
\sum_{n=1}^\infty \frac{1}{2^n} = 1
\end{equation}
to sum the geometric series of $\varepsilon$'s.
But this estimate is exactly (\ref{SPM sum bound 2}).
\end{proof}

\begin{exercise}
\label{nondecreasing exercise}
Show that a nondecreasing function on $\RR$ can only be discontinuous on a countable set.
\end{exercise}

\begin{exercise}
Let $\Sigma$ be a $\sigma$-ring, and let $\mu: \Sigma \to B$ be a function such that whenever $A_1 \subseteq A_2 \subseteq A_3 \subseteq \cdots$,
$$\lim_{n \to \infty} \mu(A_n) = \mu\left(\bigcup_{n=1}^\infty A_n\right).$$
Show that if $\mu$ is \dfn{additive} (that is, if $A \cap B = \emptyset$, then $\mu(A \cup B) = \mu(A) + \mu(B)$), then $\mu$ is $\sigma$-additive.
\end{exercise}

\begin{exercise}
Let $\mathcal F$ be the vector space of left-continuous, nondecreasing functions and $\mathcal M$ the vector space of Stieltjes premeasures.
Show that the map $f \mapsto \mu_f$ which assigns a function to its Stieltjes premeasure is a linear map $\mathcal F \to \mathcal M$.
\end{exercise}

\section{Premeasures and outer measures}
Encouraged by the previous section, we now define premeasures in general.
Our goal is to define a $\sigma$-additive function that can be extended to a measure in a unique way; thus, to define a measure, it will suffice to define a premeasure.

\begin{definition}
A set of sets $P$ is said to be a \dfn{semiring} if $\emptyset \in P$ and for every $E, F \in P$:
\begin{enumerate}
\item $E \cap F \in P$.
\item There are $G_1, \dots, G_m$ disjoint such that
$$E \setminus F = \bigcup_{n=1}^m G_n.$$
\end{enumerate}
A $\sigma$-additive function $P \to [0, \infty]$ which is not identically $\infty$ is called a \dfn{premeasure}.
\end{definition}

\begin{example}
The set of all half-open intervals $[a, b)$ is a semiring, so a Stieltjes premeasure is a premeasure.
\end{example}

\begin{lemma}
\label{semiring prop 1}
Let $P$ be a semiring and $\mu$ a premeasure on $P$. Then:
\begin{enumerate}
\item If $E_1, \dots, E_m \in P$ then there are disjoint $F_1, \dots, F_n \in P$ such that
$$((((E_1 \setminus E_2) \setminus E_3) \setminus \cdots) \setminus E_m) = \bigcup_{i=1}^n F_i.$$
\item $\mu(\emptyset) = 0$.
\end{enumerate}
\end{lemma}
\begin{proof}
Exercise \ref{semiring exercise}.
\end{proof}

\begin{lemma}
\label{semiring prop 2}
Let $P$ be a semiring and $\mu$ a premeasure on $P$. Then:
\begin{enumerate}
\item If $(E_n)_n$ is a sequence of disjoint sets in $P$ and $E \supseteq \bigcup_n E_n$, $E \in P$, then
$$\sum_{n=1}^\infty \mu(E_n) \leq \mu(E).$$
\item If $E \subseteq F$, $E, F \in P$, then $\mu(E) \leq \mu(F)$.
\end{enumerate}
\end{lemma}
\begin{proof}
We first prove the first claim. By Lemma \ref{semiring prop 1}, there are $F_i \in P$ disjoint such that
$$((((E_1 \setminus E_2) \setminus E_3) \setminus \cdots) \setminus E_m) = \bigcup_{i=1}^n F_i.$$
In particular, $E$ is the disjoint union of the $E_i$ and $F_i$. Thus
$$\mu(E) = \sum_i \mu(E_i) + \sum_j \mu(F_j).$$
But $\mu$ is nonnegative so $\sum_i \mu(E_i) \geq 0$, thus the claim.

The second claim follows from the first in the case $n = 1$, $E_1 = F$.
\end{proof}

\begin{subsec}
The power of Lemma \ref{semiring prop 2} is that it does not assume that $\bigcup E_n \in P$.
\end{subsec}

\begin{subsec}
With these basic properties of premeasures set aside, we now discuss how to extend a premeasure to a measure.
First, we note that while premeasures are $\sigma$-additive, they also have another useful property, called $\sigma$-subadditivity.
\end{subsec}

\begin{definition}
Let $P$ be a set of sets. A function $\mu: P \to (-\infty, \infty]$ such that for every sequence of $E_i \in P$, if $E \in P$ and $E \subseteq \bigcup_i E_i$, then
$$\mu(E) \leq \sum_{i=1}^\infty \mu(E_i),$$
is said to be a \dfn{$\sigma$-subadditive function}.
\end{definition}

\begin{lemma}
Every premeasure is $\sigma$-subadditive.
\end{lemma}
\begin{proof}
Suppose that $E = \bigcup_i E_i$. By Lemma \ref{semiring prop 1}, we can write
$$(((E_i \setminus E_{i-1}) \setminus E_{i-2}) \setminus \cdots \setminus E_1) = \bigcup_{j=1}^{k_i} F_i^j$$
where the $F_i^j$ are disjoint, hence
$$\mu(E) = \mu(E_1) + \sum_{i=2}^\infty \sum_{j=1}^{k_i} \mu(F_i^j).$$
But $\bigcup_j F_i^j \subseteq E_i$ so by Lemma \ref{semiring prop 2},
$$\sum_{j=1}^{k_i} \mu(F_i^j) \leq \mu(E_i).$$
Thus
$$\mu(E) \leq \sum_{i=1}^\infty \mu(E_i)$$
which was to be shown.
\end{proof}

\begin{subsec}
Because premeasures are $\sigma$-subadditive, it would be natural to extend them to a $\sigma$-subadditive function defined on a $\sigma$-ring. We do this now.
\end{subsec}

\begin{definition}
Let $R$ be a $\sigma$-ring.
An \dfn{outer measure} is a $\sigma$-subadditive function $\mu: R \to [0, \infty]$ such that $\mu(\emptyset) = 0$.
\end{definition}

\begin{subsec}
It follows from the definition that an outer measure $\mu$ is monotone; that is, if $E \subseteq F$, $E,F \in P$, then $\mu(E) \leq \mu(F)$.
\end{subsec}

\begin{subsec}
Let $\mu$ be a prmeasure.
We will now construct a $\sigma$-ring $R$ such that $\mu$ extends to an outer measure on $R$.
\end{subsec}

\begin{definition}
A set $\mathcal H$ whose elements are sets is said to be \dfn{hereditary} if for every $E \in \mathcal H$ and $F \subseteq E$, $F \in \mathcal H$.
\end{definition}

\begin{lemma}
For every semiring $P$ there is a smallest hereditary $\sigma$-ring $\mathcal H(P)$ such that $P \subseteq \mathcal H(P)$.
\end{lemma}
\begin{proof}
Let $X$ be the union of all elements in $P$. Then the power set $2^X$ is clearly a hereditary $\sigma$-ring such that $P \subseteq 2^X$.
The intersection of $\sigma$-rings containing $P$ is a $\sigma$-ring containing $P$, so it suffices to show that the intersection of hereditary sets is hereditary.

In fact, let $H$ be a set whose elements are hereditary sets, and let $\mathcal H$ be the intersection of $H$.
Let $E \in \mathcal H$; then for every $F \subseteq E$, $F$ is contained in every element of $H$, so $F \in \mathcal H$.
\end{proof}

\begin{definition}
Let $P$ be a semiring and $\mu$ be a premeasure on $P$. For every $A \in \mathcal H(P)$, define
$$\mu^*(A) = \inf \sum_{n=1}^\infty \mu(E_n)$$
where the $\inf$ ranges over all sequenes of sets $(E_n)_n$, $E_n \in P$, such that $A \subseteq \bigcup_n E_n$.
We call $\mu^*$ the \dfn{outer measure generated by $\mu$}.
\end{definition}

\begin{theorem}
Let $P$ be a semiring and $\mu$ be a premeasure on $P$. Then the outer measure $\mu^*$ generated by $\mu$ is an outer measure on $\mathcal H(P)$ and for every $E \in P$, $\mu^*(E) = \mu(E)$.
\end{theorem}
\begin{proof}
First, we check $\mu^*(\emptyset) = 0$. In fact, taking $E_n = \emptyset$ for every $n$, we have $\mu^*(\emptyset) \leq \sum_n 0 = 0$.

We now check that $\mu^*$ is $\sigma$-subadditive:
\begin{lemma}
Suppose that $A \in \mathcal H(P)$, $A_n \in \mathcal H(P)$, and $A \subseteq \bigcup_n A_n$. Then
$$\mu^*(A) \leq \sum_{n=1}^\infty \mu^*(A_n).$$
\end{lemma}
\begin{proof}[Proof of lemma]
Obviously this is true if some $\mu^*(A_n) = \infty$, so suppose that for every $n$, $\mu^*(A_n) < \infty$ and let $\varepsilon > 0$.
By definition of $\mu^*$, there are $E_i^j \in P$ such that $A_i \subseteq \bigcup_j E_i^j$
and
$$\mu^*(A_i) \geq \sum_{j=1}^\infty \mu(E_i^j) - \frac{\varepsilon}{2^i}.$$
Thus $A \subseteq \bigcup_{i,j}E_i^j$ whence
\begin{align*}\mu^*(A) &\leq \sum_{i,j} \mu(E_i^j) \leq \sum_{i,j=1}^\infty \mu(E_i^j)\\ &\leq \sum_{i=1}^\infty \mu^*(A_i) + \frac{\varepsilon}{2_i}\\& \leq \varepsilon + \sum_{i=1}^\infty \mu^*(A_i).\end{align*}
This was to be shown.
\end{proof}

Finally we check that $\mu^*(A) = \mu(A)$ when $A \in P$. Clearly $\mu^*(A) \leq \mu(A)$.
Since $\mu$ is $\sigma$-subadditive, for any $E_i \in P$ such that $A \subseteq \bigcup_i E_i$, $\mu(A) \leq \sum_i \mu(E_i)$, thus $\mu(A) \leq \mu^*(A)$.
\end{proof}

\begin{subsec}
There is a dual approach to the extension of premeasures, introduced by Lebesgue.
He considered not just outer measures but \dfn{inner measures} defined by the relation
$$\mu_*(E) = \sup \sum_{n=1}^\infty \mu(E_n)$$
where the $\sup$ ranges over all sequences of $E_n \in P$ such that $\bigcup_n E_n \subseteq P$ and the $E_n$ are disjoint.
Then Lebesgue proposed to study the $\sigma$-ring of all sets whose inner and outer measures agree.
Note the asymmetry: for inner measure we need to assume that the $E_n$ are disjoint, or else we could ``double-count" elements of $E$.
This asymmetry is the origin of several pathologies that make inner measures difficult to work with, and now this approach is considered nothing more than a historical footnote.
\end{subsec}

\begin{example}
An example of an oddity of inner measure comes from trying to compute the inner measure of the set $X$ of irrational numbers in $[0, 1]$.
Let $P$ be the semiring of intervals with rational endpoints in $[0, 1]$ and let $\mu$ be the Stieltjes premeasure on $P$ defined by $\mu([a, b)) = b - a$.
Then $\mu^*(X) = 1$.

To see this, let $x \in [0, 1]$; we will compute $\mu^*(\{x\})$. Let $[x]_n$ be a rational number such that $[x]_n < x < [x]_n + 1/n$; thus $\{x\} \subset [[x]_n, [x]_n + 1/n)$ and so
$$\mu^*(\{x\}) \leq \mu([x]_n, [x]_n + 1/n) = \frac{1}{n}$$
whence $\mu^*(\{x\}) = 0$.

Let $(x_n)_n$ be an enumeration of the countable set $\QQ \cap [0, 1]$; by $\sigma$-subadditity,
$$\mu^*(\QQ \cap [0, 1]) \leq \sum_{n=1}^\infty \mu^*(\{x_n\}) = 0$$
but $X \cup (\QQ \cap [0, 1]) = [0, 1]$, so
$$1 = \mu([0, 1]) \leq \mu^*(X) + \mu^*(\QQ \cap [0, 1]) = \mu^*(X) + 0.$$
Therefore $\mu^*(X) \geq 1$, but $X \subseteq [0, 1]$ so $\mu^*(X) \leq 1$.

But there are no intervals in $P$ which are contained in $X$; thus the only element of $P$ contained in $E$ is $\emptyset$, so
$$\mu_*(E) = \sup 0 = 0.$$
Thus this seemingly reasonable way of defining an inner measure fails to measure the set of irrational numbers.
\end{example}

\begin{exercise}
\label{semiring exercise}
Prove Lemma \ref{semiring prop 1}.
\end{exercise}


\section{The Carath√©odory construction}
Carath√©odory introduced a modern approach that we now consider which avoids the issues with inner measures.
The idea is that, while an outer measure may not be a measure, there is a canonically defined $\sigma$-ring on which the outer measure will restrict to a measure.
The elements of that ring will be called measurable sets.

\begin{subsec}
The Carath√©odory construction gives us a method to define measures: first define a premeasure, then check a certain technical hypothesis that we now state; then one has a unique measure which extends the premeasure.
\end{subsec}

\begin{definition}
Let $(X, \Sigma, \mu)$ be a measured space.
We say that $\mu$ is a \dfn{$\sigma$-finite measure} if there are countably many $E_n \in \Sigma$ such that $\bigcup_n E_n = X$ and $\mu(E_n) < \infty$.
We say that $\mu$ is a \dfn{complete measure} if for every $E \in \Sigma$ such that $\mu(E) = 0$ and $F \subseteq E$, $F \in \Sigma$.
\end{definition}

\begin{theorem}[Carath√©odory construction]
Let $P$ a semiring of subsets of a set $X$ such that $X \in P$.
Let $\mu$ be a premeasure on $P$.
Then there is a $\sigma$-algebra $\Sigma$ which contains $P$ and an extension of $\mu$ to a complete measure on $\Sigma$.
Moreover, if $\mu$ is $\sigma$-finite, then $(X, \Sigma, \mu)$ is the unique measured space with this property.
\end{theorem}

\begin{subsec}
The rest of this section is devoted to the proof of the Carath√©odory construction theorem.
We begin by constructing $\Sigma$.
We will do this by giving a property -- namely, ``measurability" -- that every set in the $\sigma$-algebra $\Sigma$ ought to satisfy.
We will then show that the set of all measurable sets forms a $\sigma$-algebra; thus, we might as well define $\Sigma$ to be that $\sigma$-algebra.
\end{subsec}

\begin{subsec}
Let us fix an outer measure $\mu^*$ be an outer measure on a hereditary $\sigma$-ring $\mathcal H$.
In practice, $\mu^*$ will be the extension of a premeasure and $\mathcal H$ will be the $\sigma$-algebra of all subsets of some set.
\end{subsec}

\begin{definition}
A \dfn{$\mu^*$-measurable set} is a set $A \in \mathcal H$ such that for every $E \in \mathcal H$,
\begin{equation}
\label{clean division}
\mu^*(E) = \mu^*(E \cap A) + \mu^*(E \setminus A).
\end{equation}
We let $\mathcal M(\mu^*)$ denote the set of all $\mu^*$-measurable sets.
In the event that (\ref{clean division}) holds, we say that $A$ \dfn{cleanly divides} $E$, so a set $A$ is $\mu^*$-measurable if for every set $E \in \mathcal H$, $A$ cleanly divides $E$.
\end{definition}

\begin{subsec}
Since an outer measure is subadditive, one already has
$$\mu^*(E) \leq \mu^*(E \cap A) + \mu^*(E \setminus A)$$
and so one just has to prove the opposite inequality
\begin{equation}
\label{Caratheodory inequality}
\mu^*(E \cap A) + \mu^*(E \setminus A) \leq \mu^*(E)
\end{equation}
to check that a set is $\mu^*$-measurable.
\end{subsec}

\begin{definition}
We say that a set $A \in \mathcal H$ is \dfn{$\mu^*$-null} if $\mu^*(A) = 0$.
We let $\mathcal N(\mu^*)$ denote the set of all $\mu^*$-null sets.
\end{definition}

\begin{subsec}
Clearly $\emptyset$ is always $\mu^*$-null, and any subset of a $\mu^*$-null set is $\mu^*$-null, thus $\mathcal N(\mu^*)$ is hereditary.
In general $\emptyset$ may be the only $\mu^*$-null set (think of counting measure), but as we will see, Stieltjes measures have lots of null sets.
We now show that every $\mu^*$-null set is measurable, and have no effect on measurability.
In fact, $\mu^*$-null sets will never matter much.
\end{subsec}

\begin{lemma}
The set $\mathcal N(\mu^*)$ of $\mu^*$-null sets is a $\sigma$-ring, and $\mathcal N(\mu^*) \subseteq \mathcal M(\mu^*)$.
Moreover, if $A$ is $\mu^*$-measurable and $Z$ is $\mu^*$-null, then $A \cup Z$ and $A \setminus Z$ are $\mu^*$-measurable.
\end{lemma}
\begin{proof}
Let $Z$ be $\mu^*$-null. Then for every $E$,
$$\mu^*(E \cap Z) + \mu^*(E \setminus Z) = 0 + \mu^*(E \setminus Z) \leq \mu^*(E)$$
since $\mathcal N(\mu^*)$ is hereditary.
Thus $Z$ is $\mu^*$-measurable, so $\mathcal N(\mu^*) \subseteq \mathcal M(\mu^*)$.
If $A$ cleanly divides $E$ then clearly so do $A \cup Z$ and $A \setminus Z$, so null sets have no effect on measurability.
Countable subadditivity implies that $\mathcal N(\mu^*)$ is a $\sigma$-ring.
\end{proof}

\begin{lemma}
\label{measurable complements lemma}
If $A_1, A_2$ are $\mu^*$-measurable sets, then so is $A_1 \setminus A_2$.
\end{lemma}
\begin{proof}
Since $E$ is the disjoint union of the sets $E \cap (A_1 \cap A_2)$, $E \cap (A_1 \setminus A_2)$, $E \cap (A_2 \setminus A_1)$, and $E \cap (A_1 \cup A_2)$, this follows from the fact that $A_1$ and $A_2$ divide each of the above sets cleanly.
We leave the details as Exercise \ref{measurable complements}.
\end{proof}

\begin{lemma}
For every outer measure $\mu^*$, the set of measurable sets $\mathcal M(\mu^*)$ is a $\sigma$-ring and $\mu^*$ restricts to a measure on $\mathcal M(\mu^*)$.
\end{lemma}
\begin{proof}

\end{proof}



TODO: Show that $P$ has measurable sets

TODO: Completions of measures

TODO: Uniqueness of extensions

Leave lots of the above as exercises.

\begin{exercise}
\label{measurable complements}
Fill in the details in the proof of Lemma \ref{measurable complements lemma}.
\end{exercise}

\begin{exercise}
Let $(X, \Sigma, \mu)$ be a measured space. Show that the following are equivalent:
\begin{enumerate}
\item $\mu$ is $\sigma$-finite.
\item There are countably many disjoint $E_i \in \Sigma$, $\mu(E_i) < \infty$, such that $\bigcup_i E_i = X$.
\item There are countably many $E_i \in \Sigma$, $\mu(E_i) < \infty$, such that $E_i \subseteq E_{i+1}$ and $\bigcup_i E_i = X$.
\end{enumerate}
These equivalences are highly useful and will be used throughout the text without explicit mention.
\end{exercise}

\begin{exercise}
Let $(X, \Sigma, \mu)$ be a measured space, and let $\mathcal N$ be the $\sigma$-algebra of all null subsets of $\mu$. Let $\overline \Sigma$ be the $\sigma$-algebra generated by $\Sigma$ and $\mathcal N$.
Show that there is a unique extension $\overline \mu$ of $\mu$ to $(X, \overline \Sigma)$, and that $(X, \overline \Sigma, \overline \mu)$ is a complete measured space.
We call $(X, \overline \Sigma, \overline \mu)$ the \dfn{completion} of $(X, \Sigma, \mu)$.
\end{exercise}

\section{Lebesgue measure on $\RR$}
In this section we define the most important measure of all: Lebesgue measure on $\RR$.

\begin{subsec}
We begin by recalling that given a nondecreasing left-continuous function $f$ on $\RR$, the Stieltjes premeasure $\mu_f$ was given by
$$\mu_f([a, b)) = f(b) - f(a)$$
whenever $a < b$.
We can extend the semiring $P$ of half-open intervals to include $\RR$ by setting
$$\mu_f(\RR) = \lim_{n \to \infty} f(n) - f(-n),$$
which may be infinite, but always makes sense, since the only way that $\mu_f(\RR)$ could be $\infty - \infty$ is if
$$\lim_{x \to -\infty} f(x) = +\infty$$
which is impossible since $f$ is increasing.
Since the Stieltjes premeasure is a premeasure, it follows from the Carath√©odory construction that there is a $\sigma$-algebra $\Sigma$ containing $P$ (and therefore containing the Borel $\sigma$-algebra $\mathcal B(\RR)$) and a measure, which we also call $\mu_f$, on $\Sigma$ which extends $\mu_f$.
\end{subsec}

\begin{lemma}
Every Stieltjes measure is $\sigma$-finite.
\end{lemma}
\begin{proof}
$\RR$ is covered by sets of the form $[n, n + 1)$, $n \in \ZZ$, of which there are countably many.
Now $\mu_f([n, n + 1)) = f(n+1) - f(n)$ is finite, so $\RR$ is $\sigma$-finite.
\end{proof}

\begin{subsec}
By the Carath√©odory construction theorem, if a premeasure extends to a $\sigma$-finite complete measure $\mu$, then $\mu$ is the unique such extension.
It follows from the previous lemma that $\mu_f$ is well-defined.
More precisely, $\mu_f$ is the unique complete Borel measure obtained by extending the Stieltjes premeasure associated to $f$.
\end{subsec}

\begin{definition}
The \dfn{Stieltjes measure} arising from a nondecreasing left-continuous function $f$ is the complete Borel measure $\mu_f$ obtained from the Stieltjes premeasure of $f$.
\end{definition}

\begin{lemma}
If $\mu_f$ is a Stieltjes measure then for every open interval $(\alpha, \beta)$ one has
$$\mu_f((\alpha, \beta)) = f(\beta) - \lim_{n \to \infty} f(\alpha + 1/n).$$
In particular, if $f$ is continuous then $\mu_f((\alpha, \beta)) = f(\beta) - f(\alpha)$.
\end{lemma}
\begin{proof}
By continuity of measure,
$$\mu_f((\alpha, \beta)) = \lim_{n \to \infty} \mu_f([\alpha + 1/n, \beta)) = \lim_{n \to \infty} f(\beta) - f(\alpha + 1/n)$$
which is what we wanted.
\end{proof}

\begin{subsec}
In particular, if $f(x) = x$, then $\mu_f((\alpha, \beta)) = \beta - \alpha$.
This fact will be used so often that we will frequently use it without reference.
\end{subsec}

\begin{definition}
The \dfn{Lebesgue measure} on $\RR$ is the Stieltjes measure arising from the Lebesgue premeasure; that is, the Lebesgue measure is $\mu_f$ where $f(x) = x$.
\end{definition}

\begin{subsec}
Let $\mu$ denote Lebesgue measure; then $\mu([\alpha, \beta)) = \beta - \alpha$ is the length of the interval $[\alpha, \beta)$.
Therefore $\mu$ is the natural generalization of ``length" to as many subsets of $\RR$ as one reasonably can generalize it to.
Indeed, if $A$ is a Lebesgue measurable subset of $\RR$ (e.g. if $A$ is Borel) then
\begin{equation}
\label{lebesgue measure formula}
\mu(A) = \inf \left\{\sum_{j=1}^\infty \beta_i - \alpha_i: A \subseteq \bigcup_{i=1}^\infty [\alpha_i, \beta_i)\right\}.
\end{equation}
\end{subsec}

\begin{theorem}
\label{translation invariance in R1}
Lebesgue measure $\mu$ is \dfn{translation-invariant} in the sense that if $A$ is a Lebesgue measurable set, and $A + x = \{a + x: a \in A\}$, then $\mu(A) = \mu(A + x)$.
Conversely, if $\nu$ is a translation-invariant complete Borel measure such that $\nu([0, 1)) = 1$, then $\mu = \nu$.
\end{theorem}
\begin{proof}
If $A = [\alpha, \beta)$ is an interval, then $\mu(A + x) = \beta + x - \alpha - x = \beta - \alpha = \mu(A)$.
If $A$ is an arbitrary measurable set, then by (\ref{lebesgue measure formula}),
\begin{align*}
\mu(A + x) &= \inf \left\{\sum_{j=1}^\infty \beta_i - \alpha_i: A + x\subseteq \bigcup_{i=1}^\infty [\alpha_i, \beta_i)\right\} \\
&= \inf \left\{\sum_{j=1}^\infty \beta_i + x- \alpha_i - x: A \subseteq \bigcup_{i=1}^\infty [\alpha_i, \beta_i)\right\}\\
&= \inf \left\{\sum_{j=1}^\infty \beta_i - \alpha_i: A \subseteq \bigcup_{i=1}^\infty [\alpha_i, \beta_i)\right\}\\
&= \mu(A).
\end{align*}

Conversely, $\nu$ is $\sigma$-finite, since by translation invariance, the sets $[n, n + 1)$ all have $\nu$-measure $1$, there are countably many of them, and they cover $\RR$.
Now if $[\alpha, \beta)$ is an arbitrary interval, we can write
$$[\alpha, \beta) = \bigcup_{n\in\ZZ} [\alpha, \beta) \cap [n, n + 1)$$
and use countable additivity to see that
$$\nu([\alpha, \beta)) = \sum_{n\in\ZZ} \nu([\alpha, \beta) \cap [n, n + 1)).$$
So it suffices to show that $\nu([\alpha, \beta)) = \mu([\alpha, \beta))$ whenever $[\alpha, \beta) \subseteq [n, n + 1)$ for some $n$, in order that this also be true for any interval $[\alpha, \beta)$.
Then by translation invariance, it suffices to check this when $\alpha = 0$, in which case $\beta \in (0, 1)$.

Suppose first that $\beta$ is rational, say $\beta = p/q$. Then by translation invariance and countable additivity,
$$\nu([\alpha, \beta)) = \nu([0, p/q)) = \sum_{j=0}^{p-1} \nu([j, (j+1)/q)) = p\nu([0, 1/q)).$$
But
$$1 = \nu([0, 1)) = \sum_{j=0}^{q-1} \nu([j, (j+1)/q)) = q\nu([0, 1/q))$$
which implies that $\nu([0, 1/q)) = 1/q$ and hence $\nu([0, p/q)) = p/q$; therefore $\nu([\alpha, \beta)) = \beta - \alpha$ whenever $\beta - \alpha$ is rational.
If $\beta - \alpha$ is irrational, choose $\beta_n > \beta_{n+1} > \cdots > \beta$ so that $\beta_n \to \beta$ and $\beta_n - \alpha$ is rational for all $n$; then $\nu([\alpha, \beta_n)) = \beta_n - \alpha$, so continuity of measure implies that $\nu([\alpha, \beta)) = \beta - \alpha$.

Since $\mu([\alpha, \beta)) = \nu([\alpha, \beta))$ for all $\alpha < \beta$, uniqueness of the Carath√©odory construction for $\sigma$-finite measures implies that $\mu = \nu$.
\end{proof}

\begin{subsec}
The above argument is an example of a ``bootstrapping" strategy that is common in measure theory.
Once one has established a simple case (here $\nu([0, 1)) = 1$), it is often possible to propagate that case to a slightly more complicated case ($\nu([0, 1/q)) = 1/q$, say), and then repeat this process until all sets of interest have been considered.
If you find yourself stuck on an exercise, it is worth trying to prove the claim in the simplest possible case and then iteratively improving the cases your proof works for until all cases are hit.
\end{subsec}

\begin{subsec}
Theorem \ref{translation invariance in R1} shows that we could have defined Lebesgue measure axiomatically. We would have had to demanded that:
\begin{enumerate}
\item Countable additivity: Lebesgue measure be a measure.
\item Borel: Every open interval be Lebesgue measurable.
\item Completeness: Every subset of a Lebesgue null set be null.
\item Translation-invariance: A translate of a Lebesgue measurable set have the same Lebesgue measurable.
\item Calibration: The interval $[0, 1)$ have Lebesgue measure $1$.
\end{enumerate}
Certainly all of these conditions seem quite tame; then the Carath√©odory construction would have proven existence and uniqueness.
However, it is convenient to pass through the notion of a Stieltjes measure along the way, as more general Stieltjes measures are quite useful in their own right.
\end{subsec}

\begin{subsec}
One may wonder if \emph{every} subset of $\RR$ is Lebesgue measurable.
Under certain reasonable set-theoretic hypotheses, this is false; we discuss a counterexample, Vitali's set, in Example \ref{Vitali set}.
But the next-best thing is true, as any set that an analyst, algebraist, topologist, or applied mathematician will ever have to work with will turn out to be measurable. We discuss this in Example \ref{all functions are measurable}.
This is closely related to a theorem of Solovay (TODO:Cite) which shows that in a certain sense, those set-theoretic hypotheses \emph{cannot} be avoided in the construction of a nonmeasurable set: a slightly different logical setup would imply that every subset of $\RR$ is measurable.
\end{subsec}

\begin{subsec}
Lebesgue measure is remarkably well-behaved, along with satisfying the five axioms above.
To see an example of another good property of Lebesgue measure, we need a new definition.
If the reader is uncomfortable with the abstract definition of a locally compact Hausdorff space, they may take $X = \RR$ in the following definition without losing any insight.
\end{subsec}

\begin{definition}
\label{dfn of radon measure}
Let $X$ be a locally compact Hausdorff space.
Suppose that $\mu$ is a Borel measure on $X$ such that:
\begin{enumerate}
\item \dfn{Outer regularity}: For every Borel set $W$,
$$\mu(W) = \inf_U \mu(U)$$
where the infimum is taken over all open sets $U \supseteq W$.
\item \dfn{Inner regularity for open sets}: For every open set $U$,
$$\mu(U) = \sup_K \mu(K)$$
where the supremum is taken over all compact sets $K \subseteq U$.
\item \dfn{Local finiteness}: For every compact set $K$, $\mu(K) < \infty$.
\end{enumerate}
Then we say that $\mu$ is a \dfn{Radon measure}.
\end{definition}

\begin{theorem}
\label{lebesgue is radon}
Every Stieltjes measure on $\RR$ is Radon.
In particular, Lebesgue measure is Radon.
\end{theorem}
\begin{proof}
Let $f$ be a nondecreasing left-continuous function.
If $K$ is compact then $K$ is bounded, so $K$ is contained in an interval $[\alpha, \beta)$ so $\mu_f(K) \leq f(\beta) - f(\alpha)$.
Therefore $\mu_f$ is locally finite.

For inner regularity, note that every open set $U$ can be written as a disjoint union of countably many open intervals, so it suffices to check when $U$ is the interval $(\alpha, \beta)$.
Now if $K \subset (\alpha, \beta)$ is compact then there is an $n$ such that $K \subseteq [\alpha + 1/n, \beta)$, so $\mu_f(K) \leq f(\beta) - f(\alpha + 1/n)$.
On the other hand,
$$\lim_{n \to \infty} \mu_f([\alpha + 1/n, \beta)) = f(\beta) - \lim_{n \to \infty} f(\alpha + 1/n) = \mu_f((\alpha, \beta)).$$
Therefore $\mu_f$ is inner regular.

For outer regularity, let $W$ be a Borel set (actually, any Stieltjes measurable set); then
$$\mu(W) = \inf_{(\alpha_n), (\beta_n)} \sum_n f(\beta_n) - f(\alpha_n)$$
where the $\inf$ ranges over all sequences of $\alpha_n$ and $\beta_n$ such that $W \subseteq \bigcup_n [\alpha_n, \beta_n)$.
Fix any such sequences.
Now $E_m^n = (\alpha_n - m^{-1}2^{-n}, \beta_n)$ is an open cover of $W$ for any $m$, so
$$\mu(W) \leq \sum_n f(\beta_n) - f(\alpha_n) < \frac{1}{m} + \sum_n f(\beta_n) - f(\alpha_n) = \sum_n f(\beta_n) - f(\alpha_n) + m^{-1}2^{-n}.$$
Taking $m \to \infty$ and minimizing $\sum_n f(\beta_n) - f(\alpha_n)$ by varying the $\alpha_n$ and $\beta_n$ we collapse the above inequalities into $\inf$s.
\end{proof}

\begin{subsec}
The proof of Theorem \ref{lebesgue is radon} shows that Stieltjes measures are not just outer regular for Borel sets, but outer regular for any Stieltjes measurable set whatsoever.
However, this fact is rarely useful; as discussed below, we are mainly interested in equivalence classes of sets modulo null sets, and every Lebesgue measurable set is equivalent under that equivalence relation to a Borel set.
\end{subsec}

\begin{subsec}
After this chapter, we will mainly be interested in not measurable sets, but rather equivalence classes of measurable sets under the equivalence relation ``symmetric difference is a null set".
That is, we think of two measurable sets $A,B$ as the same if the symmetric difference $A \Delta B = (A \setminus B) \cup (B \setminus A)$ is null.
For example, every countable set is the same as the empty set.
One can give a different construction of the Lebesgue measure if one is \emph{only} interested in equivalence classes of measurable sets, rather than measurable sets themselves; see Exercises \ref{physical lebesgue measure 1} through \ref{physical lebesgue measure 3}.
\end{subsec}

\begin{subsec}
Let us now construct a useful example of an uncountable, null compact set, known as the \dfn{standard Cantor set}.
This set will frequently be useful as an example, and will be treated at length in the exercises.

Let $C_0 = [0, 1]$, and given $C_n$ a finite union of closed intervals, let $C_{n+1}$ consist of $C_n$ with the open middle-thirds of each interval in $C_n$ removed. TODO: Draw a picture.
Let $C$, the standard Cantor set, be defined by $C = \bigcap_n C_n$.
\end{subsec}

\begin{subsec}
It is often convenient to view the Cantor set in the following way. Let $2$ be a shorthand for the set $\{0, 1\}$.
Let $2^\omega$ denote the space of sequences in $2$, thus $2^\omega$ is the set of all functions $\NN \to \{0, 1\}$.
For each $x \in 2^\omega$, we obtain a point $f(x) \in C$ in the following way.
Assume that $D_{n-1}$ is one of the closed intervals obtained in stage $n-1$ of the Cantor set construction, thus $D_{n-1}$ is an interval in $C_{n-1}$.
If $x_n = 0$, let $D_n$ be the left closed interval in $D_{n-1}$, and otherwise let $D_n$ be the right closed interval.
Then $D_n \subseteq D_{n-1} \cap C_n$.
The intersection of closed nonempty intervals is a closed nonempty interval, so we obtain such an interval $D \subseteq C$.
But a consequence of Exercise \ref{Cantor set props} is that the Cantor set contains no nontrivial intervals, so $D$ consists of a single point $f(x)$.
The map $f$ is injective since if $f(x) = f(y)$ then, at the $n$th stage of the Cantor set construction, both $x$ and $y$ agreed on which subinterval to pass to, thus $x = y$.
It is surjective since every point $p \in C$ must be in some interval $D_n$ at stage $n$, and if $D_n$ is the left interval of $D_{n-1}$ then we can set $x = 0$, and otherwise set $x = 1$; then $f(x) = p$.
One can similarly interpret the Cantor set as the set of all paths through the full infinite binary tree.
This perspective can be highly useful in some exercises and in applications.
For more on Cantor sets, see TODO:Cite Pugh.
\end{subsec}

\begin{exercise}
Let $x \in \RR$ and let $f$ be a nondecreasing, left-continuous function. Show that
$$\mu_f(\{x\}) = \lim_{\varepsilon \to 0} f(x+\varepsilon) - f(x).$$
Conclude that if $f$ is continuous, then $\mu_f$ makes all countable sets null.
\end{exercise}

\begin{exercise}
Let $f$ be a nondecreasing, left-continuous function. Show that there is a nonempty open set $U$ such that $\mu_f(U) = 0$ iff $f$ is not strictly increasing (i.e. there are $x < y$ with $f(x) = f(y)$).
\end{exercise}

\begin{exercise}
\label{Dirac measure}
Let $x \in \RR$. The \dfn{Dirac measure} at $x$, denoted $\delta_x$, is the Stieltjes measure arising from the function
$$y \mapsto \begin{cases}
0, &y \leq x\\
1, &y > x.
\end{cases}$$
A set is \dfn{Dirac measurable} at $x$ if it is measurable with respect to $\delta_x$.
Show that every subset of $\RR$ is Dirac measurable at $x$, and compute its Dirac measure.
\end{exercise}

\begin{exercise}
\label{Cantor set props}
Show that the standard Cantor set is compact and Lebesgue null, has the same cardinality as $\RR$, and contains no interval except for points and the empty set.
\end{exercise}

\begin{exercise}
Let $\mu$ denote Lebesgue measure on $\RR$.
Show that there is a Borel probability measure $\nu$ on $\RR$, such that for every countable set $A$, $\nu(A) = 0$, and if $\mu(A) > 0$, then $\nu(A) = 0$.
(Hint: Define $\nu$ in such a way that, if $C$ denotes the standard Cantor set, then $\nu(C) = 1$, and use Exercise \ref{Cantor set props}.)
\end{exercise}

\begin{exercise}
Show that the set of Lebesgue measurable subsets of $\RR$ has cardinality equal to that of the power set $2^\RR$ of $\RR$. Conclude that there exists a Lebesgue measurable set which is not Borel.
(Hint: Exercise \ref{Cantor set props}.)
\end{exercise}

\begin{exercise}
\label{fat cat}
Show that for every $\alpha \in [0, 1)$ there exists a Cantoresque subset $C_\alpha$ of $[0, 1]$ whose Lebesgue measure is $\alpha$.
In particular, $C_\alpha$ should be compact and contain no open subset of $\RR$.
This is known as a \dfn{fat Cantor set}.
Show that there does not exist a fat Cantor set of measure $1$ in $[0, 1]$.
\end{exercise}

\begin{exercise}
\label{physical lebesgue measure 1}
In this exercise and the following we give a different construction of Lebesgue measure, other than the axiomatic definition or the construction using Stieltjes measures.

Let $\Sigma_0$ be the set of all intervals (open, closed, or half-open) with rational endpoints.
Given $I \in \Sigma_0$, define $\nu(I)$ to be the length of $I$.
If $I, J \in \Sigma_0$, then $I \setminus J \in \Sigma_0$, so we can define
$$d_0(I, J) = \nu(I \setminus J) + \nu(J \setminus I).$$
Show that $d_0$ is a semimetric, so the completion $(\Sigma, d)$ of $(\Sigma_0, d_0)$ is a complete metric space, and $\nu$ is a continuous function on $\Sigma$.

Show that the ``union" of countably many elements of $\Sigma$ is well-defined, as is the ``intersection" of countably many elements and ``complement" of one element.
That is, show that these operations drop to equivalence classes of elements of $\Sigma_0$ under the equivalence relation ``distance is $0$", and then extend uniquely to $\Sigma$.
So $\Sigma$ can be thought of as an ``abstract $\sigma$-ring" in some sense, even though its elements are not sets, but something more abstract.
\end{exercise}

\begin{exercise}
\label{physical lebesgue measure 2}
Let all definitions be as Exercise \ref{physical lebesgue measure 1}.
Given $J \in \Sigma_0$, define $[J]$ to be the equivalence class of $J$ in $\Sigma$.
Then, given $I \in \Sigma$, let
$$\nu(I) = d(I, [\emptyset]).$$
Show that $\nu$ is ``$\sigma$-additive" in the sense that whenever $(E_n)_n$ is a sequence in $\Sigma$ with $E_n \cap E_m = [\emptyset]$ whenever $n \neq m$, then
$$\nu\left(\bigcup_n E_n\right) = \sum_n \nu(E_n).$$
So we can think of $\nu$ as an ``abstract measure" on the abstract $\sigma$-ring $\Sigma$.
We call $\nu$ the \dfn{physical Lebesgue measure}.
\end{exercise}

\begin{exercise}
\label{physical lebesgue measure 3}
Let $\mu$ be Lebesgue measure and $\nu$ physical Lebesgue measure as in Exercise \ref{physical lebesgue measure 2}, defined on the abstract $\sigma$-ring $\Sigma$.
Let $\Gamma$ be the $\sigma$-algebra of Lebesgue measurable subsets of $\RR$. Show that there is a surjective map $\pi: \Gamma \to \Sigma$ such that:
\begin{enumerate}
\item For every rational interval $I$, $\pi(I)$ is the equivalence class of $I$ in $\Sigma$.
\item For every sequence $(E_n)_n$ in $\Gamma$, $\pi(\bigcup_n E_n) = \bigcup_n \pi(E_n)$, and similarly for intersection and complement.
\item For every $E \in \Gamma$, $\mu(E) = \nu(\pi(E))$.
\end{enumerate}
So we can think of $\pi(E)$ as the equivalence class of $E$ under the equivalence relation ``symmetric difference is null", and $\nu$ correctly computes the Lebesgue measurable of a set.
\end{exercise}



\chapter{More on measures}
In this chapter we discuss vector-valeud measures and the relationships between measured spaces.
These turn out to be especially useful in applications, including probability theory, so we introduce the languages of probability theory and ergodic theory in this chapter as well.

\section{Measurable maps}
In topology, a continuous map is one that pulls back open sets to open sets.
Here we have no open sets to work with -- only measurable spaces -- but this turns out to be exactly what we want.

\begin{definition}
Let $(X, \Sigma)$ and $(Y, \Gamma)$ be measurable spaces.
A \dfn{measurable map} $f: X \to Y$ is a map such that for every measurable set $A \in \Gamma$, $f^{-1}(A)$ is measurable.

A \dfn{measurable isomorphism} is a measurable map $f: X \to Y$ such that $f$ is a bijection and $f^{-1}$ is measurable.
If a measurable isomorphism exists, we say that $X,Y$ are \dfn{isomorphic} as measurable spaces, or that $\Sigma$ and $\Gamma$ are \dfn{isomorphic} as $\sigma$-algebras.
\end{definition}

\begin{example}
Isomorphism of measurable spaces is a very weak notion.
If $X$ is an uncountable \dfn{Polish space} -- a complete separate metric space -- then we call its Borel $\sigma$-algebra $\Sigma$ the \dfn{standard Borel algebra}.
A theorem of a branch of logic known as descriptive set theory implies that there is only one standard Borel algebra, up to isomorphism.
So any two Polish spaces, when viewed as measurable spaces, are the same!
\end{example}

\begin{definition}
Let $(X, \Sigma, \mu)$ be a measured space, $(Y, \Gamma)$ a measurable space, and $f: X \to Y$ a measurable map.
We define $f_*(\mu)$ on $(Y, \Gamma)$ by
$$f_*(\mu)(E) = \mu(f^{-1}(E))$$
and call $f_*(\mu)$ the \dfn{pushforward measure} of $\mu$ by $f$.
\end{definition}

\begin{example}
\label{lebesgue measure torus}
Let $\Torus$ be the circle, viewed for now as the set $\{z \in \CC: |z| = 1\}$.
Then $\Torus$ has its Borel $\sigma$-algebra $\Gamma$.
Let $\Sigma$ be the Borel $\Sigma$-algebra of $\RR$ and $\mu$ the Lebesgue measure restricted to $\Sigma$.
Then we have a continuous map $f: [0, 1] \to \Torus$ defined by
$$f(x) = e^{2\pi ix}.$$
Every continuous map between Borel measurable spaces is measurable, so $f$ is.
The pushforward measure $\nu = f_*(\mu)$ is known as the \dfn{Lebesgue measure} on $\Torus$.
The diligent reader will check that $\nu$ agrees with the notion of arc length defined in multivariable calculus (Exercise \ref{arc length exercise}).
\end{example}

\begin{definition}
Let $(X, \mu)$ and $(Y, \nu)$ be measured spaces.
A \dfn{measure-preserving map} is a measurable map $f: X \to Y$ such that
$$\nu = f_*(\mu).$$
If $f$ is a measurable isomorphism, we call $f$ a \dfn{measure-preserving isomorphism}.
\end{definition}

\begin{definition}
Let $X$ be a set, $(Y, \Gamma)$ a measurable space, and $F: X \to Y$ a map.
The \dfn{pullback $\sigma$-algebra} $F^*\Gamma$ is the $\sigma$-algebra of sets of the form $F^{-1}(A)$ where $A \in \Gamma$.
\end{definition}

\begin{subsec}
We need to check that the definition of a pullback $\sigma$-algebra makes sense.
Namely, we must show that if $F: X \to Y$ is a map, and $\Gamma$ a $\sigma$-algebra on $Y$, then $F^*\Gamma$ is a $\sigma$-algebra.
This is part of the content of Exercise \ref{pullback makes sense}, which also shows that $F^*\Gamma$ is the smallest $\sigma$-algebra for which $F$ is measurable.
\end{subsec}

\begin{exercise}
Show that measurable spaces with measurable maps form a category.
\end{exercise}

\begin{exercise}
\label{arc length exercise}
By an \dfn{arc} we mean a compact connected subset of $\Torus$.
Recall the definition of the length of an arc from calculus.
Show that the length of an arc equals its Lebesgue measure.
\end{exercise}

\begin{exercise}
\label{Lebesgue measure on sphere}
Let $S^d$ denote the unit sphere in $\RR^{d+1}$, and let $N$ be its open northern hemisphere.
Let $U$ be the open unit ball in $\RR^d$, so $U \times \{0\}$ is a subset of the unit ball of $\RR^{d+1}$.
Show that the map $p: N \to \RR^{d+1}$, $p(x_1, \dots, x_{d+1}) = (x_1, \dots, x_d, 0)$, is a homeomorphism between $N$ and $U \times \{0\}$.
So the pushforward of Lebesgue measure on $\RR^d$ by $p^{-1}$ gives a Borel measure on $N$, which we call \dfn{Lebesgue measure} on $N$.
Use this fact to define Lebesgue measure of any Borel subset of $S^d$.
Show that when $d = 2$, Lebesgue measure on $S^d$ agrees with the usual notion of surface area, up to a constant factor.
\end{exercise}

\begin{exercise}
\label{pullback makes sense}
Let $F: X \to Y$ be a map, $\Gamma$ a $\sigma$-algebra on $Y$.
Show that $F^*\Gamma$ is a $\sigma$-algebra on $X$ and $F: (X, F^*\Gamma) \to (Y, \Gamma)$ is measurable.
Conversely, show that $F^*\Gamma$ is the intersection of all $\sigma$-algebras $\Sigma$ on $X$ such that $F: (X, \Sigma) \to (Y, \Gamma)$ is measurable.
\end{exercise}

\section{Vector-valued measures}
Recall that by definition, a measure $\mu$ is a $\sigma$-additive function $\mu: \Sigma \to (-\infty, \infty]$, where $\Sigma$ is a $\sigma$-algebra.
However, the definition of $\sigma$-additive function makes sense even if $(-\infty, \infty]$ is replaced by a more general codomain, and we will have use for this when we integrate functions in more general codomains than the real numbers.

\begin{subsec}
Let $B$ be a Banach space, as discussed in Appendix \ref{Banach space appendix}.
If the reader is unfamiliar with Banach spaces, they can take $B = \CC^d$ and not lose any insight.
If $(x_n)$ is a sequence in $B$, then (\ref{banach space series}) is the definition of the infinite sum $\sum_n x_n$.
\end{subsec}

\begin{definition}
Let $\Sigma$ be a $\sigma$-ring and $B$ a Banach space.
A \dfn{vector-valued measure} on $\Sigma$, or simply a \dfn{measure}, is a function $\mu: \Sigma \to B$ such that whenever $(E_n)$ are countably many disjoint sets in $\Sigma$,
$$\mu\left(\bigcup_n E_n\right) = \sum_n \mu(E_n).$$
\end{definition}

\begin{example}
The most important examples of vector-valued measures will be of the following form.
Let $\nu$ be a positive measure on a measurable space $X$, and let $f: X \to B$ be an ``integrable function".
We will get back to what this means later -- but, taking the definition of integration as a black box, set
$$\mu(E) = \int_E f(x) ~d\nu(x).$$
Then $\mu$ is a vector-valued measure, and its ``derivative" is $f$.
This will be the setting in which we generalize the fundamental theorem of calculus.
\end{example}

\begin{subsec}
Frequently, positive measures are easier to work with than vector-valued measures, so we will mainly spend this section developing tools to convert problems about vector-valued measures into problems about positive measures.
\end{subsec}

\begin{definition}
Let $\mu$ be a measure. The \dfn{total variation measure} $|\mu|$ of $\mu$ is defined by
$$|\mu|(E) = \sup_{E_1, \dots, E_n} \sum_{i=1}^n ||\mu(E_i)||_B$$
where the supremum ranges over finite sequences $E_1, \dots, E_n$ of disjoint measurable sets such that $E = \bigcup_i E_i$.
\end{definition}

\begin{theorem}
Every total variation measure is a positive measure.
\end{theorem}
\begin{proof}
Let $\mu$ be a measure. Then $|\mu|$ is nonnegative. If $E \subseteq F$ are measurable sets, write $F = E \cup (F \setminus E)$ to see that $|\mu|(E) \leq |\mu|(F)$.

To see that $|\mu|$ is $\sigma$-additive, suppose that $F,G$ are disjoint measurable sets, $E = F \cup G$.
Write $F = \bigcup_{i \leq m} F_i$ and $G = \bigcup_{j \leq n} G_j$ where the $F_i,G_j$ are all disjoint; then
$$|\mu|(E) \geq \sum_{i=1}^m ||\mu(F_i)||_B + \sum_{j=1}^n ||\mu(G_j)||_B.$$
Thus $|\mu|(E) \geq |\mu|(F) + |\mu|(G)$, so by induction if $E = \bigcup_{i \leq m} E_i$ where the $E_i$ are disjoint, then $|\mu|(E) \geq \sum_{i \leq m} |\mu|(E_i)$.
Using the monotonicity, it follows that if $(E_i)$ is a disjoint countable sequence of sets and $E = \bigcup_i E_i$, then
$$|\mu|(E) \geq \sum_{i=1}^\infty |\mu|(E_i).$$

Conversely, suppose that $E = \bigcup_j E_j = \bigcup_{i\leq n} F_i$ where $(E_j)$ is a disjoint countable sequence and $(F_i)$ is a disjoint finite sequence. Then
\begin{align*}
\sum_{i=1}^n ||\mu(F_i)||_B &= \sum_{i=1}^n \left|\left|\mu\left(\bigcup_{j=1}^\infty \left(F_i \cap E_j\right)\right)\right|\right|_B \leq \sum_{i=1}^n \sum_{j=1}^\infty ||\mu(F_i \cap E_j)||_B \\
&= \sum_{j=1}^\infty \sum_{i=1}^n ||\mu(F_i \cap E_j)||_B \leq \sum_{j=1}^\infty |\mu|(E_j).
\end{align*}
Here we used the fact that $E_j = \bigcup_{i \leq n} F_i \cap E_j$. It follows that $|\mu|(E) \leq \sum_{i=1}^\infty |\mu|(E_i)$.
\end{proof}

\begin{theorem}[triangle inequality and reverse triangle inequality]
\label{reverse triangle inequality}
Let $\mu,\nu$ be measures on $\Sigma$ with values in $B$. Then $|\mu + \nu| \leq |\mu| + |\nu|$ and
$$||\mu|(E) - |\nu|(E)| \leq |\mu - \nu|(E).$$
\end{theorem}
\begin{proof}
If $E = \bigcup_{i \leq n} E_i$, the $E_i$ disjoint, then
$$\sum_{i=1}^n ||(\mu + \nu)(E_i)||_B \leq \sum_{i=1}^n ||\mu(E_i)||_B + ||\nu(E_i)||_B \leq |\mu|(E) + |\nu|(E)$$
which implies the two desired inequalities.
\end{proof}

\begin{subsec}
Let $\mu$ be a vector-valued measure.
The total variation measure $|\mu|$ can be viewed as the positive measure that ``best dominates" $||\mu||_B$ in the sense that for every measurable set $E$, $|\mu(E)| \geq ||\mu(E)||_B$.
On the other hand, if $\mu$ is already a positive measure, then the definition of the total variation measure $|\mu|$ still makes sense, and additivity of $\mu$ implies that $\mu = |\mu|$.
Thus we can use total variation to extend definitions of measures to this more general setting.
\end{subsec}

\begin{definition}
A vector-valued measure $\mu$ is \dfn{$\sigma$-finite} if $|\mu|$ is $\sigma$-finite.
A set $E$ is \dfn{$\mu$-null} if $E$ is $|\mu|(E)$-null.
The measure $\mu$ is a \dfn{complete measure} if every $\mu$-null set is complete.
The \dfn{completion} of $\mu$ is the vector-valued measure obtained by extending the domain of $\mu$ to contain all $\mu$-null sets.
\end{definition}

\begin{exercise}
Show that the completion of a vector-valued measure is well-defined.
That is, if $(X, \Gamma)$ is a measurable space and $\mu$ is a vector-valued measure on $\Gamma$, then show that there is a $\sigma$-algebra $\Sigma$ on $X$ which contains every measurable set and every $\mu$-null set, such that $(X, \Sigma, \mu)$ is a complete measured space.
\end{exercise}

\begin{exercise}
Give an example of a vector-valued measured space $(X, \mu)$ such that $\mu(X) = 0$, but $|\mu|$ is not identically zero.
Thus, explain why we cannot define a $\mu$-null set to simply be a set $E$ such that $\mu(E) = 0$.
\end{exercise}


\section{Probability}
In 1933, Andrey Kolmogorov put probability theory -- which was long viewed as not part of rigorous mathematics -- on a sound footing by establishing three axioms that probability theory ought to satisfy.
These axioms, however, are exactly the definition of a probability measure!
Thus measure theory is an invaluable tool in applied mathematics, such as statistics.
However, even the myopic reader who only cares about pure, abstract mathematics will find probability useful to their work.

In this section we do little more than develop a language, but in later sections we will find a great use for it.

\begin{definition}
A \dfn{probability space} $(\Omega, \Sigma, P)$ is a measure space with $P(\Omega) = 1$.
Elements of $\Sigma$ are called \dfn{events} and elements of $X$ are called \dfn{outcomes}.
The quantity $P(A)$, where $A$ is an event, is called the \dfn{probability} that $A$ is true.
\end{definition}

\begin{subsec}
The intuition here is that the events form an algebra $\Sigma$ of statements that could be true or false about the world, with varying probabilities.
By an algebra of statements, more precisely, one means that it is meaningful to conjoin them using grammar: $A \cup B$ is the event that $A$ happens or $B$ happens, while $A \cap B$ is the probability that both $A$ happens and $B$ happens. The event $\Omega \setminus A$ is the probability that $A$ does not happen, and so on.
The event $\Omega$ is vacuously true; it represents the statement ``$2 + 2 = 4$".
The event $\emptyset$, on the other hand, is vacuously false; it represents the statement ``$2 + 2 = 5$".
Thus probability theory sits somewhere between analysis and logic in the world of mathematics, and the language used in the following definition is motivated.
\end{subsec}

\begin{definition}
Let $(\Omega, \Sigma, P)$ be a probability space.

The event $A \cup B$ is called $A$ \dfn{or} $B$, or the \dfn{disjunction} of $A,B$, and the event $A \cap B$ is called $A$ \dfn{and} $B$, or the \dfn{conjunction} of $A,B$.
The event $\Omega \setminus A$ is called \dfn{not} $A$, or the \dfn{negation} of $A$.

The event $\Omega$ is said to be \dfn{true}, and the negation $\emptyset$ of true is said to be \dfn{false}.
An event $A$ is said to be \dfn{almost surely true} if $P(A) = 1$, and \dfn{almost surely false} if $P(A) = 0$.

A set $\Sigma_0 \subseteq \Sigma$ of events is said to be \dfn{mutually exclusive} if for every $A, B \in \Sigma_0$, $A \cap B$ is almost surely false.
\end{definition}

\begin{subsec}
The $\sigma$-additivity of the measure $P$ says that if a countable set $\Sigma_0$ of events is mutually exclusive, its disjunction $A$ satisfies
$$P(A) = \sum_{B \in \Sigma_0} P(B),$$
thus for example we have the \dfn{inclusion-exclusion formula}
$$P(E \cup F) = P(E) + P(F) - P(E \cup F)$$
valid for any two events $E,F$ familiar from elementary probability theory.
\end{subsec}

\begin{subsec}
So far we have only discussed events. But what role do outcomes play?
Outcomes are ``microstates" and each outcome carries all possible information about a particular state that the universe could be -- the position and momentum of every last molecule, the value of every card in every player's hand.
But we are just puny mortal observers of the universe; we cannot possibly have access to all that information!
So outcomes are not terribly useful, and one generally avoids ever mentioning outcomes directly.
What we mortal observers can observe are random variables.
\end{subsec}

\begin{definition}
Let $(\Omega, P)$ be a probability space and $E$ be a measurable space.
A \dfn{random variable} of \dfn{type} $E$, also known as an \dfn{observable} of type $E$, is a measurable map $\Omega \to E$.
\end{definition}

\begin{subsec}
The points of the space $E$ represent possible values that an experiment can return.
The random variable $X: \Omega \to E$ represents an experiment. If $\omega$ is an outcome, $X(\omega)$ is the result of the experiment $X$ if the universe is in state $\omega$.
One generally takes $E = \RR$ with its Borel $\sigma$-algebra, since most experiments return numerical data, but there are other examples of useful types $E$; for example, points of $E$ are often sequences, vectors, or graphs.
If the type of $X$ is clear -- especially if it is $\RR$ -- we will suppress it.
\end{subsec}

\begin{subsec}
Let $X$ be a random variable (of type $\RR$).
The sets $[x, \infty)$ are Borel, so the sets $\{X \geq x\} = \{\omega \in \Omega: X(\omega) \geq x\}$ are actually events.
The probability of the event $\{X \geq x\}$ is frequently of interest, so we make the following definition.
\end{subsec}

\begin{definition}
Let $X$ be a random variable of type $E$.
The \dfn{distribution} $\mu_X$ of $X$ is the pushforward $X_*P$ of $P$ on $E$.
If $Y$ is another random variable and $\mu_X = \mu_Y$, we say that $X,Y$ are \dfn{identically distributed}.
\end{definition}

\begin{subsec}
Unraveling the definitions, if $A \subseteq E$ is a measurable set,
$$\mu_X(A) = P(X \in A) = P(\{\omega \in \Omega: X(\omega) \in A\}).$$
For example, if $E = \RR$ then $\mu_X([x, \infty))$ is the probability that $X \geq x$.
We think of two identically distributed random variables as being isomorphic, but not the same.
\end{subsec}

\begin{subsec}
Recall that in elementary probability theory two events $A,B$ are said to be independent if $P(A) = P(A|B)$, where $P(A|B)$ (``the probability of $A$ given $B$") is by definition $P(A \cap B)/P(B)$.
The intuition is that if we know that $B$ is true, then we want to restrict to subsets of $B$ and rescale the probability measure $P$ so that $B$ is almost surely true.
However, if $A$ and $B$ really have nothing to do with each other, the probability of $A$ given $B$ is just the probability of $A$.
We can write this in a more symmetrical form, which also avoids the issue of division by zero, as in the following definition.
\end{subsec}

\begin{definition}
Let $(\Omega, \Sigma, P)$ be a probability space and $(E, \Gamma)$ a measurable space.

Countably many events $A_n \in \Sigma$ are said to be \dfn{independent} if
$$P\left(\bigcap_n A_n\right) = \prod_n P(A_n).$$
Countably many $\sigma$-algebras $\mathcal A_n \subseteq \Sigma$ are said to be \dfn{independent} if for every $A_n \in \mathcal A_n$, the events $A_n$ are independent.
Countably many random variables $X_n$ of type $E$ are said to be \dfn{independent} if the pullback $\sigma$-algebras $X_n^*\Gamma$ are independent.

Random variables $X,Y$ are said to be \dfn{iid} if they are independent and identically distributed.
\end{definition}

\begin{subsec}
The idea in the definition of independent random variables is that the pullback $\sigma$-algebra $X^*\Gamma$ is the set of events that can be checked as true or false by measuring $X$.
\end{subsec}

\begin{example}
Suppose that I am playing a game of cards.
Every time I draw a card, I put it back in the deck and then shuffle again.
Let $X_n$ be $1$ if I draw the queen of hearts on turn $n$, and $0$ otherwise.
Then the distribution of $X_n$ is $(51/52)\delta_0 + (1/52)\delta_1$, where $\delta_x$ is the Dirac measure at $x$.
Since I shuffle between turns, the $X_n$ are independent.
So the $X_n$ are iid.
\end{example}

\begin{exercise}
Verify the inclusion-exclusion formula
$$P\left(\bigcup_{i=1}^n A_i\right) = \sum_{k=1}^n (-1)^{k+1} \sum{1 \leq i_1 < \cdots < i_k \leq n} P\left(\bigcap_{j=1}^k A_{i_j}\right)$$
valid for any events $A_1, \dots, A_n$.
\end{exercise}

\begin{exercise}[Skohorod representation]
\label{Skohorod representation}
Let $\mu$ be a Borel probability measure on $\RR$.
Show that there is a probability space $\Omega$ and a random variable $X: \Omega \to \RR$ of distribution $\mu$.
\end{exercise}

\begin{exercise}
Let $X_n$ be random variables and suppose that for every $x \in \RR$, the events $X_n \geq x$ are independent.
Show that the $X_n$ are independent random variables.
\end{exercise}

\begin{exercise}
Let $X_n$ be independent random variables of type $E$.
Suppose that $f_n: E \to E$ are measurable maps.
Show that the $f_n(X_n)$ are still independent.
\end{exercise}

\begin{exercise}
Let $X, Y: \Omega \to E$ be random variables.
A \dfn{morphism of random variables} $X \to Y$ is a measure-preserving map $F: \Omega \to \Omega$ such that $Y \circ F = X$.
Two morphisms $F,G$ are \dfn{equal almost surely} if $P(F = G) = 1$.
Two random variables $X,Y$ are \dfn{isomorphic} if there are morphisms $F: X \to Y$ and $G: Y \to X$ such that $F \circ G$ and $G \circ F$ are the identity almost surely (so $G$ is almost surely the inverse of $F$).

Show that being equal almost surely is an equivalence relation on the set of morphisms of random variables.
Show that random variables $\Omega \to E$ and morphisms between them, modulo the equivalence relation of being equal almost surely, form a category.
Show that two random variables are isomorphic iff they are identically distributed.
\end{exercise}

\section{Ergodic systems}
This section is used nowhere else in this book, except in some exercises; it is meant to showcase an application.

Measure-preserving maps from a measured space to itself are important in probability and thermodynamics; their study is known as \dfn{ergodic theory}.

\begin{definition}
A \dfn{measure-preserving system} $(X, \Sigma, P, f)$ consists of a probability space $(X, \Sigma, P)$ and a measure-preserving map $f: X \to X$.
\end{definition}

\begin{subsec}
We may suppress $X$ or $\Sigma$ from the notation when they are clear or unhelpful to specify.
\end{subsec}

\begin{subsec}
The intuition for measure-preserving systems is as follows.
We have a probability space $X$ whose events $A$ are properties that the world could have, and the probability $P(A)$ is the probability that the world is in that state.
The map $f$ represents the passing of time; each application of $f$ represents the passing of a unit of time.
However, the probability that the universe has property $A$ is the same today as it is tomorrow.
\end{subsec}

\begin{definition}
An \dfn{ergodic system} is a measure-preserving system $(X, \Sigma, P, f)$ for which, whenever $f(A) \subseteq A$ and $A \in \Sigma$, then $P(A) = 0$ or $P(A) = 1$.
\end{definition}

\begin{subsec}
Ergodic systems are the most important examples of measure-preserving systems.
The reason is that ergodic systems behave ``randomly".
In an ergodic system, the universe might have property $A$ today, but this is no evidence that the universe will have property $A$ tomorrow, because every day all the properties that the universe could have get completely mixed up every time $f$ is applied.

Let $(X, P, f)$ be an ergodic system.
Imagine that $X$ is an egg; then $P$ represents picking a random point inside the egg, and $f$ represents the action of scrambling the egg, say with chopsticks.
Though $X$ is initially in an orderly state, the ergodicity of the system means that all this order is lost and all the points of $X$ get mixed up.
This is illustrated mathematically by the following example.
\end{subsec}

\begin{example}
One ergodic system is known as the \dfn{irrational rotation}.
Let $\theta \in [0, 2\pi]$ and suppose that $\theta/\pi$ is irrational.
Then the map $f(z) = e^{i\theta}z$ on the circle $\Torus$, which rotates the circle by $\theta$, defines an ergodic system $(\Torus, \mu, f)$, where $\mu$ is Lebesgue measure.
The reader who is familiar with some Fourier analysis may show this in Exercise \ref{irrational rotation exercise}.
\end{example}

\begin{subsec}
As a sample of the power of ergodic theory, let us prove the following theorem that ``breaks the laws of thermodynamics".
If $(X, f)$ is a measure-preserving system and $x \in X$, we let $f^n(x)$ denote $f \circ \cdots \circ f$, where there are $n$ copies of $f$.
The theorem is due to Carath√©odory, which is naturally why it is named after Poincar\'e.
\end{subsec}

\begin{theorem}[Poincar\'e recurrence]
Let $(X, \Sigma, P, f)$ be a measure-preserving system.
For every $A \in \Sigma$, define $A^\flat = \{x \in A: \forall n~f^n(x) \notin A\}$.
Then $P(A^\flat) = 0$.
\end{theorem}
\begin{proof}
We first note that
$$A^\flat = A \setminus \bigcup_{n \in \NN} f^n(A)$$
which is measurable since each of the $f^n(A)$ are.

If $m > n$, then $f^n(A^\flat) \cap f^m(A^\flat)$ is empty: if $x \in f^m(A^\flat)$, so that $f^{-m}(x) \in A^\flat$, then by definition of $A^\flat$,
$$f^{-n}(x) = f^{m-n}(f^{-m}(x)) \notin A.$$

Therefore, for any $N \in \NN$,
$$P(A^\flat) = \frac{1}{N} \sum_{n=1}^N P(f^m(A^\flat)) = \frac{1}{N} P\left(\bigcup_{n=1}^N f^m(A^\flat)\right) \leq \frac{1}{N} P(X) = \frac{1}{N}.$$
So $P(A^\flat) = 0$.
\end{proof}

\begin{subsec}
Let us explain to the reader who is familiar with thermodynamics how to interpret this theorem.

Let $X$ be the set of microstates that the universe can be in and let us assume for simplicity that $X$ is finite.
Let $P$ be the normalized counting measure, so that
$$P(A) = \frac{\card A}{\card X}$$
and $\Sigma = 2^X$.
Thus $P(A)$ represents the probability of drawing a partiular microstate uniformly at random.

Let $f: X \to X$ be the map that sends the state of the universe right now to the state of the universe one second into the future.
We can think of sets $A$ as macrostates, where $x \in A$ iff $x$ is consistent with $A$.
By Poincar\'e recurrence, if the universe is currently in macrostate $A$, then there is an $N$ such that $N$ seconds into the future, the universe will again be in macrostate $A$.
In particular, the entropy of the universe will return to what it currently is, apparently contradicting the second law of thermodynamics.
This is no contradiction, however, because $N$ is much larger than the lifespan of the universe.
\end{subsec}

\begin{subsec}
We will not discuss ergodic systems much, but ergodic theory is a crucial application of measure theory.
For example, it can be used to prove the strong law of large numbers from probability, and actually very powerful generalizations thereof.
We refer the reader to TODO:Cite Couden's book to learn about ergodic theory.
\end{subsec}

\begin{exercise}
Show that Poincar\'e recurrence fails for infinite measure spaces by giving a counterexample.
\end{exercise}

\begin{exercise}
\label{irrational rotation exercise}
Show that the irrational rotation with Lebesgue measure forms an ergodic system.
(Hint: Let $A$ be a subset of the circle which the irrational rotation sends into itself. Consider the Fourier series of $1_A$. You are allowed to assume basic facts about Fourier series.)
\end{exercise}


\chapter{Measurable functions}
Throughout this chapter, let $(X, \Sigma)$ be a measurable space and let $B$ be a Banach space.
We would like to consider functions $f: X \to B$ which ``respect" $\Sigma$. Then, given a measure $\mu$ defined on $\Sigma$, we will be able to define the integral $\int_X f~d\mu$ of $f$ with respect to $\mu$.

\section{Simple functions}
When we prove a theorem $T$ about functions in measure theory, we want to follow the following template:
\begin{enumerate}
\item Let $\mathcal F$ be the set of functions for which $T$ is true. Show that $\mathcal F$ contains all functions which are ``sufficiently simple."
\item Show that $\mathcal F$ is closed under linear combination, so is a vector space.
\item Show that $\mathcal F$ is closed under taking limits of appropriate type.
\item Conclude that every appropriate function lies in $\mathcal F$.
\end{enumerate}
In this section we treat the ``sufficiently simple" functions.

\begin{definition}
A \dfn{simple function} is a function $f: X \to B$ such that the image of $f$ is finite, and for every $b$ in the image of $f$, $f^{-1}(b)$ is a measurable set.
The set of simple functions is denoted $\Simp(X \to B)$.
\end{definition}

\begin{subsec}
The simple functions have a particularly convenient canonical form.
To define them, we first characterize the $\RR$-valued simple functions.
\end{subsec}

\begin{definition}
Let $Y \subseteq X$ be a measurable set. The \dfn{indicator function} of $Y$, denoted $1_Y$, is the function $X \to \{0, 1\}$, defined by $1_Y(y) = 1$ if $y \in Y$ and $1_Y(y) = 0$ if $y \notin Y$.
\end{definition}

\begin{subsec}
Note that every indicator function is simple, since its image is $\{0, 1\}$, the preimage of $0$ is $Y^c$, the preimage of $1$ is $Y$, and $Y,Y^c$ are both measurable.
Conversely, if $f \in \Simp(X \to \CC)$, $f$ is a linear combination of indicator functions. In fact, if $\{y_1, \dots, y_n\}$ is the image of $f$, and the preimage of $y_i$ is $Y_i$, then
$$f(x) = \sum_{i=1}^n y_i1_{Y_i}(x).$$
Indeed, the $Y_i$ are disjoint since they are preimages of distinct real numbers, so $y_i1_{Y_i}(x) = y_i$ iff $f(x) = y_i$, and $f(x) = 0$ otherwise.
This characterization also works for $B$-valued simple functions: if $\{b_1, \dots, b_n\}$ is the image of $f$, and the preimage of $b_i$ is $Y_i$, then
$$f(x) = \sum_{i=1}^n b_i1_{Y_i}(x).$$
\end{subsec}

\begin{subsec}
We now show that $\Simp(X \to B)$ is closed under various operations.
\end{subsec}

\begin{definition}
A vector space $A$ over $\CC$ is called an \dfn{algebra} if it is equipped with a multiplication $A \times A \to A$ which is associative, distributes over addition, and satisfies, for every $c,d \in \CC$ and $x,y \in A$,
$$(cx)(dy) = (cd)(xy).$$
If the multiplication of $A$ has an identity, we call the identity $1$ and call $A$ a \dfn{unital algebra}.
\end{definition}

\begin{subsec}
In particular, a collection of functions is an algebra iff it is closed under multiplication.
See Exercise \ref{algebra review}.
\end{subsec}

\begin{lemma}
\label{Simp is an algebra}
$\Simp(X \to B)$ is a vector space. In particular, $\Simp(X \to \CC)$ is a unital algebra.
\end{lemma}
\begin{proof}
Let $f, g \in \Simp(X \to B)$, say
$$f(x) = \sum_{i=1}^n y_i1_{Y_i}(x)$$
and
$$g(x) = \sum_{j=1}^m z_j1_{Z_j}(x).$$
We first claim that $f + g$ is simple. In fact, the image of $f + g$ is contained in $\{y_i + z_j: 1 \leq i \leq n, ~1 \leq j \leq m\}$, and the preimage of $y_i + z_j$ under $f + g$ is $Y_i \cap Z_j$.

The proof that $\Simp(X \to B)$ is closed under scaling is similar. Clearly $\Simp(X \to B)$ is nonempty, so this implies that $\Simp(X \to B)$ is a vector space.

Now if $B = \CC$, function multiplication is defined, and
$$fg(x) = \sum_{i=1}^n y_i1_{Y_i}(x)\sum_{j=1}^m z_j1_{Z_j}(x) = \sum_{i,j} y_iz_j 1_{Y_i \cap Z_j}(x).$$
Therefore $fg$ is simple.
Moreover, the function $f(x) = 1$ is an identity for multiplication.
\end{proof}

\begin{lemma}
\label{Simp is closed under minmax}
Let $f, g \in \Simp(X \to \CC)$. Then $|f| \in \Simp(X \to \CC)$. In fact, if $f, g \in \Simp(X \to \RR)$, then $\max(f, g) \in \Simp(X \to \RR)$ and $\min(f, g) \in \Simp(X \to \RR)$.

Moreover, if $f \in \Simp(X \to B)$, the function $x \mapsto ||f(x)||$ is in $\Simp(X \to \CC)$.
\end{lemma}
\begin{proof}
Left as Exercise \ref{Simp closure exer}.
\end{proof}

\begin{exercise}
\label{algebra review}
Look up or prove the following algebraic theorems:
\begin{enumerate}
\item Let $\varphi: \CC \to A$ be a morphism of rings. Then $A$ is an algebra, where scalar multiplication is defined by $za = \varphi(z)a$, for any $z \in \CC$ and $a \in A$. We call $\varphi$ the \dfn{canonical inclusion} of $\CC$ into $A$.
\item If $A$ is a unital algebra with multiplicative identity $1_A$, then the map $\varphi(z) = 1_Az$, $\varphi: \CC \to A$, is a morphism of rings, and is in fact the canonical inclusion of $\CC$ into $A$.
\item If $V$ is a vector space of functions $X \to \CC$, then $V$ is an algebra over $\CC$ iff $V$ is closed under function multiplication.
\end{enumerate}
None of these theorems actually require that we are working over $\CC$; they are valid if $\CC$ is replaced with any field.
However, you are not expected to check that.
\end{exercise}

\begin{exercise}
\label{Simp closure exer}
Prove Lemma \ref{Simp is closed under minmax}.
\end{exercise}

\begin{exercise}
\label{Borel-Cantelli}
If $(A_n)_n$ is a sequence of measurable sets, we define $\limsup_{n \to \infty} A_n$ by the relation
$$1_{\limsup_{n \to \infty} A_n} = \limsup_{n \to \infty} 1_{A_n}.$$
Then:
\begin{enumerate}
\item Show that $\limsup_{n \to \infty} A_n$ is a well-defined measurable set.
\item Show that $x \in \limsup_{n \to \infty} A_n$ iff there are infinitely many $n \in \NN$ such that $x \in A_n$.
\item Prove the \dfn{Borel-Cantelli lemma}: If $\mu$ is a nonnegative measure on $X$ such that
$$\sum_{n=1}^\infty \mu(A_n) < \infty,$$
then $\limsup_{n \to \infty} A_n$ is $\mu$-null.
\end{enumerate}
The Borel-Cantelli lemma is a primitive example of a ``zero-one law", a theorem that implies that certain sets must either be null or have null complement.
\end{exercise}

\begin{exercise}
Given $x \in [0, 1)$, we may assign $x$ a canonical decimal expansion by not letting $x$ have a decimal expansion that ends with an infinitely repeating string of nines.
We let $x_j \in \{0, \dots, 9\}$ denote the $j$th entry in the canonical decimal expansion of $x$ (so for example $(\pi - 3)_3 = 1$).
Let us say that $x$ has \dfn{uniform expansion} at $n \in \NN$ if for every $d \in \{0, \dots, 9\}$, the set of $j \in \{1, \dots, 10n\}$ such that $x_j = d$ has cardinality $n$.
In other words, $x$ has uniform expansion at $n$ iff for every $d \in \{0, \dots, 9\}$ the probability that a $j \in \{1, \dots, 10n\}$ drawn uniformly at random satisfies $x_j = d$ is $1/10$.

Let $A$ be the set of $x \in [0, 1)$ such that there are infinitely many $n \in \NN$ such that $x$ has uniform expansion at $n$.
Show that $A$ is a Borel set, and that $A$ is Lebesgue null. (Hint: Use the Borel-Cantelli lemma, Exercise \ref{Borel-Cantelli}).)
\end{exercise}



\section{Measurable functions}
We want to know which functions $X \to B$ are ``good" from the perspective of measure theory. To accomplish this, recall the notion of pointwise convergence.

\begin{definition}
A sequence of functions $f_n: X \to B$ is said to \dfn{converge pointwise} to a function $f$ if for every $x \in X$,
$$f(x) = \lim_{n \to \infty} f_n(x).$$
\end{definition}

\begin{subsec}
Let $\mu$ be a complete measure on $\Sigma$.
If $\mu$ is not already complete, we can always expand $\Sigma$ by adjoining the $\mu$-null sets to $\Sigma$, so this assumption is no loss in generality.
\end{subsec}

\begin{subsec}
In measure theory, a property is said to hold \dfn{almost everywhere} if it holds everywhere except a null set, and hold \dfn{almost nowhere} if it only holds on a null set.
We will refer to measurable functions whose definition only makes sense almost everywhere as if they were defined on all of $X$.
\end{subsec}

\begin{example}
Let $\mu$ be Lebsegue measure on $\RR$ and $f(x) = 1/x$.
Then $f(0)$ is not defined, but $\{0\}$ is a $\mu$-null set.
So we can view $f$ as a function $\RR \to \CC$, even though it is only defined almost everywhere.
\end{example}

\begin{subsec}
Because $\mu$-null sets are not very important, we want to view two functions that are equal almost everywhere as actually being the same function, modulo ``measurement error".
For example, if $u(x)$ denotes the temperature in the air at a point $x \in \RR^3$ measured by some thermometer, and we measure that $u(x) = 0$ at every $x$ close to $0$, but $u(0) = 1$, then we must have made an error in the measurement of $u(0)$, and might as well view this measurement $u$ as ``the same as" the measurement of temperature which is identically $0$ in a neighborhood of $0$.
\end{subsec}

\begin{definition}
\label{almost converge dfn}
Let $\mu$ be a measure on $\Sigma$. A sequence of functions $f_n: X \to B$ is said to \dfn{converge pointwise almost everywhere} with respect to $\mu$, or simply \dfn{almost converge}, to a function $f: X \to B$ if there is a null set $Z$ such that on $X \setminus Z$, $f_n \to f$ pointwise. In this case, we write
$$f = \lim_{n \to \infty} f_n,$$
noting that the limit is meant almost everywhere if unclear from context.
\end{definition}

\begin{subsec}
Note that in Definition \ref{almost converge dfn}, we allow the functions $f_n$, or their limit $f$, to be undefined on a null set, which is then viewed as a subset of the bad set $Z$ where the $f_n$ may not converge to $f$.
\end{subsec}

\begin{example}
Any sequence of functions which converges pointwise almost converges.
As an example of a sequence of functions which almost converges but doesn't converge pointwise, let $f_n(x) = x^n$, $X = [0, 1]$. Then $f_n \to 0$ everywhere except $1$, so $f_n \to 0$ almost everywhere with respect to Lebesgue measure.
\end{example}

\begin{definition}
A \dfn{measurable function} $f: X \to B$ is a function such that there is a sequence $f_n \in \Simp(X \to B)$ such that $f_n \to f$ almost everywhere.
Let $\mathcal M(X \to B)$ denote the set of measurable functions.
\end{definition}

\begin{subsec}
The notation $\mathcal M(X \to B)$ will make more sense when we define the $L^p$-spaces later on.
We will abuse notation and write $\mathcal M$ if $X,B$ are clear from context, and may also write something like $\mathcal M(X \to B, \mu)$ if $\mu$ is not clear from context.
\end{subsec}

\begin{lemma}
$\mathcal M(X \to B)$ is a vector space.
In particular, $\mathcal M(X \to \CC)$ is an algebra such that if $f, g \in \mathcal M(X \to \CC)$, then so are $\max(f,g)$, $\min(f,g)$, and $|f|$.
Moreover, if $f \in \mathcal M(X \to B)$, then $x \mapsto ||f(x)||$ is in $\mathcal M(X \to \CC)$.
\end{lemma}
\begin{proof}
Let $f,g \in \mathcal M(X \to B)$, and suppose that $f_n \in \Simp(X \to B)$, $f_n \to f$. Similarly let $g_n \to g$, $g_n \in \Simp(X \to B)$.
Then $f_n + g_n \in \Simp(X \to B)$ by Lemma \ref{Simp is an algebra} and $f_n + g_n \to f + g$.

We leave the other claims as an exercise for the reader.
\end{proof}

\begin{subsec}
Let $N$ be the set of all functions $f$ which are zero almost everywhere, thus there is a null set $Z$ such that on $X \setminus Z$, $f = 0$.
\end{subsec}

\begin{lemma}
The set $N$ of functions that are zero almost everywhere is a vector subspace of $\mathcal M(X \to B)$.
\end{lemma}
\begin{proof}
Let $f \in N$, and suppose that $Z$ is the set where $f$ is nonzero.
We first claim that $f$ is measurable; in fact, the sequence $f_n = 0$ converges to $f$ pointwise except on $Z$, hence almost everywhere.

Now if $g \in N$, and $g$ is nonzero on a set $W$, then $f + g$ is nonzero on a subset of the null set $Z \cup W$; since $\mu$ is complete, any subset of $Z \cup W$ is null. The argument for scalars is similar. Clearly $0 \in N$ so $N$ is nonempty.
\end{proof}

\begin{subsec}
Whenever $W$ is a vector subspace of a vector space $V$, we may form its quotient space $V/W$ of equivalence classes, where two elements $f, g \in V$ are viewed as equivalent if $f - g \in W$.
In particular, if we take the quotient $\mathcal M(X \to B)/N$, two functions $f,g$ are equivalent iff $f - g$ is zero almost everywhere.
\end{subsec}

\begin{definition}
Let $N$ be the space of all functions that are zero almost everywhere is a vector subspace. We denote its quotient space
$$M(X \to B) = \frac{\mathcal M(X \to B)}{N}.$$
We will abuse terminology and refer to equivalence classes $f \in M(X \to B)$ as ``functions", and a representative of an equivalence class $f$ as a \dfn{version} of $f$.
\end{definition}

\begin{subsec}
Again, we may write $M(X \to B, \mu)$ and similar notations to mean $M(X \to B)$.
In general, we will want to work with $M$ whenever possible rather than $\mathcal M$.
\end{subsec}

\begin{exercise}
Let $\mu$ be a probability measure on a measurable space $X$.
Let $(f_n)_n$ be a sequence of measurable functions on $(X, \mu)$, and $f$ a measurable function on $(X, \mu)$.
Assume that for every $\varepsilon > 0$, one has
$$\sum_{n=1}^\infty \mu(\{x \in X: ||f_n(x) - f(x)|| > \varepsilon\}) < \infty.$$
Show that $f_n \to f$ almost everywhere.

This characterization is highly useful in probability, where one is typically not able to refer directly to elements of $X$, but only measurable sets, but still wants to be able to discuss convergence almost everywhere.
(Hint: Use the Borel-Cantelli lemma, Exercise \ref{Borel-Cantelli}).)
\end{exercise}



\section{Characterizing measurable functions}
The current definition of $M$ is unwieldly. Its elements are equivalence classes of functions, themselves defined to be the limits of simple functions, whose definition was natural but already little long.
Here we give another characterization of measurability that is somewhat easier to work with, and will readily imply that every function that is relevant to analysis is measurable.

\begin{subsec}
Throughout, we as usual fix a complete measured space $(X, \Sigma, \mu)$ and a Banach space $B$.
\end{subsec}

\begin{definition}
\label{almost separably valued dfn}
A function $f: X \to B$ is \dfn{almost separably valued} if there is a null set $Z$ such that $f(X \setminus Z)$ is separable in the topology of $B$.
\end{definition}

\begin{subsec}
Being almost separably valued is a good condition. It means that, modulo a harmless null set, the image of $f$ consists of points which can be approximated by points that lie in a countable set $C$; and elements of $C$ then are likely to admit finitary descriptions.
Think of how difficult $\RR$ would be to work with if we did not have $\QQ$, whose elements are described as pairs of natural numbers!
\end{subsec}

\begin{subsec}
Thankfully, most Banach spaces that arise naturally in analysis turn out to be separable; certainly any finite-dimensional vector space has this property, and all but one Banach space that we will consider in this text will be separable.
Certainly any function into a separable Banach space is almost separably valued. So Definition \ref{almost separably valued dfn} will turn out to be a slightly annoying technical condition, and not at all of import, in practice.
The reader who is only interested in the case $B = \CC$, which is reasonable to do on one's first reading, can forget about this hypothesis altogether.
\end{subsec}

\begin{definition}
The \dfn{carrier}\footnote{Some books prefer the term ``support", but we use ``support" to mean the closure of the carrier, whenever $(X, \mu)$ has a topology.} of a function $f: X \to B$ is the set $\{x \in X: f(x) \neq 0\}$.
\end{definition}

\begin{subsec}
Now $B$ has a norm, so it has open balls $B(x, r) = \{y \in B: ||x - y|| < r\}$, and in particular $B$ has a topology: its open sets are the unions of the balls $B(x, r)$.
So we can define its Borel $\sigma$-algebra in the usual way: it is the smallest $\sigma$-algebra containing the topology of $B$.
\end{subsec}

\begin{subsec}
Our goal in this section is to prove the following theorem:
\end{subsec}

\begin{theorem}
\label{characterization of measurable functions}
Let $f: X \to B$ be a function with carrier $C$, possibly only defined almost everywhere. Then the following are equivalent:
\begin{enumerate}
\item $f$ is measurable.
\item $f$ is almost separably valued and for every open set $U \subseteq B$, $f^{-1}(U) \cap C$ is measurable.
\item $f$ is almost separably valued and for every closed set $K \subseteq B$, $f^{-1}(K) \cap C$ is measurable.
\item $f$ is almost separably valued and for every Borel set $W \subseteq B$, $f^{-1}(W) \cap C$ is measurable.
\end{enumerate}
\end{theorem}

\begin{corollary}
\label{characterization of measurable functions II}
Let $\Gamma$ be the Borel $\sigma$-algebra of $B$, so $B = (B, \Gamma)$ is a measurable space whose measurable sets are exactly the Borel sets.
Then a function $f: X \to B$ is measurable iff $f$ is almost separably valued and for every measurable $Y \subseteq B$, $f^{-1}(Y)$ is measurable.
\end{corollary}

\begin{subsec}
The reader should compare Corollary \ref{characterization of measurable functions II} to the result which says that a function $f$ is continuous iff the preimage of an open set is open. It says that a measurable function $X \to B$ is, modulo sets of measure zero, the same thing as a measurable map $X \to B$, where $B$ is equipped with its Borel $\sigma$-algebra.
\end{subsec}

\begin{subsec}
Before we prove Theorem \ref{characterization of measurable functions}, we need several lemmata which are useful in their own right.
\end{subsec}

\begin{lemma}
\label{Newberger lemma 1}
Let $f_n: X \to B$ be a sequence of functions converging pointwise to a function $f$.
For every open $U \subseteq B$, we define $U_n = \{y \in U: \inf_{x \notin U} ||x - y|| > 1/n\}$.
Then
$$f^{-1}(U) = \bigcup_{n=1}^\infty \bigcup_{K=1}^\infty \bigcap_{k=K}^\infty f_k^{-1}(U_n).$$
\end{lemma}
TODO: Draw a picture of $U_n$
\begin{proof}
The following are equivalent:
\begin{enumerate}
\item $x \in f^{-1}(U)$.
\item $f(x) \in U$.
\item There are $n, K$ such that for every $k \geq K$, $f_k(x) \in U_n$.
\item There are $n, K$ such that for every $k \geq K$, $x \in f_k^{-1}(U_n)$.
\item There are $n, K$ such that $x \in \bigcap_{k \geq K} f_k^{-1}(U_n)$.
\item $x \in \bigcup_n \bigcup_K \bigcap_{k \geq K} f_k^{-1}(U_n)$.
\end{enumerate}
Indeed, for every $i \in \{1, \dots, 6\}$, the $i$th entry in the above list is clearly equivalent to the $i+1$th entry.
\end{proof}

\begin{definition}
A function $f: X \to B$ is \dfn{separably valued} if the image of $f$ is separable in $B$.
\end{definition}

\begin{lemma}
\label{Newberger lemma 2}
Let $f: X \to B$ be a function with carrier $C$. Then the following are equivalent:
\begin{enumerate}
\item $f$ is the pointwise limit of simple functions.
\item $f$ is separably valued and for every open set $U \subseteq B$, $f^{-1}(U) \cap C$ is measurable.
\item $f$ is separably valued and for every open ball $U \subseteq B$, $f^{-1}(U) \cap C$ is measurable.
\end{enumerate}
\end{lemma}
\begin{proof}
We first show that $1$ implies $2$.
Let $f_n \to f$ pointwise, $f_n \in \Simp(X \to B)$ and for every $n$, let $\{b_1^n, \dots, b_{k(n)}^n\}$ be the image of $f_n$.
Let $K$ be the closure of $K_0 = \{b_i^n: n \in \NN,~i \in \{1, \dots, k(n)\}\}$.
Then $K_0$ is countable and dense in $K$, so $K$ is separable; moreover, $f(X) \subseteq K$, so $f$ is separably valued.
Now let $U \subseteq B$ be an open set; then $f^{-1}(U) \cap C = f^{-1}(U \setminus \{0\})$, and $U \setminus \{0\}$ is open.

Thus we must show that if $V$ is an open set which does not contain $0$, $f^{-1}(V)$ is measurable. Let $V_k = \{y \in V: \inf_{x \notin V} ||x - y|| > 1/n\}$. Clearly $f_n^{-1}(V_k)$ is measurable since there are only finitely many points of $f_n(X)$ in $V_k$, each with a measurable preimage, and Lemma \ref{Newberger lemma 1} implies
$$f^{-1}(V) = \bigcup_{n=1}^\infty \bigcup_{K=1}^\infty \bigcap_{k=K}^\infty f_k^{-1}(V_n)$$
which is measurable since the measurable sets form a $\sigma$-algebra.

Clearly $2$ implies $3$ so it suffices to show that $3$ implies $1$.
Let $\{b_i: i \in \NN\}$ be dense in $f(X)$.
Let
$$C_{ij} = \{x \in C: ||f(x) - b_i|| < 1/j\}.$$
Then $C_{ij}$ is a preimage of a union of open balls, so $C_{ij}$ is measurable.
Now it would be reasonable to define for every $x \in C_{ij}$, $f_n(x) = b_i$, except that the $C_{ij}$ are not disjoint.

To rectify this problem, let
$$E_{ijn} = C_{ij} \setminus \bigcup_{\substack{(i,j) < (k, \ell) \leq (n, n)\\1 \leq i,j \leq n}} C_{k\ell}$$
where $(i, j) \leq (k, \ell)$ iff $j < \ell$ or $j = \ell$ and $i \leq k$.
Then if $n$ is fixed, the $E_{ijn}$ are disjoint, $E_{ijn} \subseteq C_{ij}$.
Now let
$$f_n = \sum_{i,j=1}^n b_i 1_{E_{ijn}}.$$
\begin{sublemma}
$f_n \to f$ pointwise.
\end{sublemma}
\begin{proof}
Let $x \in X$. If $f(x) = 0$, then for every $n$, $f_n(x) = 0$, so $f_n(x) \to f(x)$.

Otherwise, $x \in C$. Let $\varepsilon > 0$. Let $N_1 > 1/\varepsilon$ and choose $N_2$ so that
$$||f(x) - b_{N_2}|| < \frac{1}{N_1}.$$
Now let $N = \max(N_1, N_2)$. Then $x \in C_{N_2N_1}$, so if $n > N$,
$$(k, \ell) = \max_{(N_1, N_2) \leq (i, j) \leq (n, n)} (i,j),$$
then $x \in E_{k\ell n}$. Therefore $f_n(x) = b_k$ and
$$||f(x) - b_k|| < \frac{1}{\ell} \leq \frac{1}{N_1} < \varepsilon.$$
But $f_n(x) = b_k$, so $||f_n(x) - f(x)|| < \varepsilon$.
\end{proof}
This implies $1$.
\end{proof}

\begin{lemma}
\label{Newberger lemma 3}
Let $f: X \to B$ be a function with carrier $C$. The following are equivalent:
\begin{enumerate}
\item For every closed set $K \subseteq B$, $f^{-1}(K) \cap C$ is measurable.
\item For every open set $U \subseteq B$, $f^{-1}(U) \cap C$ is measurable.
\item For every Borel set $W \subseteq B$, $f^{-1}(W) \cap C$ is measurable.
\end{enumerate}
\end{lemma}
\begin{proof}
Obviously $3$ implies $1$.

Now assume $1$. Then let $U \subseteq B$ be open,
$$K_n = \{y \in B: \inf_{x \notin U} ||x - y|| \geq \frac{1}{n}\}.$$
Then $K_n$ is closed and $U = \bigcup_n K_n$. But $f^{-1}(U) \cap C = \bigcup_n f^{-1}(K_n) \cap C$, and the $f^{-1}(K_n) \cap C$ are measurable, so $2$ follows.

To see that $2$ implies $3$, note that the set $\Gamma$ of all sets $Y$ such that $f^{-1}(Y) \cap C$ is measurable is a $\sigma$-algebra.
Indeed $\Gamma$ contains $\emptyset$ so is nonempty, is closed under complement since $f^{-1}(B \setminus Y) = X \setminus f^{-1}(Y)$, and is closed under countable union since $f^{-1}(\bigcup_n Y_n) = \bigcup_n f^{-1}(Y_n)$.
Since $\Gamma$ contains the open sets, $\Gamma$ contains the Borel sets.
\end{proof}

\begin{proof}[Proof of Theorem \ref{characterization of measurable functions}]
We can show that $f$ is measurable iff $f$ is almost separably valued and for every open set $U$, $f^{-1}(U) \cap C$ is measurable.
In fact, Lemma \label{Newberger lemma 3} then immediately shows that for every open set $U$, $f^{-1}(U) \cap C$ is measurable iff the same is true when ``open set" is replaced with ``closed set" or ``Borel set".

First assume that $f$ is measurable. Then there are $f_n \in \Simp(X \to B)$ and a null set $Z$ such that $f_n \to f$ pointwise on $X \setminus Z$ and $f$ is defined on $X \setminus Z$.
So $f_n1_{X \setminus Z} \to f1_{X \setminus Z}$ (where $f1_{X \setminus Z} = 0$ if $f$ is undefined), so $f1_{X \setminus Z}$ meets the criteria of Lemma \ref{Newberger lemma 2}; since null sets are measurable, so does $f$.

Conversely, if $Z$ is a null set such that $f(X \setminus Z)$ is separable and for every open set $U$, $f^{-1}(U) \cap C$ is measurable, then $f1_{X \setminus Z}$ is separably valued and for every open set $U$, $(f1_{X \setminus Z})^{-1}(U) \cap C$ is measurable, so Lemma \ref{Newberger lemma 2} implies the claim.
\end{proof}

We now prove a very important theorem about measurable functions. Note that the analogous result for continuous functions (or even Riemann integrable functions) does not hold.

\begin{theorem}
\label{measurable functions converge}
Suppose that $f_n$ are measurable functions which almost converge to a function $f$. Then $f$ is measurable.
\end{theorem}
\begin{proof}
We apply Newberger's theorem.
Since the $f_n$ are almost separably valued, there are null sets $Z_n$ such that $K = \overline{\bigcup_n f_n(X \setminus Z_n)}$ is closed.
Therefore $f$ is almost separably valued. Then Lemma \ref{Newberger lemma 1} implies that for every open set $U \subseteq B$,
$$f^{-1}(U) \cap C = \bigcup_{n=1}^\infty \bigcup_{K=1}^\infty \bigcup_{k=K}^\infty f_n^{-1}(U_n) \cap C$$
which implies that $f^{-1}(U)$ is a countable union of countable unions of countable intersections of measurable sets, hence is measurable.
\end{proof}

\begin{subsec}
\label{all functions are measurable}
Let $\RR$ be equipped with its usual Lebesgue measure (or really any Borel measure $\mu$ on any space with a countable dense subset, such that for every countable set $Z$, $\mu(Z) = 0$).
Then any continuous function $\RR \to B$ pulls back open sets to open (hence Borel) sets and has separable image (since the image of $\QQ$ is dense in the image of $\RR$), hence is measurable by Theorem \ref{characterization of measurable functions}.
Any pointwise limit of continuous functions is also measurable; for example any function with only a discrete set of discontinuities, or with only jump discontinuities.
A monotone function has only jump discontinuities, so is measurable. A similar argument applies for any left-continuous or right-continuous function.
And of course, we can modify any of the above functions on a countable set (or any null set!) to get another measurable function.
See Exercise \ref{all functions are measurable exer}.

TODO: Draw a picture of continous functions converging to a finitely disct function or a function with jump disc.
\end{subsec}

\begin{example}
\label{nonseparable function}
An example of a function which is not almost separably valued is given by Example \ref{nonseparable space}.
Let $\delta$ be as in that example and let $f(x) = \delta_x$. Then for any uncountable $Y \subseteq \RR$, $f(Y)$ is an uncountable discrete set, so removing a null set cannot possibly help us here.
\end{example}

\begin{example}[Vitali's set]
\label{Vitali set}
Recall that we defined Lebesgue measure on $\Torus$, $\mu$, in Example \ref{lebesgue measure torus}.
If we rotate $\Torus$ by an angle $\theta$, then the rotation preserves $\mu$; that is, if $A \subseteq \Torus$ is measurable, and $A + \theta = \{e^{i(\varphi+\theta)}: e^{i\varphi} \in A\}$, then $\mu(A) = \mu(A + \theta)$.
The group $\QQ$ of rational numbers under addition acts on $A$ by rotation: if $q \in \QQ$, define a map $e^{i\theta} \mapsto e^{i(\theta + 2\pi q)}$ from the circle to itself.

Let $\mathcal O$ be the set of all orbits of the action of $\QQ$; that is, elements of $\mathcal O$ are sets
$$\{e^{i(\varphi+2\pi q)}: q \in \QQ\}.$$
Each orbit is countable since it is indexed by $\QQ$, yet $\Torus$ is uncountable, so $\mathcal O$ must be uncountable.
Now the axiom of choice \ref{axiom of choice} implies that there is a set $X \subset \Torus$ which contains exactly one element from each orbit in $\mathcal O$.
Suppose that $X$ is measurable. Then $\bigcup_{q \in \QQ} X + q = \Torus$ and the union is disjoint, so
$$1 = \mu(\Torus) = \sum_{q \in \QQ} \mu(X +  q) = \sum_{q \in \QQ} \mu(X),$$
so $\mu(X) > 0$ (so that it sums to $1$) yet $\mu(X) = 0$ (since the sum of infinitely many copies of any nonzero number is infinite and hence $> 1$), a contradiction.

Therefore $X$ is nonmeasurable, and so is its indicator function $1_X$.
\end{example}

\begin{subsec}
But should you, dear reader, worry about nonmeasurable functions?
Example \ref{all functions are measurable} shows that functions that appear in mainstream analysis, algebra, or number theory are measurable.
Example \ref{nonseparable function} does suggest that in deeply infinitary parts of functional analysis, one may have to worry about functions which are not separably valued, and Vitali's set shows that in logic, where the axiom of choice (and its evil friends such as the axiom of power set and the axiom schema of replacement) is of import, nonmeasurable sets may emerge.
But (TODO cite me) there exist models of set theory with certain axioms weakened where Vitali's construction fails and every almost separably valued function is measurable, and someone with a more constructivist bent may conclude from that theorem that indeed every function is measurable in ``reality" (whatever that means).
Strichartz (TODO cite me) summarized these observations by remarking that ``wise-guys who like using the axiom of choice will have to worry about ... wolves under the bed, etc."
\end{subsec}

\begin{exercise}
\label{all functions are measurable exer}
Prove the assertions in Example \ref{all functions are measurable}.
\end{exercise}

\begin{definition}
Define the \dfn{Baire space} $B_n$ inductively: let $B_0$ be the space of continuous functions $[0, 1] \to \CC$, and let $B_{n+1}$ be the space of pointwise limits of functions in $B_n$.
If $f \in B_n$, we say that $f$ is \dfn{$n$-Baire}.

Unfortunately, there is another notion of Baire space, having to do with the Baire category theorem, which is not the same as the Baire space that we just defined.
\end{definition}

\begin{exercise}
Show that every Baire function is Borel.
(The converse is true if one allows for $\alpha$-Baire functions, $\alpha$ any countable ordinal, but you are not being asked to prove that.)
\end{exercise}

\begin{exercise}
Show that the derivative of a differentiable function is $1$-Baire.
Show that the function $1_{\QQ \cap [0, 1]}$ is $2$-Baire but not $1$-Baire.
\end{exercise}

\begin{exercise}
Find a function which is $3$-Baire but not $2$-Baire. More generally, find a function which is $(n+1)$-Baire but not $n$-Baire.
\end{exercise}

\section{Convergence of measurable functions}
We have already discussed two means by which measurable functions may converge to other measurable functions: pointwise and almost pointwise.
From this point onwards, pointwise convergence will be largely irrelevant; following our philosophy that null sets are important, almost pointwise will usually be the desired property.

\begin{subsec}
Throughout, we fix a complete measured space $(X, \Sigma, \mu)$ and a Banach space $B$.
\end{subsec}

\begin{definition}
A sequence of functions $f_n$ converge to a function $f$ \dfn{uniformly} if for every $\varepsilon > 0$ there is an $N$ such that for every $n > N$, $\sup ||f_n - f||_B < \varepsilon$.
\end{definition}

\begin{subsec}
Now, by analogy with the notion of a property holding ``almost everywhere" (everywhere except a null set), we introduce the notion of a property holding \dfn{nearly everywhere}; that is, everywhere except a set of measure $\varepsilon > 0$. The property holds for arbitrarily small $\varepsilon$, but the parameters in the property (the $\delta$s, $N$s, and so on) may become arbitrarily ``bad" as $\varepsilon \to 0$.
\end{subsec}

\begin{definition}
A sequence of functions $f_n: X \to B$ \dfn{converges nearly uniformly} to a function $f: X \to B$ if for every $\varepsilon > 0$ there is a set $E_\varepsilon$ such that $|\mu|(X \setminus E_\varepsilon) < \varepsilon$ and $f_n \to f$ uniformly on $E_\varepsilon$.
\end{definition}

\begin{subsec}
Thus $f_n \to f$ nearly uniformly iff for every $\varepsilon > 0$ there is a $E$ such that for every $\delta > 0$ there is an a $N$ such that $|\mu|(E) < \varepsilon$ and for every $n > N$, $\sup_E ||f_n - f||_B < \delta$.
Clearly a sequence which converges nearly uniformly converges almost pointwise; indeed, the sets $E_\varepsilon$ where the sequence fails to converge uniformly have a null intersection $E$, and if the sequence fails to converge pointwise at a point $x$, then $x \in E$.
In particular, the nearly uniform limit of a sequence of measurable functions is measurable.
\end{subsec}

\begin{lemma}
Suppose that $f_n: X \to B$ and $g_n: X \to B$, $f_n \to f$ and $g_n \to g$ nearly uniformly. Then the following limits also hold nearly uniformly:
\begin{enumerate}
\item $f_n + g_n \to f + g$.
\item For every $c \in \CC$, $cf_n \to cf$.
\item If $B = \CC$, $f_ng_n \to fg$.
\item $(x \mapsto ||f_n(x)||_B) \to (x \mapsto ||f(x)||_B)$.
\item $\max(f_n, g_n) \to \max(f, g)$.
\item $\min(f_n, g_n) \to \min(f_n, g_n)$.
\end{enumerate}
\end{lemma}
\begin{proof}
Routine and omitted.
\end{proof}

\begin{theorem}[Egorov]
Let $X$ be a finite measure space (thus $\mu(X) < \infty$) and suppose that $f_n \in M(X \to B)$ almost converge to $f$, and the $f_n$ are measurable.
Then $f_n \to f$ nearly uniformly.
\end{theorem}
\begin{proof}
After throwing away a harmless null set, we may assume that $f_n \to f$ pointwise. Now define
$$E_m^n = \{x \in X: \exists k \geq n(||f(x) - f_k(x)||_B \geq \frac{1}{m})\}.$$
Since $x \mapsto ||f(x) - f_k(x)||_B$ is measurable, by Theorem \ref{characterization of measurable functions}, $E_{mn}$ is measurable.
Moreover, if $m$ is fixed, the $E_m^n$ shrink as $n$ increases and $\bigcap_n E_{mn} = \emptyset$, since $f_n \to f$.
By Lemma TODO, since $|\mu|(X) < \infty$, $\lim_n \mu(E_m^n) = 0$. So for every $\varepsilon > 0$ and every $m$ we may find $n(m)$ such that
$$\mu(E_m^{n(m)}) < \frac{\varepsilon}{2^m}.$$
Now let $F = E \setminus \bigcup_m E_m^{n(m)}$, so
$$\mu(E \setminus F) \leq \sum_{m=1}^\infty \mu(E_m^{n(m)}) < \varepsilon.$$
So it suffices to show that for every $\delta > 0$ there is a $N$ such that for every $n > N$, $\sup_F ||f_n - f||_B < \delta$.
Indeed, if $1/m < \delta$ and $N = n(m)$, then for every $x \in F$, $x \notin E_N^m$, so if $n > N$ then $||f(x) - f_n(x)||_B < \delta$.
\end{proof}

\begin{definition}
A sequence of functions $f_n: X \to B$ is said to be a \dfn{nearly uniform Cauchy sequence} if for every $\varepsilon > 0$ there is a measurable set $E_\varepsilon$ such that $\mu(X \setminus E_\varepsilon) < \varepsilon$ and for every $\delta > 0$ there is an $N$ such that for every $n_1, n_2 > N$, $\sup ||f_{n_1} - f_{n_2}||_B < \delta$.
\end{definition}

\begin{subsec}
Since the hypothesis of being nearly uniform Cauchy is not altered if we change the functions $f_n$ on a null set, we can work with equivalence classes of functions (equivalent iff equal almost everywhere) rather than functions themselves. This will be important when we demand that the limit of a Cauchy sequence be unique; it will not be a unique function everywhere, but only almost everywhere.
\end{subsec}

\begin{lemma}
\label{nearly uniform cauchy converges}
Let $f_n \in M(X \to B)$ be a nearly uniform Cauchy sequence. Then there is a unique $f \in M(X \to B)$ such that $f_n \to f$ nearly uniformly.
\end{lemma}
\begin{proof}
For every $m$ we can find $E_m$ such that $|\mu|(X \setminus E_m) < 1/m$ and $f_n$ is uniformly Cauchy on $E_m$. Let $E = \bigcup_m E_m$.
Then $|\mu|(X \setminus E) < 1/m$ for every $m$, so $|\mu|(X \setminus E) = 0$, and it is okay if we leave $f$ undefined on $X \setminus E$.
As for if $x \in E$, we can choose an $m$ such that $x \in E_m$. Since the $f_n$ are a nearly uniform Cauchy sequence, the $f_n(x)$ are a Cauchy sequence, which converge to some $y \in B$ since $B$ is a Banach space.
Therefore we may let $f(x) = y$.

Now the $f_n \to f$ nearly uniformly. In fact, for every $\varepsilon > 0$ we may take $m > 1/\varepsilon$ and let $E_\varepsilon = E_m$.
Then $f_n \to f$ uniformly on $E_\varepsilon$.

As for uniqueness, the $f_n \to f$ almost pointwise, and pointwise limits are unique (so that almost pointwise limits are unique almost everywhere). But $f$ was only defined up to measure zero, so this is no loss.
\end{proof}

\begin{definition}
Let $f_n: X \to B$ be a sequence of measurable functions, $f: X \to B$. We say that $f_n$ \dfn{converges in measure} to $f$ if for every $\varepsilon > 0$ the set
$$\lim_{n\to \infty} |\mu|(\{x \in X: ||f_n(x) - f(x)||_B > \varepsilon\}) = 0.$$
If $\mu$ is a probability measure, we instead say that $\mu$ \dfn{converges in probability}.
\end{definition}

\begin{subsec}
We sometimes abbreviate the set in the above definition as $\{||f_n - f||_B > \varepsilon\}$.
In other words, $f_n \to f$ in measure iff for every $\varepsilon > 0$ and every $\delta > 0$ there is an $N$ such that for every $n > N$,
$$|\mu|(\{||f_n - f||_B > \varepsilon\}) < \delta,$$
and collapsing quantifiers this happens iff for every $\varepsilon > 0$ there is an $N$ such that for every $n > N$,
$$|\mu|(\{||f_n - f||_B > \varepsilon\}) < \varepsilon.$$
\end{subsec}

\begin{subsec}
What is the intuition for convergence in measure?
Suppose that we are scientists running experiments in an attempt to compute the value of a function $f$.
As the number of test subjects $n$ goes to infinity, the experimental data $f_n$ should converge to $f$, but in what sense?
Let $X$ be the set of possible outcomes and $P(E)$ the probability that one of the outcomes in $E$ occurs, thus $P$ is a probablity measure. Then $P(\{||f_n(x) - f(x)||_B > \varepsilon\})$
is the probability that we got an experimental error of size at least $\varepsilon$; as $n \to \infty$, this probability becomes vanishingly small.
However, on the off-chance that an error of size at least $\varepsilon$ occurs, we have no control over how bad the error may be!
Thus $f_n \to f$ in probability and a priori we can prove no stronger.
\end{subsec}

\begin{lemma}
\label{conv in measure is hausdorff}
If $f_n \to f$ in measure, then $f$ is unique almost everywhere, hence as an element of $M(X \to B)$.
\end{lemma}
\begin{proof}
Suppose that $f_n \to g$ in measure as well. Then for every $\varepsilon > 0$ and $n$,
$$\{||f - g||_B > \varepsilon\} \subseteq \{||f - f_n||_B > \varepsilon/2\} \cup \{||g - f_n||_B   > \varepsilon/2\}.$$
If $n$ is large enough, the right hand side has measure at most $\varepsilon$.
\end{proof}

\begin{definition}
Let $f_n: X \to B$ be a sequence of functions. We say that the $f_n$ are \dfn{Cauchy in measure} if for every $\varepsilon > 0$ there is a $N$ such that for every $n_1, n_2 > N$,
$$|\mu|(\{||f_{n_1} - f_{n_2}||_B > \varepsilon\}) < \varepsilon.$$
\end{definition}

\begin{lemma}
Suppose that $f_n: X \to B$ and $g_n: X \to B$, $f_n \to f$ and $g_n \to g$ in measure. Then the following limits also hold in measure:
\begin{enumerate}
\item $f_n + g_n \to f + g$.
\item For every $c \in \CC$, $cf_n \to cf$.
\item If $B = \CC$, $f_ng_n \to fg$.
\item $(x \mapsto ||f_n(x)||_B) \to (x \mapsto ||f(x)||_B)$.
\item $\max(f_n, g_n) \to \max(f, g)$.
\item $\min(f_n, g_n) \to \min(f, g)$.
\end{enumerate}
\end{lemma}
\begin{proof}
Routine and omitted.
\end{proof}

\begin{subsec}
How does convergence in measure relate to other modes of convergence?
It does not imply almost pointwise convergence -- imagine a sequence of functions racing back and forth along $[0, 1]$, their supports getting smaller with every time they turn around. TODO: Draw a picture.
Nor does it follow from almost pointwise convergence on infinite measure sets -- just take $f_n = 1_{[n, n+1]}$ as a counterexample.
But convergence in measure is weaker than nearly uniform convergence, hence from almost pointwise convergence on finite measure sets. TODO: Draw a diagram.
\end{subsec}

\begin{lemma}
\label{nearly uniform implies in measure}
Suppose that $f_n \to f$ nearly uniformly; then $f_n \to f$ in measure.
\end{lemma}
\begin{proof}
Let $\varepsilon > 0$.
Then there is a set $E_\varepsilon$ on which $f_n \to f$ uniformly such that $\mu(X \setminus E_\varepsilon) < \varepsilon$, thus if $n$ is large enough $\sup_{E_\varepsilon} |f_n - f| < \varepsilon$, so $\{||f_n - f||_B > \varepsilon\} \subseteq X \setminus E_\varepsilon$ and hence $\mu(\{||f_n - f||_B > \varepsilon\}) < \varepsilon$.
So $f_n \to f$ in measure.
\end{proof}

\begin{corollary}
If $\mu(X) < \infty$ and $f_n \to f$ almost pointwise, then $f_n \to f$ in measure.
\end{corollary}
\begin{proof}
By Egorov's theorem and Lemma \ref{nearly uniform implies in measure}.
\end{proof}

\begin{subsec}
We now come to a critical result which implies that Cauchyness in measure not only implies convergence in measure, but other modes of convergence as well.
This result has been called the \dfn{Riesz-Weyl theorem} or the \dfn{fundamental theorem of integration}.
\end{subsec}

\begin{theorem}[fundamental theorem of integration]
Suppose that $f_n$ is a Cauchy sequence in measure. Then there is a subsequence of $f_{n_k}$ and a unique $f \in M(X \to B)$ such that:
\begin{enumerate}
\item The $f_{n_k}$ are a nearly uniform Cauchy sequence.
\item $f_{n_k} \to f$ nearly uniformly.
\item $f_n \to f$ in measure.
\end{enumerate}
\end{theorem}
\begin{proof}
Let $n_1 = 1$, and choose $n_{k+1} > n_k$ such that if $m_1, m_2 \geq n_{k+1}$, then
$$|\mu|(\{||f_{m_1} - f_{m_2}||_B \geq 2^{-k}\}) < 2^{-k}.$$
Let $g_k = f_{n_k}$.
\begin{sublemma}
$g_k$ is nearly uniformly Cauchy.
\end{sublemma}
\begin{proof}
Let $\varepsilon > 0$ and choose $K$ so that $\sum_{k\geq K} 2^{-k} < \varepsilon$. Let
$$F = X \setminus \bigcup_{k \geq K} \{||g_k - g_{k+1}||_B > 2^{-k}\}.$$
Then $\mu(X \setminus F) < \varepsilon$.

Now let $\delta > 0$ and choose $N$ so large that $N \geq K$, $2^{1-N} < \delta$. Then if $j > \ell > N$, $x \in F$,
\begin{align*}
||g_j(x) - g_\ell(x)||_B &= ||g_j(x) - g_{j-1}(x) + g_{j-1}(x) - g_{j-2}(x) + \cdots + g_{\ell+1}(x) - g_\ell(x)||_B\\
&\leq \sum_{i=\ell}^{j-1} ||g_{i+1}(x) - g_i(x)||_B\\
&\leq \sum_{i=\ell}^{j-1} 2^{-i} < 2^{1-N} < \delta.
\end{align*}
Therefore the $g_k$ are a uniform Cauchy sequence on $F$ and hence nearly uniform on $X$.
\end{proof}
So by Lemma \ref{nearly uniform cauchy converges}, there is an $f$ such that $\lim_k g_k = f$ nearly uniformly.
But then Lemma \ref{nearly uniform implies in measure} implies that $\lim_k g_k = f$ in measure.
But
\begin{equation}
\label{form1}\{||f - f_n(x)||_B > \varepsilon\} \subseteq \{||f - g_k||_B > \varepsilon/2\} \cup \{||f_n - g_k||_B > \varepsilon/2\},
\end{equation}
and the $g_k$ are a subsequence of the Cauchy-in-measure sequence $f_n$, hence the right hand side of (\ref{form1}) is $<\varepsilon$ if $n,k$ are large enough. So $f_n \to f$ in measure.
Uniqueness follows by Lemma \ref{conv in measure is hausdorff}.
\end{proof}

\begin{corollary}
If $f_n \to f$ in measure, then there is a subsequence of $f_{n_k}$ such that $f_{n_k} \to f$ nearly uniformly.
\end{corollary}
\begin{proof}
The $f_n$ are Cauchy in measure, so the fundamental theorem of integration implies that there is a subsequence that is nearly uniformly Cauchy.
Uniqueness of a nearly uniform limit implies that the subsequence must converge to $f$.
\end{proof}

\begin{exercise}
Find an example which shows that the hypothesis of finite measure in Egorov's theorem cannot be omitted.
\end{exercise}

\section{Regularity of measurable functions}
Before we define the integral, we pause to use Egorov's theorem to prove a partial converse to the theorem which said that every continuous function was measurable.
Of course not every measurable function is continuous (most measure spaces don't even come with a topology, but also, any familiar discontinuous function on $\RR$ will be measurable), but we will do the best that we can this section.

\begin{subsec}
Throughout this section, fix a locally compact Hausdorff space $X$. If the reader is not familiar with such notions, they can take $X = \RR^c$.
\end{subsec}

\begin{subsec}
Recall that a function $f: \RR^c \to \CC^d$ is \dfn{smooth} if for every point $x$ and every vector of natural numbers $(k_1, \dots, k_c)$, the partial derivative
$$\partial_1^{k_1} \partial_2^{k_2} \cdots \partial_c^{k_c} f(x)$$
exists; here $\partial_i^{k_i}$ is the operator that takes a function to its $k_i$th partial derivative along its $i$th basis vector.
Clearly every smooth function is differentiable and hence continuous.
\end{subsec}

\begin{lemma}[Urysohn]
Let $K_0,K_1 \subseteq X$ be disjoint closed sets. Then there is a continuous function $f: X \to [0, 1]$ such that $f|K_0 = 0$ and $f|K_1 = 1$.
Moreover, if $X = \RR^c$, we can even assume that $f$ is smooth.
\end{lemma}

\begin{subsec}
We refer the reader to a book on topology such as (TODO cite me) for the proof of Urysohn's lemma. (Or in an appendix?)
We will also need the fact that in every Hausdorff space, a compact set is closed. Again we refer to (TODO cite me) for the proof, though when $X = \RR^c$, this follows from the Heine-Borel theorem.
\end{subsec}

\begin{subsec}
Now the open sets of $X$ generate a topology, namely the Borel $\sigma$-algebra of $X$. Therefore $X$ is a measurable space in a natural way.
By a \dfn{Borel measure} on $X$ we mean a measure defined on the Borel $\sigma$-algebra of $X$.
\end{subsec}

\begin{lemma}
Every continuous function is measurable with respect to the Borel $\sigma$-algebra.
\end{lemma}
\begin{proof}
Let $f: X \to B$ be continuous; then the $f$-preimage of an open set is open, hence Borel, hence measurable.
We now appeal to Theorem \ref{characterization of measurable functions}.
\end{proof}

\begin{definition}
View $X$ as a complete measured space $(X, \Sigma, \mu)$, where $\mu$ is a Borel measure and $\Sigma$ is the $\sigma$-algebra of $\mu$-measurable sets (so that $\Sigma$ is generated by the Borel sets and $\mu$-null sets).
Let $f: X \to B$ be a function.
We say that $f$ is a \dfn{nearly continuous function} if for every $\varepsilon > 0$ there is a set $E$ such that $\mu(X \setminus E) < \varepsilon$ and $f|E$ is continuous.
\end{definition}

\begin{subsec}
You should check that your favorite discontinuous function (that isn't the indicator function of the Vitali set) is nearly continuous.
For example the function $x \mapsto 1/x$ is nearly continuous because if we discard a small neighborhood of $0$, then it is continuous.
\end{subsec}

\begin{subsec}
Throughout the rest of the section, we fix a positive Radon measure $\mu$ on $X$, and take its completion, so if $\Sigma$ denotes the $\sigma$-algebra generated by Borel sets and $\mu$-null sets, then $(X, \Sigma, \mu)$ is a complete measured space, which we also denote by $X$.
Thus $X$ is equipped with a topology, a $\sigma$-algebra, and a measure; so $X$ is a lot like the real line $\RR$, and when we refer to measurable functions, nearly continuous functions, and so on, we do so with respect to $\Sigma$.
\end{subsec}

\begin{lemma}
\label{smooth functions are pointwise dense}
If $f: X \to \CC^d$ is a measurable function, then there is a sequence of continuous functions $f_n: X \to \CC^d$ such that $f_n \to f$ almost pointwise.
If $X = \RR^c$ then we can even take the $f_n$ to be smooth.
\end{lemma}
\begin{proof}
We first check this when $f$ is the indicator function of a compact set $K$.
By outer regularity, for every $n$ there is an open set $U_n \supseteq K$ such that $\mu(U_n \setminus K) < 1/n$, and after taking intersections we can assume that $U_n \supseteq U_{n+1}$.
The complement $X \setminus U_n$ is closed, so by Urysohn's lemma there is a continuous function $f_n: X \to [0, 1]$, smooth if $X = \RR^c$, such that $f_n|K = 1$ and $f_n|(X \setminus U_n) = 0$.
Now $f_n \to f$ almost pointwise. Indeed, if $x \in K$, then for every $n$, $f_n(x) = 1$; otherwise, unless $x$ is in $\bigcap_n U_n \setminus K$, which is a null set, there is an $N$ such that $x \notin U_N$, and hence for every $n > N$, $x \notin U_n$, so $f_n(x) = 0$.
TODO: Draw a picture.

We now check when $f$ is the indicator function of an open set $U$.
By inner regularity, there is a sequence of compact sets $K_m$ such that $K_m \subseteq K_{m+1}$ and $\mu(U \setminus K_m) < 1/m$.
In particular, $\lim_m 1_{K_m} = 1_U$ almost pointwise.
Now there are sequences of continuous functions (smooth if $X = \RR^c$) $f_n^m: X \to [0, 1]$ such that $\lim_n f_n^m = 1_{K_m}$ almost pointwise, thus
$$|f_n^n(x) - 1_U(x)| \leq |f_n^n(x) - 1_{K_n}(x)| + |1_{K_n}(x) - 1_U(x)|.$$
The right-hand side vanishes as $n \to \infty$ so $f_n^n \to 1_U$ almost pointwise.
TODO: Draw a picture.

A similar argument applies when $f$ is the indicator function of a Borel set $W$.
Indeed, by outer regularity, there is a sequence of open sets $U_m$ such that $U_m \supseteq K_{m+1}$, $\mu(U_m \setminus W) < 1/m$.
We can find a sequence of continuous (smooth?) functions $f_n^m: X \to [0, 1]$ such that $\lim_n f_n^m = 1_{U_m}$ almost pointwise, and $\lim_m 1_{U_m} = 1_W$ almost pointwise, so $f_n^n \to 1_W$ almost pointwise.

If $f$ is the indicator function of a measurable set, then we can modify $f$ on a null set and replace it with the indicator function of a Borel set.

If $f \in \Simp(X \to \CC)$, then $f$ is a linear combination of indicator functions of measurable sets $f_1, \dots, f_n$, so we can find sequences approximating each of the summands $f_i$ and use linearity.

If $f$ is an arbitrary measurable function $X \to \CC$, we can approximate $f$ by simple functions.

If $f$ is a vector of measurable functions $X \to \CC^d$, we can approximate each of the components of $f$ by continuous (smooth?) functions.
\end{proof}

\begin{theorem}[Luzin]
If $\mu(X) < \infty$, then a function $f: X \to \CC^d$ is measurable iff $f$ is nearly continuous.
\end{theorem}
\begin{proof}
If $f$ is nearly continuous, then for every $\varepsilon > 0$ we can find a set $E_\varepsilon$ on which $f$ is continuous, hence measurable, and $\mu(X \setminus E_\varepsilon) < \varepsilon$.
Taking their union, we conclude that $f$ is measurable at almost every point of $X$, and hence everywhere on $X$.
Note that this direction was already valid for any Borel measure and any Banach space codomain.

Conversely, suppose that $f$ is measurable.
By Lemma \ref{smooth functions are pointwise dense}, we can find a sequence of continuous (or even smooth) functions $f_n$ with $f_n \to f$ almost pointwise, and hence nearly uniformly by Egorov's theorem.
The uniform limit of a sequence of functions is continuous, so the nearly uniform limit is nearly continuous.
\end{proof}

\begin{exercise}
Show that there exists a measurable function on $\RR^d$ which is not nearly smooth.
\end{exercise}

\begin{exercise}
Let $\mu$ be a $\sigma$-finite positive Radon measure on $\RR^d$.
Show that for every Borel set $A$ such that $\mu(A) > 0$, there is an $R > 0$ such that $0 < \mu(B(0, R) \cap A) < \infty$.
Since this is in particular true for Lebesgue measure, it is often no loss of generality to suppose that the sets one is working with have finite Lebesgue measure.
\end{exercise}

\begin{exercise}
Let $\mu$ be Lebesgue measure on $\RR$.
Show that there is a Borel set $A \subseteq [0, 1]$ such that for every open interval $U \subseteq [0, 1]$, $0 < \mu(A \cap U) < \mu(U)$.
(Hint: Start with a fat Cantor set, c.f. Exercise \ref{fat cat}, and then put more fat Cantor sets in the leftover intervals, but be careful.)
\end{exercise}

\begin{exercise}
Let $\mu$ be Lebesgue measure on $\RR$.
Let $A \subseteq \RR$ be a Borel set such that $\mu(A) > 0$.
Show that for every $\varepsilon > 0$ there is an open interval $U$ such that $\mu(U \cap A) > (1 - \varepsilon)\mu(U)$.
(Hint: Use the pigeonhole principle.)
\end{exercise}

\begin{exercise}
\label{steinhaus}
Prove \dfn{Steinhaus' theorem}: Let $A$ be a Borel subset of $\RR$ with positive Lebesgue measure. Then the set $\{x - y: (x, y) \in A^2\}$ contains an open set $U$ such that $0 \in U$.
\end{exercise}

\begin{exercise}
Let $G \subset \RR$ be a proper subgroup of $\RR$ under addition.
Show that if $G$ is Borel then $G$ is null.
(Hint: use Exercise \ref{steinhaus}, Steinhaus' theorem).
\end{exercise}


\section{Integration of simple functions}
We are ready to define the integral, at least for simple functions.

\begin{subsec}
A priori, our intuitive definition of integration as ``the net signed area under the graph" is problematic.
Consider the function $f = 1_{[0, \infty)} - 1_{(-\infty, 0]}$. What is the net signed area under the graph of $f$? Well, to the left of $0$, it is $-\infty$, and to the right it is $+\infty$, so we run into our usual pesky foe, $\infty - \infty$.
To put off this problem for now, we dodge the issue by declaring that we will for now only try to integrate functions whose integrals will be finite.
\end{subsec}

\begin{subsec}
For the rest of the chapter, fix a measure $\mu$, either valued in $\CC$ (which is a one-dimensional Banach space) or $(-\infty, \infty]$.
The reason that we do not allow $\mu$ to be more generally vector-valued is that we need to be able to multiply elements of the Banach space $B$ by $\mu(E)$.
\end{subsec}

\begin{definition}
An \dfn{integrable simple function} is a function $f \in \Simp(X \to B)$ such that for every nonzero $b$ in the image of $f$, $f^{-1}(b)$ has finite measure.
We denote the set of integrable simple functions by $\ISF(X \to B)$.
\end{definition}

\begin{subsec}
We want the integral to be, at first, a linear map $\ISF(X \to B) \to B$.
To motivate it, let's suppose that $B = \CC$, $X = \RR$, $\mu$ is Lebesgue measure, and $E$ is an interval. Then $\int_{-\infty}^\infty 1_E$ had better be the area of the rectangle $E \times [0, 1]$ (TODO draw a picture), hence $\int_{-\infty}^\infty 1_E = \mu(E)$. In order for linearity to hold, if $c \in \CC$, we must then have $\int_{-\infty}^\infty c1_E = c\mu(E)$.
\end{subsec}

\begin{subsec}
For every integrable simple function $f$, $f$ can be written in terms of the indicator functions in a unique way; namely, if $\{b_1, \dots, b_n\}$ is the image of $f$,
\begin{equation}
\label{canonical ISF rep}
f(x) = \sum_{i=1}^n b_i1_{f^{-1}(b_i)}(x).
\end{equation}
In particular, the indicator functions span $\ISF(X \to \CC)$.
\end{subsec}

\begin{definition}
We call (\ref{canonical ISF rep}) the \dfn{canonical representation} of the integrable simple function $f$ with image $\{b_1, \dots, b_n\}$.
\end{definition}

\begin{definition}
Let $f \in \ISF(X \to B)$ and suppose that (\ref{canonical ISF rep}) is the canonical representation of $f$. Let $E$ be a measurable set. We define the \dfn{integral} of $f$ to be
$$\int_E f~d\mu = \sum_{i=1}^n b_i\mu(f^{-1}(b_i) \cap E).$$
\end{definition}

\begin{subsec}
We will occasionally write $\int f$ or similar to mean $\int_X f~d\mu$, but only when $X$ and $\mu$ are understood. If we need a dummy variable, we may write $\int_E f(x)~d\mu(x)$, and if $\mu$ is understood we may even write $\int_E f(x)~dx$. If $E$ is an interval $[a, b]$, we may write $\int_a^b$ to mean $\int_E$.
For example, once we will have adequately defined integration,
$$\int_0^{2\pi} \sin x~dx = 0$$
as one would expect.
\end{subsec}

\begin{lemma}
\label{properties of ISF integral}
Let $f,g \in \ISF(X \to B)$. Then:
\begin{enumerate}
\item \dfn{Linearity}: For every $c \in \CC$,
$$\int_X cf + g~d\mu = c\int_X f ~d\mu + \int_X g~d\mu.$$
\item The \dfn{triangle inequality}:
$$\left|\left|\int f(x) ~d\mu(x)\right|\right|_B \leq \int ||f(x)||_B ~d|\mu|(x).$$
\item The \dfn{change-of-variables formula}: Let $(Y, \nu)$ be a measured space. Suppose that $h: Y \to X$ is a measurable map and $\mu$ is the pushforward measure $\mu = h_*\nu$. Then
$$\int_X f~d\mu = \int_Y f \circ h~d\nu.$$
\item If $B = \RR$ and $f \leq g$, then $\int f \leq \int g$.
\item If $E,F$ are disjoint measurable sets, then
$$\int_{E \cup F} f = \int_E f + \int_F f.$$
\item If $E \subseteq F$ are measurable sets, $B = \RR$, and $\mu$ is a nonnegative measure, then
$$\int_E f~d\mu \leq \int_F f~d\mu.$$
\item $\int ||f(x)||_B ~d|\mu|(x) = 0$ if and only if $f = 0$ almost everywhere.
\end{enumerate}
\end{lemma}
\begin{proof}
See Exercise \ref{integral props exer 1}.
\end{proof}

\begin{subsec}
We want to extend the integral from $\ISF(X \to B)$ to the space $M(X \to B)$ of all measurable functions.
But we cannot merely define $\int f = \lim_n f_n$, where the $f_n$ are simple functions that converge to $f$.
Indeed, if $f_n = 1_{[n, n+1]}$ then $f_n \to 0$ pointwise, but $\lim_n \int f_n = 1$, and we certainly do not want $\int 0 = 1$!
We need another notion of convergence, which will turn out to be closely related to convergence in measure.
\end{subsec}

\begin{definition}
Given $f \in \ISF(X \to B)$, let
\begin{equation}
\label{L1 norm dfn}
||f||_1 = \int_X ||f(x)||_B ~d|\mu|(x).
\end{equation}
One calls $||f||_1$ the \dfn{$L^1$-norm} of $f$.
\end{definition}

\begin{subsec}
As the reader should check, the $L^1$ norm is a seminorm. See Exercise \ref{L1 norm exer}.
Now when we say that $f_n \to f$ in $L^1$, we mean that $||f_n - f||_1 \to 0$. Similarly if we say that the $f_n$ are Cauchy in $L^1$, we mean that $||f_n - f_m||_1 \to 0$.
\end{subsec}

\begin{subsec}
It is natural to want to extend the $L^1$ norm to the completion of the space $\ISF(X \to B)$, on which it will actually be a norm.
(See Theorem \ref{completion exists} for more on that.)
\end{subsec}

\begin{definition}
The completion of $\ISF(X \to B)$ is known as $L^1(X \to B)$.
\end{definition}

\begin{subsec}
Formally, $L^1(X \to B)$ consists of Cauchy sequences of simple functions modulo Cauchy equivalence.
We will define the integral as a linear map $L^1(X \to B) \to B$:
\end{subsec}

\begin{definition}
\label{definition of integral}
Let $f \in L^1(X \to B)$ and suppose that $E$ is a measurable set.
Choose a Cauchy sequence of $f_n \in \ISF(X \to B)$ such that $f_n \to f$ in $L^1$.
We define the \dfn{integral} of $f$ to be
$$\int_E f~d\mu = \lim_{n \to \infty} \int_E f_n~d\mu.$$
\end{definition}

\begin{subsec}
Let's check that Definition \ref{definition of integral} makes sense. When we say that $f_n \to f$ in $L^1$, we mean that $f$ is the equivalence class of the Cauchy sequence $(f_n)_n$.
So if there was another Cauchy sequence $(g_n)_n$ with $g_n \to f$ in $L^1$,
\begin{align*}\left|\left|\lim_{n \to \infty} \int_E g_n - f_n ~d\mu\right|\right| &\leq \lim_{n \to \infty} \int_E ||g_n(x) - f_n(x)||_B ~d|\mu|(x)\\&
\leq \lim_{n \to \infty} \int_X ||g_n(x) - f_n(x)||_B ~d|\mu|(x)
\\& = \lim_{n \to \infty} ||g_n - f_n||_1 = 0,
\end{align*}
the last equality following because the $g_n$ and the $f_n$ are Cauchy equivalent.
Therefore the choice of Cauchy sequence in Lemma \ref{definition of integral} is immaterial, and any choice will return the same integral.
As a consequence, the $L^1$ norm extends to all of $L^1(X \to B)$ by the equation (\ref{L1 norm dfn}).
\end{subsec}

\begin{lemma}
\label{properties of ISF integral 2}
The conclusion of Lemma \ref{properties of ISF integral} holds for any $f,g \in L^1(X \to B)$, not just $f,g \in \ISF(X \to B)$.
\end{lemma}
\begin{proof}
Left as Exercise \ref{integral props exer 2}.
\end{proof}

\begin{exercise}
\label{integral props exer 1}
Prove Lemma \ref{properties of ISF integral}.
\end{exercise}

\begin{exercise}
\label{L1 norm exer}
Show that the $L^1$-norm is a seminorm on $\ISF$, and that $||f||_1 = 0$ iff $f = 0$ almost everywhere.
\end{exercise}

\begin{exercise}
\label{integral props exer 2}
Prove Lemma \ref{properties of ISF integral 2}.
\end{exercise}

\begin{exercise}
Let $A = \{1, \dots, d\}$ with counting measure. Therefore \emph{every} function $A \to \RR$ is an integrable simple function, and we can identify $f \in \ISF(A \to \RR)$ with the vector $(f(1), \dots, f(d))$.
So we can identify $\ISF(A \to \RR)$ with $\RR^d$.
Show that the topology induced by the $L^1$-norm on $\RR^d$ is the usual euclidean topology on $\RR^d$.
What is the unit ball in the $L^1$-norm shaped like?
\end{exercise}

\section{The integral in general}
The conclusion of the previous section, wherein we treated the integral on $L^1(X \to B)$, was really quite silly.
We want to integrate functions, not equivalence classes of Cauchy sequences of simple functions.
This is analogous to how we want to study real numbers, not equivalence classes of Cauchy sequences of rational numbers.
We need some sort of isomorphism which sends functions to members of $L^1$.

\begin{theorem}[fundamental theorem of integration, part II]
Suppose that $f_n \to f$ in $L^1$. Then there is a function $f'$ such that $f_n \to f'$ in measure and there is a subsequence of $f_{n_k}$ such that $f_{n_k} \to f'$ nearly uniformly, and hence almost pointwise.
\end{theorem}
\begin{proof}
We have to show that the $f_n$ are Cauchy in measure; the other claims follow from the first part of the fundamental theorem of integration.

To see that the $f_n$ are Cauchy in measure, we reason by contraposition, so suppose that we are given a subsequence $f_{k_n}$ and a $\varepsilon > 0$ such that for every $n,m$,
$$\{||f_{k_m} - f_{k_n}||_B > \varepsilon\} > \varepsilon.$$
Then
\begin{align*}
||f_{k_m} - f_{k_n}||_1 &= \int_X ||f_{k_m}(x) f_{k_n}(x)||_B~d\mu(x)\\
&\geq \int_{\{||f_{k_m} - f_{k_n}||_B > \varepsilon\}} ||f_{k_m}(x) f_{k_n}(x)||_B~d\mu(x)\\
&\geq \int_{\{||f_{k_m} - f_{k_n}||_B > \varepsilon\}} \varepsilon ~d\mu(x)\\
&= \varepsilon \int_{\{||f_{k_m} - f_{k_n}||_B > \varepsilon\}} ~d\mu(x)\\
&= \varepsilon |\mu|(\{||f_{k_m} - f_{k_n}||_B > \varepsilon\}) > \varepsilon^2 > 0.
\end{align*}
Therefore the $f_n$ are not Cauchy in $L^1$, so they do not converge in $L^1$.
\end{proof}

\begin{subsec}
Now if $f_n \to f$ in $L^1$ and $f_n \to f'$ in measure, then it is tempting to identify $f'$ with $f$, but we need to check that the choice of $L^1$ Cauchy sequence does not matter.
\end{subsec}

\begin{theorem}[fundamental theorem of integration, part III]
Suppose that $f_n \to f$ in $L^1$ and $f_n \to f'$ in measure.
If $g_n \to f$ in $L^1$, then $g_n \to f'$ in measure.
Conversely, if the $g_n$ are Cauchy in $L^1$ and $g_n \to f'$ in measure, then $g_n \to f$ in $L^1$.
\end{theorem}
\begin{proof}
Suppose that $g_n \to f$ in $L^1$.
Then the sequence $(f_1, g_1, f_2, g_2, \dots)$ is Cauchy in $L^1$, hence Cauchy in measure; but it has a subsequence which converges in measure to $f'$ in measure, so the mother sequence must also converge in measure to $f'$, and hence every subsequence, including the $g_n$, must converge in measure to $f'$.

As for the converse, we use part I of the fundamental theorem of integration to show that there are subsequences $f_{n_k}, g_{n_k}$ which converge nearly uniformly to $f'$, and are Cauchy in $L^1$.
Let $h_k = f_{n_k} - g_{n_k}$. Then the $h_k$ is Cauchy in $L^1$, converge nearly uniformly to $0$, and if $h_k \to 0$ in $L^1$ then the $f_{n_k}$ and $g_{n_k}$ are Cauchy equivalent.
\begin{lemma}
$h_k \to 0$ in $L^1$.
\end{lemma}
\begin{proof}
Let $\varepsilon > 0$, and choose $N$ so that if $n_1, n_2 \geq N$ then $||h_n - h_m||_1 < \varepsilon$. We claim that $||h_N||_1 \lesssim \varepsilon$ where the implied constant only depends on the sequence and not on the index $N$, so that if $n > N$ then
$$||h_n||_1 \leq ||h_n - h_N||_1 + ||h_N||_1 \lesssim \varepsilon.$$
But $h_N \in \ISF(X \to B)$, so the carrier $E$ of $h_N$ satisfies $\mu(E) < \infty$, and $h_N$ is bounded, thus $||h_N(x)|| \lesssim 1$, where the implied constant does not depend on $x$ or the index $N$, but only on the sequence.

Since $h_n \to 0$ nearly uniformly, there is a measurable set $F \subseteq E$ such that $|\mu|(E \setminus F) < \varepsilon$ and $h_n \to 0$ uniformly on $F$. Therefore
$$\int_{E \setminus F} ||h_n(x)||_B ~d|\mu|(x) \lesssim \int_{E \setminus F} ~|\mu|(x) = |\mu|(E \setminus F) < \varepsilon.$$
Meanwhile, if $N$ is large enough, then $||h_N(x)||_B < \varepsilon$ for every $x \in F$,
$$\int_F ||h_N(x)||_B~d|\mu|(x) < \varepsilon |\mu|(F) \leq \varepsilon |\mu|(E).$$
So
$$||h_N||_1 = \int_X ||h_N(x)||_B ~d|\mu|(x) \lesssim \varepsilon$$
which was to be shown.
\end{proof}

Hence the $f_{n_k}$ and $g_{n_k}$ are Cauchy equivalent.
Since the mother sequences $f_n$ and $g_n$ are Cauchy, if they have subsequences that are Cauchy equivalent, then the $f_n$ and $g_n$ are Cauchy equivalent, so since $f_n \to f$ in $L^1$, $g_n \to f$ in $L^1$.
\end{proof}

\begin{subsec}
Summarizing, if $f \in L^1$, then there is an $f' \in M$ with the following property: for every $L^1$ Cauchy sequence $f_n \in \ISF$ such that $f_n \to f$ in $L^1$, such that $f_n \to f'$ in measure, nearly uniformly along a subsequence, and almost pointwise along a subsequence.
Moreover, $L^1$ is the completion of $\ISF$, so such a $L^1$ Cauchy sequence must exist.
\end{subsec}

\begin{corollary}
Let $f \in M$, and suppose the $f_n \in \ISF$ are an $L^1$ Cauchy sequence. Then the following are equivalent:
\begin{enumerate}
\item $f_n \to f$ in measure.
\item $f_n \to f$ nearly uniformly.
\item $f_n \to f$ almost everywhere.
\end{enumerate}
\end{corollary}
\begin{proof}
That $1$ implies $2$ implies $3$ is the content of the fundamental theorem of integration.
Now if $f_n \to f$ almost everywhere, Egorov's theorem furnishes a subsequence $f_{n_k}$ which converges to $f$ nearly uniformly, hence in measure.
But the $f_n$ are Cauchy in $L^1$, hence in measure; if the mother sequence is Cauchy and a subsequence converges, the mother sequence converges, so $f_n \to f$ in measure.
\end{proof}

\begin{subsec}
Elements of $M$ are functions up to the equivalence relation of being equal almost everywhere.
That is,
$$M = \frac{\mathcal M}{\mathcal N}$$
where $\mathcal M$ is the space of all measurable functions and $\mathcal N$ is the space of measurable functions which are zero almost everywhere.
Therefore if $f_n \to f$ in $L^1$ and $f_n \to f'$ in measure (equivalently, nearly uniformly, or almost everywhere), we can actually identify $f$ with $f'$ and think of $f'$ as a ``function" by choosing a version of $f'$.
Henceforth we will not make a distinction between elements of $L^1$, elements $f$ of $M$ which admit an $L^1$ Cauchy sequence of simple functions which converge to $f$ in measure, and versions of $f$.
Therefore we are (finally!) ready to define the integral in general.
\end{subsec}

\begin{definition}
Let $f \in M(X \to B)$, and suppose that there is a $L^1$ Cauchy sequence $f_n \in \ISF(X \to B)$ such that $f_n \to f$ in measure. Then we say that $f \in L^1(X \to B)$, define for any measurable set $E$ the \dfn{integral}
$$\int_E f ~d\mu = \lim_{n \to \infty} \int_E f_n~d\mu,$$
and the \dfn{$L^1$ norm}
$$||f||_1 = \int_X ||f(x)||_B ~d|\mu|(x).$$
If the integral $\int_X f~d\mu$ exists, we say that $f$ is \dfn{integrable} or \dfn{summable}.
\end{definition}

\begin{theorem}
Let $f,g \in L^1(X \to B)$. Then:
\begin{enumerate}
\item \dfn{Linearity}: For every $c \in \CC$,
$$\int_X cf + g~d\mu = c\int_X f ~d\mu + \int_X g~d\mu.$$
\item The \dfn{triangle inequality}:
$$\left|\left|\int_X f(x) ~d\mu(x)\right|\right|_B \leq \int_X ||f(x)||_B~d|\mu|(x).$$
\item The \dfn{change-of-variables formula}: Let $(Y, \nu)$ be a measured space. Suppose that $h: Y \to X$ is a measurable map and $\mu$ is the pushforward measure $\mu = h_*\nu$. Then
$$\int_X f~d\mu = \int_Y f \circ h~d\nu.$$
\item If $B = \RR$ and $f \leq g$, then $\int f \leq \int g$.
\item If $E,F$ are disjoint measurable sets, then
$$\int_{E \cup F} f = \int_E f + \int_F f.$$
\item If $E \subseteq F$ are measurable sets, $B = \RR$, and $\mu$ is a nonnegative measure, then
$$\int_E f~d\mu \leq \int_F f~d\mu.$$
\item $\int ||f(x)||_B ~d\mu(x) = 0$ if and only if $f = 0$ almost everywhere.
\end{enumerate}
\end{theorem}
\begin{proof}
This follows from the previous version of the theorem by density in $L^1$.
\end{proof}

\begin{subsec}
We can extend the definition of the integral even further.
If $f \in M(X \to B)$ has a nonnegative version, we write $f \geq 0$.
\end{subsec}

\begin{definition}
Let $f \in M(X \to B)$, and assume that $f \geq 0$. Let $E$ be a measurable set. If for every $L^1$ Cauchy sequence $f_n \in \ISF(X \to B)$, $f_n$ does not converge to $1_E f$ in measure, then we write
$$\int_X f ~d\mu = \infty$$
provided that $\mu$ is a nonnegative measure.
\end{definition}

\begin{subsec}
Now if $f \in M(X \to \CC)$, we can write $f = f_a + if_b$ where $f_a, f_b$ are real-valued, and $\int f = \int f_a + i\int f_b$.
So integration of complex-valued functions reduces to integration of real-valued functions. Moreover, if $f$ is real-valued then we can write $f = f_+ - f_-$ where $f_\pm \geq 0$. So $\int f = \int f_+ - \int f_-$.
This makes sense even if one (but not both!) of the $\int f_\pm$ is infinite.
Thus the only measurable functions which cannot be integrated are those whose integrals would be $\infty - \infty$.
That's a far cry from the Riemann integral, whose definition was quite restricted!
\end{subsec}

\begin{subsec}
While in practice we identify functions which are equal almost everywhere, sometimes it is convenient to work with functions, rather than their equivalence classes.
Recall that $\mathcal M$ is the space of measurable functions; analogously we let $\mathcal L^1$ denote the space of functions whose equivalence classes are in $L^1$. If $f \in \mathcal L^1$, we let $[f]$ denote the equivalence class of $f$ and define
$$\int_E f ~d\mu = \int_E [f]~d\mu.$$
This definition then extends to those elements of $\mathcal M$ whose integral is not $\infty - \infty$.
Notice that $||\cdot||_1$ is a seminorm on $\mathcal L^1$, and a norm on $L^1$.
\end{subsec}

\begin{subsec}
Let us now recast the above in the language of probability theory.
\end{subsec}

\begin{definition}
Let $(\Omega, P)$ be a probability space.
Let $X$ be a random variable of type $B$ on $\Omega$.
The \dfn{expected value} of $X$ is
$$EX = \int_\Omega X~dP$$
provided that $X \in L^1$.
If in addition $X^2 \in L^1$ and $B = \RR$, then the \dfn{variance} of $X$ is
$$\Var X = E((X - EX)^2).$$
The \dfn{standard deviation} of $X$ is $\sqrt{\Var X}$.
\end{definition}

\begin{exercise}
\label{Chebyshev}
Let $\mu$ be a positive measure.
Prove \dfn{Chebyshev's inequality}, which says that if $f \in M$, then for any $t > 0$ and $p > 0$,
$$\mu(||f(x)||_B \geq t) \leq t^{-p} \int_{||f||_B \geq t} ||f||_B^p~d\mu.$$
Here $||f||_B \geq t$ is the set $\{x \in X: ||f(x)||_B \geq t\}$.
\end{exercise}

\begin{exercise}
Let $\delta_x$ be the Dirac measure at $x \in \RR$, as in Exercise \ref{Dirac measure}.
Show that every function $f: \RR \to B$ is Dirac measurable and compute the integral $\int_\RR f~d\delta_x$.
\end{exercise}

\begin{exercise}
Let $X$ be a random variable of type $\RR$. Show that
$$\Var X = E(X^2) - (EX)^2 \geq 0$$
with equality iff $X$ is almost surely constant, as long as the definition of $\Var X$ makes sense.
\end{exercise}

\begin{exercise}
\label{integrating a distribution}
Let $X$ be a random variable of type $\RR$ and distribution $\mu$. Show that
$$EX = \int_{-\infty}^\infty x ~d\mu(x)$$
as long as the definition of $EX$ makes sense.
\end{exercise}

\chapter{Properties of integration}
In the previous chapter we defined integration. Now we show that integration is quite robust; most importantly, it commutes with most types of limits.
Integration with Lebesgue measure also agrees with the Riemann integral whenever the Riemann integral is defined.

\section{Integrable functions}
Let us treat the properties of integrable functions.
Throughout this section, let $X = (X, \Sigma, \mu)$ be a complete measured space, $B$ a Banach space, and $L^1 = L^1(X \to B)$.
We view $L^1$ as the space of integrable functions $\mathcal L^1$ modulo the space of functions $f$ with $||f||_1 = 0$, but by the fundamental theorem of integration, $L^1$ is naturally isomorphic to the completion of the space $\ISF$ of integrable simple functions.

\begin{lemma}
Let $f_n$ be an $L^1$ Cauchy sequence and $f \in M$. Then $f_n \to f$ nearly uniformly iff $f_n \to f$ in measure iff $f_n \to f$ in $L^1$.
\end{lemma}
\begin{proof}
This was already true for $\ISF$, and $L^1$ is the completion of $\ISF$.
\end{proof}

\begin{lemma}
If $f_n \to f$ in $L^1$, then $\int f_n \to \int f$.
\end{lemma}
\begin{proof}
We have
$$\left|\left| \int_E f_n ~d\mu - \int_E f ~d\mu \right| \right|_B \leq \int_E ||f_n(x) - f(x)||_B ~d|\mu|(x) = ||f_n - f||_1$$
which converges to $0$.
\end{proof}

\begin{subsec}
If $f, f'$ are versions of the same element of $M$, then their carriers $C,C'$ are equal up to a set of measure zero; indeed, the set of points $x$ such that $f(x) = 0$ but $f'(x) \neq 0$ is null, but that set is $C \setminus C'$.
Thus we can speak of the carrier of an equivalence class of functions, which is a set modulo sets of measure zero.
\end{subsec}

\begin{lemma}
If $f \in L^1$, then the carrier of $f$ is $\sigma$-finite.
\end{lemma}
\begin{proof}
Let $f_n \in \ISF$, $f_n \to f$. Then the $f_n$ have finite-support carriers $C_n$, and the carrier of $f$ is contained in the union $\bigcup_n C_n$.
\end{proof}

\begin{lemma}
\label{L1 functions almost have finite carrier}
Let $f \in L^1$. Then for every $\varepsilon > 0$ there is a measurable set $E$ such that $|\mu|(E) < \infty$ and
$$\int_{X \setminus E} ||f(x)||_B ~d|\mu|(x) < \varepsilon.$$
\end{lemma}
\begin{proof}
Let $g \in \ISF$, $||f - g||_1 < \varepsilon$.
Let $E$ be the carrier of $g$. Then $g = 0$ on $X \setminus E$, so
$$\int_{X \setminus E} ||f(x)||_B ~d|\mu|(x) = \int_{X \setminus E} ||f(x) - g(x)||_B ~d|\mu|(x) \leq ||f - g||_1 < \varepsilon.$$
\end{proof}

\begin{definition}
Let $f \in M$. We say that $f$ is \dfn{almost bounded}, or $f \in L^\infty$, if there is a version of $f$ which is bounded.
In that case, we define the \dfn{$L^\infty$ norm} of $f$ by
$$||f||_\infty = \inf_{f'} \sup_{x \in X} ||f(x)||_B$$
where the $\inf$ is taken over all versions $f'$ of $f$ such that $f'$ is bounded.
\end{definition}

\begin{subsec}
We leave it to the reader to check that $L^\infty$ is a vector space and $||\cdot||_\infty$ is a norm.
\end{subsec}

\begin{lemma}
$L^\infty$ is a Banach space.
\end{lemma}
\begin{proof}
We are given an $L^\infty$ Cauchy sequence of $f_n \in L^\infty$, then we can choose bounded versions $f_n'$, and for almost every $x \in X$,
$$||f_n'(x) - f_m'(x)||_B \leq ||f_n - f_m||_\infty \to 0$$
so the $f_n'(x)$ form a Cauchy sequence in the Banach space $B$, and hence converge to a vector that we call $f(x)$.
We claim that $f_n' \to f$ almost uniformly; that is, there is a null set away from which $f_n' \to f$ uniformly.
Indeed, given $\varepsilon > 0$ we can find $N$ such that for almost every $x$ and every $n_1, n_2 > N$, $||f_{n_1}'(x) - f_{n_2}'(x)||_B < \varepsilon$; this implies that $||f_n'(x) - f(x)||_B < \varepsilon$ if $n > N$.
Therefore
$$||f_n - f||_\infty \leq \sup_x ||f_n'(x) - f(x)||_B < \varepsilon$$
where the $\sup$ is taken over all $x$ on the set on which $f_n' \to f$ uniformly, hence over almost every $x \in X$.
\end{proof}

\begin{subsec}
The space $\mathcal L^\infty$ is defined to be the space of all versions of all elements of $L^\infty$, and on $\mathcal L^\infty$, $||\cdot||_\infty$ is a seminorm. Its normalization is $L^\infty$.
\end{subsec}

\begin{subsec}
It is worth contrasting the norms $L^1$ and $L^\infty$. $L^1$ only cares about the ``area under the graph"; a function $f$ whose graph is a narrow but very tall spike is tiny in $L^1$. Meanwhile $L^\infty$ only cares about ``height of the graph"; that same function $f$ would have an enormous $L^\infty$ norm.
On the other hand, a function which is very wide but shallow would be tiny in $L^\infty$ but huge in $L^1$. TODO: Draw a picture.
Later we will define $L^p$ norms which serve as a ``weighted average" between the two extremes.
\end{subsec}

\begin{lemma}
The space $L^1 \cap L^\infty$ of almost bounded integrable (equivalence classes of) functions is dense in $L^1$.
\end{lemma}
\begin{proof}
One has $\ISF \subseteq L^1 \cap L^\infty \subseteq L^1$, but $\ISF$ is dense in $L^1$, so $L^1 \cap L^\infty$ is as well.
\end{proof}

\begin{subsec}
How are the $L^\infty$ and $L^1$ norms related?
Well, if the measure of $X$ is finite, then the graph of the function cannot be ``too wide", as our next lemma shows.
\end{subsec}

\begin{lemma}
If $\mu(X) < \infty$ then
$$||f||_1 \leq \mu(X) ||f||_\infty.$$
\end{lemma}
\begin{proof}
We check
$$||f||_1 \leq \int_X ||f(x)||~d\mu(x) \leq \int_X ||f||_\infty ~d\mu = ||f||_\infty \int_X ~d\mu = ||f||_\infty \mu(X).$$
Easy as that!
\end{proof}

\begin{subsec}
Conversely, if the graph of the function cannot be ``too skinny", then we have the opposite bound.
To make this precise, we need the notion of a ``granular measure".
\end{subsec}

\begin{definition}
A \dfn{granular measure} is a measure $\mu$ such that there is a $\delta > 0$ such that for every measurable set $E$, either $E = \emptyset$ or $|\mu|(E) \geq \delta$.
\end{definition}

\begin{subsec}
For example, counting measure is $\delta$-granular, with $\delta = 1$.
Another example is Lebesgue measure restricted to the $\sigma$-algebra generated by the intervals $[n, n+1]$, which is also $1$-granular.
\end{subsec}

\begin{lemma}
If $\mu$ is $\delta$-granular, then
$$||f||_\infty \leq \frac{||f||_1}{\delta}.$$
\end{lemma}
\begin{proof}
If $f = 0$ almost everywhere, then both sides of the claimed equation are $0$.
Otherwise, let $E_n = \{||f|| > ||f||_\infty - 1/n\}$; then $\mu(E_n) \geq \delta$ and $E_n \supseteq E_{n+1}$, so let $E = \bigcap_n E_n$; either $|\mu|(E_n) < \infty$ for some $n$ or $|\mu|(E_n) = \infty$ for all $n$.
In the latter case, there is an $n$ large enough that $||f||_\infty - 1/n > 0$ and
$$||f||_1 \geq \int_{E_n} ||f(x)||_B ~d|\mu|(x) \geq (||f||_\infty - \frac{1}{n}) |\mu|(E) = \infty$$
and there is nothing to prove. Otherwise, $|\mu|(E) = \lim_n |\mu|(E_n) \geq \delta$ and
$$||f||_1 \geq \int_E ||f(x)||~d|\mu|(x) \geq ||f||_\infty \delta,$$
proving the claim.
\end{proof}

\begin{subsec}
Let us now show that for Radon measures, and in particular Lebesgue measure, continuous functions are integrable on compact sets.
If the reader is unfamiliar with locally compact Hausdorff spaces, they may as usual take $X = \RR^d$ and $\mu$ Lebesgue measure.
\end{subsec}

\begin{definition}
Let $X$ be a locally compact Hausdorff space, and suppose that $\mu$ is a Radon measure on $X$.
A \dfn{locally integrable function} is a function $f$ such that for every compact set $K$, $f|K$ is an integrable function on $K$.
The space of locally integrable functions modulo null sets is denoted $L^1_l$.
A \dfn{almost locally bounded function} is a function $f$ such that for every compact set $K$, $f|K$ is almost bounded on $K$.
The space of almost locally bounded functions modulo null sets is denoted $L^\infty_l$.
\end{definition}

\begin{lemma}
Let $X$ be a locally compact Hausdorff space, and suppose that $\mu$ is a Radon measure on $X$.
Let $f$ be a continuous function; then $f \in L^1_l \cap L^\infty_l$.
\end{lemma}
\begin{proof}
First note that every continuous function is bounded on a compact set $K$.
Therefore $f \in L^\infty_l$, and since $\mu$ is Radon, $|\mu|(K) < \infty$; therefore
$$\int_K ||f(x)||~d|\mu|(x) \leq \sup_{x \in K} ||f(x)||\cdot |\mu|(K) < \infty.$$
Therefore $f \in L^1_l$.
\end{proof}

\begin{exercise}
Show that every set with Jordan content (see Exercise \ref{Jordan content 1}) is Borel.
\end{exercise}

\section{Indefinite integrals}
In calculus, one defined the indefinite integral $g$ of a continuous function $f: [a, b] \to \RR$ by the relation
$$g(x) = \int_a^x f(t)~dt.$$
By the fundamental theorem of calculus, $g$ is differentiable and $g' = f$.
So we would like to define the indefinite integral of an arbitrary measurable function, and we would like it to have good regularity properties, but this is problematic; we used the order structure of $\RR$ to choose the interval $[a, x]$, but there is no such thing as an order on an arbitrary measure space, and there is no such thing as a differentiable function on an arbitrary measure space either.

But what if we thought of the indefinite integral as a function of the \emph{set} $[a, x]$ rather than the number $x$?
As it turns out, this will fix both problems, and also the pesky issue of needing to choose $a$ (the somewhat arbitrary choice of $a$ being the reason for the constant of integration that has caused calculus students so much grief).

\begin{subsec}
Throughout, let $X = (X, \Sigma, \mu)$ be a complete measured space, with $\mu$ valued in $(-\infty, \infty]$ or $\CC$, and $B$ a Banach space.
\end{subsec}

\begin{definition}
Let $f \in M$ and suppose that $\int f$ is defined. For every measurable set $E$, define
$$\nu(E) = \int_E f~d\mu.$$
We call $\nu$ the \dfn{indefinite integral} of $f$.
We also write $f = d\nu/d\mu$ and call $f$ the \dfn{Radon-Nikodym derivative} of $\nu$.
If $\nu$ is a measure which is an indefinite integral, we say that $\nu$ is \dfn{Radon-Nikodym differentiable}.
\end{definition}

\begin{subsec}
The hypothesis that $\int f$ is defined rules out the possibility that $\nu(E) = \infty - \infty$.
It is satisfied, for example, if $f \in L^1$ or $f \geq 0$.
\end{subsec}

\begin{lemma}
Let $f,g \in M$. Suppose that the indefinite integrals $\nu_f,\nu_g$ of $f,g$ are defined. Then for every measurable set $E$,
$$||\nu_f(E) - \nu_g(E)||_B \leq ||f - g||_1.$$
\end{lemma}
\begin{proof}
One checks
$$||\nu_f(E) - \nu_g(E)||_B = \left|\left| \int_E f - g ~d\mu\right|\right| \leq ||f - g||_1$$
which proves the claim.
\end{proof}

\begin{theorem}
Suppose that $f \in L^1$, and $\nu$ is the indefinite integral of $f$. Then $\nu$ is a finite measure.
\end{theorem}
\begin{proof}
Finiteness follows from $f \in L^1$, so we just need to check that $\nu$ is countably additive.
We first check this when $f \in \ISF$. Indeed, if $f = b1_E$ is the canonical representation of $f$ and the $F_j$ are a sequence of disjoint measurable sets with union $F$, then
$$\nu(F) = b\mu\left(E \cap \bigcup_j F_j\right) = \sum_j b\mu(E \cap F_j) = \sum_j \nu(F_j).$$
Otherwise, $f$ is a linear combination of functions with canonical representation of the form $b1_E$ and the claim still follows.

Now if $f \in L^1$, then for every $\varepsilon > 0$ there is a $g \in \ISF$ such that $||f - g||_1 < \varepsilon$; let $\rho$ be the indefinite integral of $g$. Then for every measurable set $E$, $||\nu(E) - \rho(E)||_B \leq ||f - g||_1 < \varepsilon$.

If all but finitely many of the $F_j$ are empty, then there is an $N$ such that
$$\nu(F) = \int_F f ~d\mu = \sum_{j<N} \int_{F_j} f~d\mu = \sum_{j<N} \nu(F_j) = \sum_j \nu(F_j).$$
So it suffices to show that as $N \to \infty$, the partial sum $\sum_{j<N} \nu(F_j)$ converges to $\nu(F)$.
Let $F^N = \bigcup_{j<N} F_j$, so $\nu(F^N) = \sum_{j<N} \nu(F_j)$.

We already showed that $\rho$ is a measure, so if $N$ is large enough then for every $n > N$,
$$||\rho(F) - \rho(F^N)||_B < \varepsilon.$$
In particular,
\begin{align*}
||\nu(F) - \nu(F^N)||_B \leq ||\nu(F) - \rho(F)||_B + ||\rho(F) - \rho(F^N)||_B + ||\rho(F^N) - \nu(F^N)||_B < 3\varepsilon.
\end{align*}
This implies $\nu(F^N) \to \nu(F)$.
\end{proof}

Radon-Nikodym differentiable measures have a particularly easy-to-understand total variation.
\begin{theorem}
Let $\nu$ be a Radon-Nikodym differentiable measure. Then for any measurable set $E$,
$$|\nu|(E) = \int_E \left|\left|\frac{d\nu}{d\mu}(x)\right|\right|~d|\mu|(x).$$
\end{theorem}
\begin{proof}
Let $f = d\nu/d\mu$.

Suppose that $E$ is a measurable set and $E = \bigcup_i E_i$, a finite disjoint union. Then
$$\sum_i ||\nu(E_i)|| = \sum_i \left|\left| \int_{E_i} f~d\mu\right|\right| \leq \int_E ||f(x)||~d\mu(x).$$
Taking the supremum over all such finite disjoint unions we see that $|\nu|(E) \leq \int_E ||f||$.

We first check the converse when $f \in \ISF$. Let $f = \sum_{i \leq k} b_i 1_{F_i}$ where the $F_i$ are disjoint.
Let $F = \bigcup_i F_i$.
Let us write $E \cap F_i = \bigcup_{j \leq n_i} G_{ij}$ where the $G_{ij}$ are disjoint. Then
$$|\nu|(E) \geq \sum_{i,j} ||\nu(G_{ij})||_B = \sum_{i,j} ||b_i||_B |\mu(G_{i,j})| = \sum_i ||b_i||_B \sum_j |\mu(G_{ij})|.$$
That is,
$$|\nu|(E) \geq \int_E ||f(x)|| ~d|\mu|(x).$$

In general, if $f,g \in L^1$ are the derivatives of $\nu,\lambda$ respectively, then
$$||\nu|(E) - |\lambda||(E) \leq |\nu - \lambda|(E) \leq \int_E ||(f - g)(x)||_B ~d|\mu|(x) \leq ||f - g||_{L^1},$$
by the reverse triangle inequality, Theorem \ref{reverse triangle inequality}.
Now a straightforward approximation argument shows that the ISF case extends to all of $L^1$.
\end{proof}

\begin{definition}
A measure $\nu$ is \dfn{absolutely continuous} with respect to $\mu$ if for every $\varepsilon > 0$ there is $\delta > 0$ such that for every measurable set $E$, if $|\mu|(E) < \delta$, then $|\nu|(E) < \varepsilon$.
\end{definition}

\begin{theorem}
\label{indefinite integral is abs cts}
For every $f \in L^1$, the indefinite integral of $f$ is absolutely continuous.
\end{theorem}
\begin{proof}
Let $\varepsilon > 0$ be given.
Since $\ISF \subseteq L^1 \cap L^\infty$, there is $g \in L^\infty$ such that $||f - g||_1 \leq \varepsilon/2$.
Suppose that $E$ is a measurable set such that $|\mu|(E) < \varepsilon/2||g||_\infty$. Then
\begin{align*}
\int_E ||f(x)|| ~d|\mu|(x) &\leq ||f - g||_1 + \int_E ||g(x)|| ~d|\mu|(x) \\
&\leq ||f - g||_1 + |\mu|(E)||g||_\infty \leq \varepsilon
\end{align*}
which completes the proof.
\end{proof}

\begin{subsec}
Later we will show the Radon-Nikodym theorem, which says that a measure $\nu$ is absolutely continuous iff every $\mu$-null set is automatically $\nu$-null, which happens iff $\nu$ is differentiable.
\end{subsec}


\section{Convergence theorems}
One of the cornerstone of calculus and its applications is the ability to interchange an integral with another sort of limit.
Unfortunately, this sort of manuever is not valid in general.

\begin{example}
Let $f_n = 1_{[n, n + 1]}$. Then $f_n \to 0$ pointwise but
$$\lim_{n \to \infty} \int_{-\infty}^\infty f_n(x) ~dx = 1.$$
\end{example}

\begin{subsec}
Roughly speaking, there are two settings in which it is acceptable to commute an integral with a limit.
For one, if all functions involved are ``dominated" by some function in $L^1$, then it is usually safe to do so; one way to make this precise is the dominated convergence theorem.
\end{subsec}

\begin{theorem}[dominated convergence]
Let $f_n \in L^1(X \to B)$, and suppose that $f_n \to f$ almost pointwise. If there is a $g \in L^1(X \to [0, \infty))$ such that for every $n$ and almost every $x \in X$,
$$||f_n(x)|| \leq g(x),$$
then $f \in L^1(X \to B)$ and $f_n \to f$ in $L^1(X \to B)$.
\end{theorem}
\begin{proof}
By Lemma \ref{L1 functions almost have finite carrier}, there is a measurable set $E$ with $|\mu|(E) < \infty$ such that
$$\int_{X \setminus E} g(x) ~d|\mu|(x) < \varepsilon.$$
Thus
$$\int_{X \setminus E} ||f_n(x) - f_m(x)||_B \leq 2\int_{X \setminus E} g(x) ~d|\mu|(x) < 2\varepsilon.$$
Let $\nu$ be the indefinite integral of $g$.
By Theorem \ref{indefinite integral is abs cts}, there is $\delta > 0$ so small that if $|\mu|(G) < \delta$ then $|\nu|(G) < \varepsilon$.
Since $E$ has finite measure, Egorov's theorem implies that there is a measurable set $F \subseteq E$ such that $|\mu|(E \setminus F) < \delta$ and $f_n \to f$ in $L^\infty(F)$.
But then $|\nu|(E \setminus F) < \varepsilon$, and so
$$\int_{E \setminus F} ||f_n - f_m(x)||_B \leq 2\int_{E \setminus F} g(x) ~d|\mu|(x) = 2|\nu|(E \setminus F) < 2\varepsilon.$$
In particular, $\int_{X \setminus F} ||f_n - f_m||_B ~d|\mu| < 4\varepsilon$.
Since $F$ has finite measure and $f_n \to f$ in $L^\infty(F)$, $f_n \to f$ in $L^1(F)$ and so $(f_n)$ is Cauchy in $L^1$; so choose $N$ so large that if $n,m \geq N$ then
$$||f_n - f_m||_{L^1(F)} < \varepsilon.$$
Then
$$||f_n - f_m||_1 \leq ||f_n - f_m||_{L^1(F)} + \int_{X \setminus F} ||f_n - f_m||_B ~d|\mu| < 5\varepsilon$$
so $(f_n)$ is Cauchy in $L^1$.
Since $f_n \to f$ almost pointwise, it follows that $f_n \to f$ in $L^1$.
\end{proof}

\begin{example}
We will compute
$$\lim_{n \to \infty} \int_0^n \left(1 + \frac{x}{n}\right)^n e^{-2x} ~dx.$$
First we compute
$$\lim_{n \to \infty} \left(1 + \frac{x}{n}\right)^n e^{-2x} = e^x e^{-2x} = e^{-x}.$$
Now, we have a pesky changing bound of integration, so we write
$$\lim_{n \to \infty} \int_0^n \left(1 + \frac{x}{n}\right)^n e^{-2x} ~dx = \lim_{n \to \infty} \int_0^\infty 1_{[0, n]}(x) \left(1 + \frac{x}{n}\right)^n e^{-2x} ~dx.$$
Since the integrand converges to $e^{-x}$, after finitely many $n$ (which are are allowed to discard, since we only care about the limiting behavior), we get
$$1_{[0, n]}(x) \left(1 + \frac{x}{n}\right)^n e^{-2x} \leq 2e^{-x}.$$
On the other hand,
$$\int_0^\infty e^{-x} ~dx = 1,$$
so $x \mapsto 2e^{-x}$ is in $L^1$ and by dominated convergence,
$$\lim_{n \to \infty} \int_0^n \left(1 + \frac{x}{n}\right)^n e^{-2x} ~dx = \int_0^\infty \lim_{n \to \infty} 1_{[0, n]}(x) \left(1 + \frac{x}{n}\right)^n e^{-2x} ~dx = \int_0^\infty e^{-x} ~dx = 1$$
as desired.
These sorts of problems are very common on preliminary exams for graduate students, so the reader should probably master them.
\end{example}

\begin{subsec}
The other situation in which it is acceptable to interchange an integral with a limit is when we can strongly use the order structure of $\RR$ in teh codomain.
So, we will need to restrict to the case when $B = [0, \infty)$ for the rest of the section, and thus formulate the so-called monotone convergence theorem.
\end{subsec}

TODO: Monotone convergence

\begin{corollary}
\label{positive summation}
Let $f_n \geq 0$ be nonnegative integrable functions and $\mu$ a nonnegative measure on $X$. Then
$$\int_X \sum_n f_n~d\mu = \sum_n \int_X f_n~d\mu.$$
\end{corollary}
\begin{proof}
The sequence of partial sums is increasing, so we can apply monotone convergence.
\end{proof}

\begin{corollary}
Let $f \geq 0$ be a nonnegative measurable function and $\mu$ a nonnegative measure. Then
$$\int_X f~d\mu = \sup_s \int_X s~d\mu$$
where the supremum is taken over all nonnegative $s \in \ISF(X \to [0, \infty))$.
\end{corollary}
\begin{proof}
We first show that there is a sequence of simple functions $\leq f$ converging to $f$ monotonically.
Fix $n$, and let $A_n = \{0, 1/n, 2/n, \dots, n - 2/n, n - 1/n, n\}$.
For each $y \in A_n$, let $E_y^n = f^{-1}([y, y + 1/n))$. Let
$$f_n = \sum_{y \in A_n} y1_{E_y^n}.$$
Now let $s_n = \max_{m \leq n} f_m$.
Then $s_n$ is simple and and $s_n \leq s_{n+1}$, and $s_n \to f$ almost everywhere.
So
$$\lim_{n \to \infty} \int_X s_n~d\mu = \int_X f~d\mu$$
by monotone convergence. Therefore
$$\int_X f~d\mu \leq \sup_s \int_X s~d\mu.$$
Monotonicity of the integral implies the other direction.
\end{proof}


\begin{exercise}
Let $f$ be a measurable $B$-valued function. Show that if there $g \in L^1(X \to [0, \infty))$ with $||f||_B \leq g$ almost everywhere, then $f \in L^1$.
\end{exercise}

\begin{exercise}
Suppose that $|\mu|(X) < \infty$ (for example, $\mu$ is a probability measure). Let $(f_n)$ be a sequence of functions in $L^\infty$ such that there is $C > 0$ such that for every $n$, $||f_n||_{L^\infty} \leq C$.
Show that if $f_n \to f$ almost pointwise, then $f_n \to f$ in $L^1$.
\end{exercise}

\begin{exercise}
Consider the \dfn{gamma function}
$$\Gamma(z) = \int_0^\infty x^{z - 1} e^{-x} ~dx.$$
Show that $\Gamma$ is well-defined when $z > 0$ and is infinitely differentiable there. Then show that $\Gamma(n + 1) = n!$ if $n \in \NN$.
\end{exercise}

\begin{exercise}
Show that
$$\lim_{n \to \infty} \int_0^1 \frac{n^{3/2}x}{1 + n^2x^2} ~dx = 0.$$
\end{exercise}

\section{Product measures}
Previous our development of the Lebesgue measure has been totally one-dimensional: we have defined the measure of a measurable subset of the line $\RR$.
We would like to do the same for higher-dimensional spaces.

We first review the notion of a product set. Suppose that we are given sets $X_\alpha$, where $\alpha$ ranges over a set $A$.
The \dfn{Cartesian product} $\prod_{\alpha \in A} X_\alpha$ is by definition the set of maps $x: A \to \bigcup_{\alpha \in A} X_\alpha$ such that for every $a \in A$, $x(\alpha) \in X_\alpha$.
We usually write $x_\alpha$ or $\pi_\alpha(x)$ to mean $x_\alpha$. The maps
$$\pi_\beta: \prod_{\alpha \in A} X_\alpha \to X_\beta$$
are known as \dfn{canonical projection}s and the sets $X_\alpha$ are known as \dfn{factors}.

We mainly will be interested in the case when $A = \{1, \dots, n\}$ is a finite set, in which case we write $X_1 \times \cdots X_n$ to mean the product of sets $X_i$, $i \in A$.
An element of $X_1 \times \cdots \times X_n$ can be written as an $n$-tuple $(x_1, \dots, x_n)$, where $x_i \in X_i$.
For example, $\RR^n$ is a product of $n$ copies of $\RR$, and its elements are $n$-tuples of real numbers.

\begin{lemma}
Suppose that $X_\alpha$ are nonempty sets. Then $\prod_\alpha X_\alpha$ is nonempty.
\end{lemma}
\begin{proof}
We first note that we can assume that the $X_\alpha$ are disjoint. Indeed, if they are not, we can replace them with
$$X_\alpha' = X_\alpha \times \{\alpha\}.$$
Then elements of $X_\alpha'$ are pairs $(x, \alpha)$ where $x \in X_\alpha$.
There is an obvious bijection $X_\alpha \to X_\alpha'$, $x \mapsto (x, \alpha)$, so we identify the two sets $X_\alpha$ and $X_\alpha'$.
Henceforth we replace $X_\alpha$ with $X_\alpha$ and hence assume the $X_\alpha$ are disjoint.

Define a map $f: \bigcup_{\alpha \in A} X_\alpha \to A$ by declaring that if $x \in X_\alpha$ then $f(x) = \alpha$.
Since the $X_\alpha$ are all nonempty, $f$ is surjective.
By the axiom of choice, Axiom \ref{axiom of choice}, there is an injective map $g: A \to \bigcup_{\alpha \in A} X_\alpha$ such that $f \circ g$ is the identity, and so $g(\alpha) \in X_\alpha$.
Define an element $x$ of $X_\alpha$ by letting $x_\alpha = g(\alpha)$.
\end{proof}
If $A$ is \emph{finite} -- the case that is the most interesting to us -- then the use of the axiom of choice in the above argument is unnecessary (but otherwise it cannot be avoided, because if every product of nonempty sets is nonempty, then the axiom of choice is necessarily true).
The use of the axiom of choice in the above argument is a hint that infinite products may be rather ill-behaved in measure theory.

Having discussed Cartesian products of sets, we now move on to products of measurable spaces.
\begin{definition}
Let $(X_\alpha, \Sigma_\alpha)$ be measurable spaces.
A \dfn{measurable rectangle} in $\prod_\alpha X_\alpha$ is a Cartesian product $\prod_\alpha Y_\alpha$, where $Y_\alpha \in \Sigma_\alpha$ and all but finitely many of the $Y_\alpha$ are equal to $X_\alpha$.
The set of measurable rectangles is denoted $\bigoplus_\alpha \Sigma_\alpha$.
\end{definition}

The measurable rectangles do not form a $\sigma$-algebra in general.
For example, in $\RR^2$, the diagonal $\{(x, x): x \in \RR\}$ is not a rectangle, but will be in the $\sigma$-algebra generated by the rectangles, as we will later show.

The rather awkward requirement that finitely many of the $Y_\alpha$ are equal to the $X_\alpha$ can be explained by the following lemma.

\begin{lemma}
Let $(X_\alpha, \Sigma_\alpha)$ be measurable spaces.
Then $\bigoplus_m \Sigma_m$ is a semiring in $\prod_m X_m$.
\end{lemma}
\begin{proof}
Let $E, F$ be measurable rectangles.
Since all but finitely many of the $E_\alpha$ are $X_\alpha$, we can rename those $\alpha$ such that $E_\alpha \neq X_\alpha$ to be natural numbers.
That is, the only $E_\alpha$ which are not $X_\alpha$ will be called $E_1, \dots, E_m$.
Then if any unrenamed $\alpha$ has $F_\alpha \neq X_\alpha$, we can rename those $\alpha$ to $m+1, \dots, n$.
Thus, we can assume that
$$A = \{1, \dots, n\} \cup B$$
where for every $\beta \in B$, $E_\beta = F_\beta = X_\beta$.
One can then ignore the $E_\beta$ and $F_\beta$ entirely, and so assume that $B = \emptyset$.
Then, arguing by induction, one can assume that $n = 2$.
So assume that $E = E_1 \times E_2$ and $F = F_1 \times F_2$.

Now products commute with intersections, so $E \cap F$ is also a product of measurable sets, hence a measurable rectangle.
One similarly checks that
$$(E_1 \times E_2) \setminus (F_1 \times F_2) = (E_1 \times (E_2 \setminus F_2)) \cup (E_1 \setminus F_1) \times (E_2 \cap F_2).$$
The above union is disjoint.
\end{proof}

Therefore it is reasonable to want to define a premeasure on $\bigoplus_m E_m$, which we do shortly.

\begin{definition}
Let $(X_\alpha, \Sigma_\alpha)$ be measurable spaces, and let $X = \prod_\alpha X_\alpha$.
The \dfn{product $\sigma$-algebra} $\bigotimes_\alpha \Sigma_\alpha$ is the $\sigma$-algebra on $X$ generated by measurable rectangles in $X$.
We call $(X, \bigotimes_\alpha \Sigma_\alpha)$ the \dfn{product measurable space} of the $(X_\alpha, \Sigma_\alpha)$.
\end{definition}

Let $(\prod_\alpha X_\alpha, \bigotimes_\alpha \Sigma_\alpha)$ be a product measurable space. We will usually just denote this space by $\prod_\alpha X_\alpha$, leaving $\bigotimes_\alpha \Sigma_\alpha$ understood, since usually $\bigotimes_\alpha \Sigma_\alpha$ is the only interesting $\sigma$-algebra on $\prod_\alpha X_\alpha$.

We leave it to the categorically-minded reader to check that the product measurable space satisfies the universal property of products, and leave everyone else to quizzically wonder what such a sentence means.
This is another sign that our definition of measurable space, with its bizarre clause that all but finitely many of the factors are trivial, is ``correct".

We recall that a measure $\mu$ is complex-valued if for every measurable $E$, $\mu(E)$ is a complex number or $\infty$.
We will restrict to complex-valued measures because we need to be able to multiply the measures of sets.
Actually, if $\mu$ is complex-valued, then we can define its \dfn{complex conjugate} $\overline \mu$ by $\overline \mu(E) = \overline{\mu(E)}$.
Then we can define the \dfn{real part} $\Re \mu = (\mu + \overline \mu)/2$ and \dfn{imaginary part} $\Im \mu = (\mu - \overline \mu)/2i$.
Then $\mu = \Re \mu + i\Im \mu$.
Thus whenever we work with complex-valued measures, we can replace them with real-valued measures whenever necessary.
For a real-valued measure, we define $\mu_+ = (\mu + \mu)/2$ and $\mu_- = (\mu - \mu)/2$, thus $\mu_\pm$ are nonnegative measures and $\mu_+ - \mu_- = \mu$.
So, when working with products of measured spaces, we will state theorems that are for complex-valued measures, but then prove them for nonnegative measures, since every complex-valued measure can be written as a sum of nonnegative measures.

\begin{definition}
Let $(X_1, \Sigma_1, \mu_1), \dots, (X_n, \Sigma_m, \mu_n)$ be measured spaces, where all the $\mu_m$ are complex-valued measures.
We define a function $\bigoplus_m \mu_m = \mu_1 \oplus \cdots \oplus \mu_n$ on $\bigoplus_m \Sigma_m$ by
$$\left(\bigoplus_m \mu_m\right)(E) = \mu_1(E_1)\mu_2(E_2) \cdots \mu_n(E_n).$$
We take the convention $0 \times \infty = 0$ whenever necessary.
\end{definition}

We note that if we have an \emph{infinite} collection of measured spaces $(X_\alpha, \Sigma_\alpha, \mu_\alpha)$, $\alpha \in A$ it is reasonable to define $\bigoplus_\alpha \mu_\alpha$ whenever we can guarantee that the infinite product $\prod_\alpha \mu_\alpha(E_\alpha)$ converges.
For example this happens if, for every $\alpha$, $\mu_\alpha$ is a probability measure.
However, this case can be rather tricky, due to the technicalities in the definition of a product of infinitely many measurable spaces.
We discuss this in more detail in Example \ref{cantor measure}.

\begin{lemma}
\label{product premeasure is a premeasure}
Let $(X_1, \Sigma_1, \mu_1), \dots, (X_n, \Sigma_m, \mu_n)$ be measured spaces, where all the $\mu_m$ are complex-valued measures.
Then $\bigoplus_m \mu_m$ is a premeasure on $\bigoplus_m \Sigma_m$.
\end{lemma}
\begin{proof}
We must show that $\bigoplus_m \mu_m$ is $\sigma$-additive, and it suffices to check when $n = 2$, by induction.
By the usual reduction we can assume that the $\mu_m$ are nonnegative.
In that case we change notation and write $\eta = \mu \oplus \nu$, where $(X, \mu)$ and $(Y, \nu)$ are measured spaces.

Suppose that $E \times F$ is a rectangle which is a disjoint union of rectangles $E_n \times F_n$.
Then
$$1_E(x) 1_F(y) = 1_{E \times F}(x, y) = \sum_{n=1}^\infty 1_{E_n \times F_n}(x, y) = \sum_{n=1}^\infty 1_{E_n}(x) 1_{F_n}(y).$$
Therefore for any $x$,
$$1_E(x) \nu(F) = 1_E(x) \int_Y 1_F(y)~d\nu(y) = \int_Y \sum_{n=1}^\infty 1_{E_n}(x) 1_{F_n}(y) ~d\nu(y).$$
Thus by Corollary \ref{positive summation},
$$1_E(x) \nu(F) = \sum_{n=1}^\infty 1_{E_n}(x) \int_Y 1_{F_n}(y)~d\nu(y) = \sum_{n=1}^\infty 1_{E_n}(x)\nu(F_n).$$
Applying Corollary \ref{positive summation} again we see that
$$\eta(E \times F) = \mu(E) \nu(F) = \sum_{n=1}^\infty \mu(E_n) \nu(F_n) = \sum_{n=1}^\infty \eta(E_n \times F_n).$$
This is what we needed to prove.
\end{proof}

\begin{corollary}
Let $(X_1, \Sigma_1, \mu_1), \dots, (X_n, \Sigma_m, \mu_n)$ be measured spaces, where all the $\mu_m$ are complex-valued measures.
Then $\bigoplus_m \mu_m$ extends to a measure on $\bigotimes_m \Sigma_m$, which is unique and $\sigma$-finite if the $\mu_m$ are all $\sigma$-finite.
\end{corollary}
\begin{proof}
Existence is obvious by Lemma \ref{product premeasure is a premeasure} and the Carath√©odory construction.
As for uniqueness, we use $\sigma$-finiteness of $\mu_m$ to find measurable sets $E_m^k \subseteq X_m$ such that $E_m^k \subseteq E_m^{k+1}$, $\bigcup_k E_m^k = X_m$, and $\mu_m(E_m^k) < \infty$.
Then $\prod_m E_m^k \subseteq \prod_m E_m^{k+1}$, $\bigoplus_m \mu_m(\prod_m E_m^k) = \prod_m \mu_m(E_m^k) < \infty$, and $\bigcup_k \prod_m E_m^k = \prod_m X_m$.
This implies that the extension of $\bigoplus_m \mu_m$ to a measure on $\bigotimes_m \Sigma_m$ is $\sigma$-finite and therefore unique.
\end{proof}

\begin{definition}
Let $(X_1, \Sigma_1, \mu_1), \dots, (X_n, \Sigma_m, \mu_n)$ be measured spaces, where all the $\mu_m$ are complex-valued measures.
Let $\bigotimes_m \mu_m = \mu_1 \otimes \cdots \mu_n$ be the extension of the premeasure $\bigoplus_m \mu_m$ to $\bigotimes_m \Sigma_m$.
We call $\bigotimes_m \mu_m$ the \dfn{product measure} of the $\mu_m$ and $(\prod_m X_m, \bigotimes_m \Sigma_m, \bigotimes_m \mu_m)$ the \dfn{product measured space}.
\end{definition}

Let us give some examples of product measures.
We first consider the simplest example, which any reader who has played a children's card game is familiar with.

\begin{example}
\label{card games}
Let $A = \{1, \dots, n\}$, equipped with the $\sigma$-algebra consisting of \emph{every} subset of $A$, and consider a function $\beta: A \to [0, 1]$ such that $\sum_{m=1}^n \beta(m) = 1$.
Then $\beta$ defines a probability measure $\mu$ by
$$\mu(\{a_1, \dots, a_k\}) = \sum_{j=1}^k \beta(a_j).$$
For example if $\beta = 1/n$, then $\mu$ is the \dfn{uniform probability measure} which sends every set $E$ to its cardinality divided by $n$.
If one has a set of $n$ cards, and the probability of drawing card $m$ is $\beta(m)$, then $\mu(E)$ is the probability of drawing a card in the set $E$.

Now we consider the Cartesian power $A^\ell = A \times \cdots \times A$ ($\ell$ factors).
Elements of $A^\ell$ are vectors of $\ell$ elements of $A$, and if $\mu^\ell = \bigotimes_\ell \mu$ is the product measure on $A^\ell$, then $\mu^\ell(E_1 \times E_2 \times \cdots \times E_\ell)$ can be interpreted as the probability of first drawing a card in $E_1 \subseteq A$, then in $E_2 \subseteq A$, and so on, and then in $E_\ell \subseteq A$, with replacement.
In particular, if $E^\ell = E \times \cdots \times E$ is the Cartesian power of a set $E \subseteq A$, then $\mu^\ell(E^\ell) = \mu(E)^\ell$ is the probability of drawing a card in $E$ $\ell$ times in a row, with replacement.
\end{example}

\begin{example}
\label{cantor measure}
Let $A, \beta$ be as in Example \ref{card games}.
Now let us consider an infinitely long game, where one draws an infinite sequence of cards (the logicians would say that the player draws $\omega$ cards, because of TODO:Appendix) with replacement.
Let $A^\omega$ be the set of sequences with values in $A$, viewed as a measurable space by endowing it with the $\sigma$-algebra generated by the measurable rectangles.
By a cardinality argument similar to the one given in Lemma \ref{Borel sigma algebra}, one can show that not every subset of $A^\omega$ is measurable.
On the other hand, the reader who is familiar with Cantor spaces (TODO:Appendix), and with the notion of the product of topological spaces (TODO:Appendix), will check that if we endow each copy of $A$ with the discrete topology (which is its unique Hausdorff topology) and then endow $A^\omega$ with the product topology, $A^\omega$ is Cantor, and every Borel set is measurable (and conversely, that every measurable set is Borel).

Since $\mu$ is probability, an infinite product of numbers $\mu(E_n)$ will converge. Therefore if $E$ is a rectangle in $A^\omega$, and $\pi_n$ is the canonical projection onto the $n$th factor,
$$\mu^\omega(E) = \prod_n \mu(\pi_n(E))$$
is well-defined, and the reader can check (using the fact that for all $n$ large enough, $\mu(\pi_n(E))$ must be either $0$ or $1$ -- why?) that $\mu^\omega$ is a premeasure on the measurable rectangles, and hence a Borel probability measure.
In the case that $n = 2$ and $\mu$ is uniform (so $\beta = 1/2$), then we say that $\mu^\omega$ is the \dfn{standard Cantor measure}.
It is of essential importance in probability theory and logic, among other fields.
\end{example}

Example \ref{cantor measure} motivates the idea that the product of Borel $\sigma$-algebras should be the Borel $\sigma$-algebra of the product spaces.
Unfortunately, this is not true in general.
We include the following example for the reader's amusement, but it is not terribly important and can be omitted.

\begin{example}
Let $\kappa$ be an uncountable cardinal as in TODO:Appendix, let $A = \{1, 2\}$ with its discrete topology, and let $X = A^\kappa$ be the Cartesian power, consisting of one factor of $A$ for each ordinal of cardinality less than $\kappa$. Let $\pi_\alpha$ be projection onto the $\alpha$th factor.
Let $\Delta$ be the diagonal, so $x \in \Delta$ iff there is a $y \in A$ for every $\alpha < \kappa$, $\pi_\alpha(x) = y$.

Since $X$ is a product of discrete (hence Hausdorff) spaces, $X$ is Hausdorff, so $\Delta$ is closed TODO:Appendix and hence Borel.
On the other hand, if $\Delta$ was measurable, then (as the set-theoretically minded reader can check) for all but countably many $\alpha$, $\pi_\alpha(\Delta) = A$, contradicting the fact that there are uncountably many $\alpha$ and $\pi_\alpha(\Delta) = \{y\}$.
\end{example}

The above example is highly pathological.
The below lemma covers most interesting cases.
We remind the reader that if $X_m$ are metric spaces with metrics $d_m$ then $\prod_m X_m$ can be given the metric
\begin{equation}
\label{max metric}
d(x, y) = \max_m d_m(\pi_m(x), \pi_m(y)).
\end{equation}

\begin{lemma}
\label{borel products}
Let $X_1, \dots, X_n$ be separable metric spaces.
Then the Borel $\sigma$-algebra on $\prod_m X_m$ is the product of the Borel $\sigma$-algebras on $X_m$.
\end{lemma}
\begin{proof}
By induction we can assume $n = 2$, and then change notation to write $X = X_1$, $Y = X_2$. We let $\mathcal B(Z)$ denote the Borel $\sigma$-algebra of the metric space $Z$.

By a \dfn{Borel cylinder} in $X \times Y$ we mean a set of the form $\pi_X^{-1}(E)$ or $\pi_Y^{-1}(F)$ where $E$ is Borel in $X$ and $F$ is Borel in $Y$.
We mean similarly for a \dfn{Borel cylinder}.
We leave it to the reader to check that $\mathcal B(X) \otimes \mathcal B(Y)$ is generated by the Borel cylinders.
Clearly every Borel cylinder is Borel, so this implies that every element of $\mathcal B(X) \otimes \mathcal B(Y)$ is Borel.
TODO: Draw a picture of a cylinder.

Conversely, since $X, Y$ are separable there are countable dense subsets $E, F \subseteq X, Y$.
Then $E \times F$ is countable and dense in $X \times Y$.
Let $B(x, y, r)$ denote the ball of radius $r$ centered at $(x, y)$; then $B(x, y, r) = B_X(x, r) \times B_Y(y, r)$ if we are using the metric \ref{max metric}. Here $B_X(x, r)$ is a ball in $X$ and similarly for $B_Y$.
Let $\mathcal S$ be the set of $B(x, y, r)$ with $(x, y) \in E \times F$ and $r \in \QQ$; then any open set in $X \times Y$ is a countable union of sets in $\mathcal S$ and so $\mathcal S$ generates $\mathcal B(X \times Y)$.
Therefore $\mathcal B(X \times Y) \subseteq \mathcal B(X) \otimes \mathcal B(Y)$.
\end{proof}

In the following section we use Lemma \ref{borel products} to define the Lebesgue integral in general.

\section{The Lebesgue integral}
Let $\mu$ be a Stieltjes measure.
Then $\mu$ is a Borel measure on $\RR$, and by Lemma \ref{borel products}, a product of $d$ copies of $\mu$ gives rise to a Borel measure on $\RR^d$.
We will mainly be interested in the case when $\mu$ is the Lebesgue measure.

\begin{definition}
Let $\mu$ be the Lebesgue measure on $\RR$.
The Borel measure $\mu^d = \bigotimes_{i=1}^d \mu$ on $\RR^d$ is called the \dfn{Lebesgue measure} on $\RR^d$.
If $f \in L^1(\RR^d, \mu^d)$, we say that $f$ is \dfn{Lebesgue integrable} and call $\int f~d\mu^d$ the \dfn{Lebesgue integral} of $f$.
\end{definition}

If $d = 2$ then the Lebesgue measure of a rectangle, or indeed any of the classical shapes, is just its area.
Similarly if $d = 3$ then the Lebesgue measure of a rectangular prism, or any other classical shape, is just its volume.
Thus Lebesgue measure generalizes the basic notions of Euclidean geometry to arbitrary (Borel) subsets of $\RR^d$.

In general Lebesgue measure is so important that we usually refer to it implicitly.
For example, we will usually just write $\int f$ or $\int f(x) ~dx$ for the Lebesgue integral of $f$.

In this section we record the basic properties of the Lebesgue measure.

\begin{theorem}
\label{lebesgue is radon 2}
The Lebesgue measure is a $\sigma$-finite Radon measure.
\end{theorem}
\begin{proof}
By induction on $d$. When $d = 1$ this is the content of Theorem \ref{lebesgue is radon}.
Now $\mu^d = \mu^{d-1} \otimes \mu$, and we know that both $\mu^{d-1}$ and $\mu$ are Radon.

First we check local finiteness. By the Heine-Borel theorem every compact set is bounded and hence is contained in a compact rectangle in $\RR^d$, which is a product of a compact rectangle in $\RR^{d-1}$ and a compact interval, both of which have finite measure.
TODO:Draw a picture.
This makes $\sigma$-finiteness easy to prove, because $[-n, n]^d$ is a compact (hence finite measure) rectangle that grows to be all of $\RR^d$.

Now we check inner regularity on open rectangles.
An open rectangle $U$ in $\RR^d$ is a product of an open rectangle $U^* = \prod_{i<d} \pi_i(U)$ in $\RR^{d-1}$ and an open interval $\pi_d(U)$.
Now if $K$ is compact in $U$, then obviously $\mu(K) \leq \mu(U)$.
Conversely, for every $\varepsilon > 0$, we can find a compact interval $K_d \subset \pi_d(U)$ with $\mu^d(\pi_d(U) \setminus K_d) < \varepsilon$ and a compact rectangle $K^* \subset U^*$ with $\mu^d(U^* \setminus K^*) < \varepsilon$. So $K = K^* \times K^d$ also has $\mu^d(U \setminus K)$ arbitrarily small.

Every open set $U$ is a countable union of almost disjoint\footnote{in the sense that their intersection is Lebesgue null} open rectangles $U_n$, which can be approximated from within by compact sets $K_n^m \subset U_n$ with $\mu(U_n \setminus K_n^m) < \varepsilon 2^{-m}2^{-n}$. Then the $K_n^n$ are disjoint and $L_n = \bigcup_{m \leq n} K_m^m$ is compact.
Moreover if $\mu^d(U) = \infty$ then $\mu^d(L_n) \to \infty$; otherwise
$$\mu^d(U) = \sum_n \mu^d(U_n) \leq \sum_n \mu^d(K_n^n) + \frac{1}{2^n2^n} < \varepsilon + \mu^d(L_n) + \sum_{m > n} \mu^d(K_m^m)$$
and
$$\sum_{m > n} \mu^d(K_m^m) \leq \sum_{m > n} \mu^d(U_m) < \varepsilon$$
if $n$ is large enough, since the sequence of $\mu^d(U_m)$ is absolutely summable.
Therefore the $L_n$ approximate $U$ from within.

The proof of outer regularity is similar to the proof of inner regularity, and we leave it as an exercise.
The reader may wish to use ``half-open rectangles" in the proof of outer regularity.
\end{proof}

\begin{theorem}
\label{translation invariance in Rd}
If $A$ is Borel in $\RR^d$ and $x \in \RR^d$, then the translation $A + x$ has the same Lebesgue measure as $A$.
\end{theorem}
\begin{proof}
See Exercise \ref{translation invariance exer}.
\end{proof}

\begin{theorem}
Let $f: [\alpha, \beta] \to \RR$ be a bounded Riemann integrable function and let $R$ be its Riemann integral. Then
$$\int_\alpha^\beta f(x)~dx = R.$$
\end{theorem}
\begin{proof}
The Riemann integral approximates $f$ from below by step functions $f_n$ on $[\alpha, \beta]$ which converge to $f$ pointwise, and $R$ is the limit of the $f_n$ as $n \to \infty$.
Since $f$ is a bounded function on a set of finite measure it is in $L^1$, and then dominated convergence implies that the Lebesgue integral is the limit of the integrals of the $f_n$.
\end{proof}

Thus, we really have generalized the familiar notion of integration that many students learn about in high school or their first year of undergraduate education.
We now prove that the integral of a function is the area under its graph.

\begin{theorem}
Let $f \in L^1(\RR^d \to [0, \infty))$.
Let $U = \{(x, y): x \in \RR^d, ~0 \leq y \leq f(x)\} \subset \RR^{d+1}$.
Then
$$\mu^{d+1}(U) = \int_{\RR^d} f(x)~dx.$$
\end{theorem}
\begin{proof}
All functions here are nonnegative (so that we do not have to talk about ``net signed area"), so by monotone convergence and continuity of measure, it suffices to check this for simple functions, and then by linearity it suffices to check this for an indicator function $f = 1_A$.
But this is obvious:
\begin{align*}U &= \{(x, y): x \in \RR^d, ~0 \leq y \leq f(x)\} \\&= \{(x, y): x \in A, ~0 \leq y \leq 1\} \cup \{(x, y): x \notin A, ~0 \leq y \leq 0\} \\&= (A \times [0, 1]) \cup (A^c \times \{0\}).\end{align*}
Since $\mu^{d+1}(A^c \times \{0\}) = 0$,
$$\mu^{d+1}(U) = \mu^{d+1}(A \times [0, 1]) = \mu^d(A) \mu^1([0, 1]) = \mu^d(A) = \int_{\RR^d} 1_A(x)~dx.$$
That proves the claim.
\end{proof}

Be aware, however, that there are Riemann integrable functions which are not Lebesgue integrable.
The reason is that, to avoid integrals of the form $\infty - \infty$, we demanded that Lebesgue integrals converge absolutely, while the Riemann integral is allowed to converge conditionally.
See Exercise \ref{sinc} for an example of this phemonenon.

\begin{exercise}
\label{translation invariance exer}
Prove Theorem \ref{translation invariance in Rd}. (Hint: Use Theorem \ref{translation invariance in R1}.)
\end{exercise}

\begin{exercise}
\label{euclidean group}
The \dfn{euclidean group} is the group of invertible functions $\RR^d \to \RR^d$ generated by translations, rotations around the origin, and reflections. Equivalently, it is the group generated by translations and orthogonal linear maps.
An element of the euclidean group is called a \dfn{rigid motion}. Show that if $A$ is a rigid motion and $\mu$ denotes Lebesgue measure, then $A_*\mu = \mu$.
This generalizes Theorem \ref{translation invariance in Rd}.
\end{exercise}

\begin{exercise}
Let $A: \RR^d \to \RR^d$ be an invertible linear map, $\mu$ Lebesgue measurable, and $E$ a Lebesgue measurable set. Show that $A_*\mu(E) = |\det A|\mu(E)$.
(Hint: Use Exercise \ref{euclidean group} to show that without loss of generality, we may assume that $A$ is positive. Now use the spectral theorem.)
\end{exercise}

\begin{exercise}
\label{sinc}
Define the \dfn{sampling function} $\sinc: \RR \to \RR$ by $\sinc x = \sin x/x$ for $x \neq 0$ and $\sinc 0 = 1$.
Let $F(r)$ be the Riemann integral of $\sinc$ on $[0, r]$. Show that $\lim_{r \to \infty} F(r)$ exists and is finite.
However, show that $\sinc$ is not Lebesgue integrable on $[0, \infty)$.
\end{exercise}

\section{Changing the order of integration}
In this section we prove the following extremely useful theorem.
We let $f(x, \cdot)$ denote the function $y \mapsto f(x, y)$ whenever $f$ is a function of two variables; similarly for $f(\cdot, y)$.
\begin{theorem}[Fubini]
Let $(X, \Sigma, \mu)$ and $(Y, \Gamma, \nu)$ be $\sigma$-finite complex-valued measured spaces.
Let $f: X \times Y \to \CC$ be a nonnegative $(\Sigma \otimes \Gamma)$-measurable function.
Then the following are equivalent:
\begin{enumerate}
\item $f \in L^1(X \times Y \to \CC, \mu \otimes \nu)$.
\item For almost every $x \in X$, $f(x, \cdot) \in L^1(Y \to \CC, \nu)$ and the function
$$x \mapsto \int_Y f(x, y)~d\nu(y)$$
is in $L^1(X \to \CC, \mu)$.
\item For almost every $y \in Y$, $f(\cdot, y) \in L^1(X \to \CC, \mu)$ and the function
$$y \mapsto \int_X f(x, y)~d\mu(x)$$
is in $L^1(Y \to \CC, \nu)$.
\end{enumerate}
Moreover,
\begin{equation}
\label{change order of integration}
\int_{X \times Y} f~d(\mu \otimes \nu) = \int_X \int_Y f(x, y) ~d\mu(x)~d\nu(y) = \int_Y \int_X f(x, y) ~d\nu(y) ~d\mu(x).
\end{equation}
\end{theorem}
We will weaken the hypotheses on this theorem somewhat before the end of the section.
Because of (\ref{change order of integration}) we can \emph{define} the \dfn{double integral} by
$$\iint_{X \times Y} f ~d\mu ~d\nu = \int_{X \times Y} f~d(\mu \otimes \nu).$$
One similarly defines triple integrals, quadruple integrals, et cetra, by induction.
Indeed, the hypothesis that only two measure spaces are in play in the statement of Fubini's theorem can be completely done away with, by induction, and one can consider arbitrary finite products of measure spaces.
We will also do away with the hypothesis that $f$ is nonnegative, at the price of requiring that $f \in L^1$.
This is necessary to protect ourselves from our old enemy, $\infty - \infty$.
We \emph{cannot} do away with the $\sigma$-finite hypothesis, however TODO:show this.

TODO: State the Banach space valued version.

Before we prove Fubini's theorem, let us record three of its many applications.
\begin{corollary}
Let $(x_{i,j})_{i,j=1}^\infty$ be absolutely summable, thus
$$\sum_{i=1}^\infty \sum_{j=1}^\infty |x_{i,j}| < \infty,$$
or nonnegative, thus for every $i,j$, $x_{i,j} \geq 0$. Then
$$\sum_{i=1}^\infty \sum_{j=1}^\infty x_{i,j} = \sum_{j=1}^\infty \sum_{i=1}^\infty x_{i,j}.$$
\end{corollary}
\begin{proof}
This is an immediate consequence of Fubini's theorem applied to counting measure.
\end{proof}

\begin{corollary}
One has the \dfn{Gaussian integral formula}
$$\int_{-\infty}^\infty e^{-x^2} ~dx = \sqrt \pi.$$
\end{corollary}
\begin{proof}
We first note that
$$\int_{-\infty}^\infty e^{-x^2}~dx = \int_{-\infty}^\infty e^{-y^2}~dy$$
since all we have done is replace a dummy variable. Therefore it suffices to show that
\begin{equation}
\label{gaussian integral squared}
\int_{-\infty}^\infty e^{-x^2}~dx \int_{-\infty}^\infty e^{-y^2}~dy = \pi.
\end{equation}
Clearly $x \mapsto e^{-x^2}$ is nonnegative, so by Fubini's theorem we can replace the product integral by a double integral:
$$\int_{-\infty}^\infty e^{-x^2}~dx \int_{-\infty}^\infty e^{-y^2}~dy = \iint_{\RR^2} e^{-(x^2 + y^2)}~dA(x, y).$$
Here $A$ (short for area) is Lebesgue measure on $\RR^2$.
Now $\{0\}$ is a null set so we can discard it, and the reader who recalls their calculus class will diligently check that $\RR^2 \setminus \{0\} \cong \RR_+ \times [0, 2\pi)$ according to the map $(r \cos \theta, r \sin \theta) \mapsto (r, \theta)$, where the open half-line $\RR_+$ is given the Borel measure $\mu$ with
$$\mu(E) = \int_E r~dr$$
and $[0, 2\pi)$ is given Lebesgue measure. That is,
$$dA(r \cos \theta, r \sin \theta) = d\mu(r) ~d\theta = r~dr~d\theta.$$
To check this claim, one just needs to show that the Borel sets in $\RR^2 \setminus \{0\}$ are generated by ``rectangles" (which here are sectors $\{(r \cos \theta, r \sin \theta): r \in [r_1, r_2], ~\theta \in [\theta_1, \theta_2]\}$), and that for every such rectangle $R$, which we identify with the (plain old) rectangle $[r_1, r_2] \times [\theta_1, \theta_2]$, its area satisfies
$$A(R) = (\theta_2 - \theta_1)\int_{r_1}^{r_2} r~dr.$$
TODO:Draw a picture of a sector
Once the reader verifies this, they are entitled to apply Fubini's theorem again, and
$$\iint_{\RR^2} e^{-(x^2 + y^2)}~dA(x, y) = \int_0^{2\pi} \int_0^\infty re^{-r^2}~dr~d\theta = 2\pi \int_0^\infty re^{-r^2}~dr.$$
Now this is really just a calculus problem: if $s = r^2$ then $ds = 2r~dr$, and so one easily checks that
$$\int_0^\infty re^{-r^2}~dr = \frac{1}{2}.$$
Then (\ref{gaussian integral squared}) immediately follows.
\end{proof}

\begin{corollary}
Let $X,Y$ be independent random variables of type $\RR$. If $X,Y$ are in $L^1$, then $E(XY) = (EX)(EY)$, and if $X^2, Y^2 \in L^1$, then $\Var(X+Y) = \Var X + \Var Y$.
\end{corollary}
\begin{proof}
Let $\mu_X,\mu_Y$ be the distributions of $X,Y$.
Let $A = A_1 \times A_2 \subseteq \RR^2$ be a Borel rectangle.
Then
$$\mu_X \otimes \mu_Y(A) = \mu_X(A_1) \mu_Y(A_2) = P(X \in A_1) P(Y \in A_2) = P(X \in A_1 \cap Y \in A_2)$$
by independence. On the other hand, the random variable $(X, Y)$ of type $\RR^2$ has distribution
$$\nu(A) = P(X \in A_1 \cap Y \in A_2)$$
so $\nu = \mu_X \otimes \mu_Y$.
It follows that
$$E(|X||Y|) = \int_{\RR^2} \prod_{j=1}^n |x||y| ~d\nu(x, y) = \iint_{\RR^2} |x||y| ~d\mu_X(x)~d\mu_Y(y)$$
by Exercise \ref{integrating a distribution} and Fubini's theorem. This integral simplifies to
$$\iint_{\RR^2} |x||y| ~d\mu_X(x)~d\mu_Y(y) = \int_{-\infty}^\infty |x| ~d\mu_X(x) \int_{-\infty}^\infty |y| ~d\mu_Y(y) = (E|X|)(E|Y|)$$
by Exercise \ref{integrating a distribution}.
So by Fubini's theorem we can repeat the above argument with absolute values dropped and conclude $E(XY) = (EX)(EY)$.

Now set $X' = X - EX$, $Y' = Y - EY$. Then $X',Y'$ are independent and $EX' = EY' = 0$, so $E(X'Y') = 0$.
Thus
\begin{align*}\Var(X + Y) &= E((X' + Y')^2) = E((X')^2) + E((Y')^2) + 2E(X'Y') \\
&= \Var X' + \Var Y' = \Var X + \Var Y
\end{align*}
as desired.
\end{proof}

Monotone Classes

TODO: Prove Fubini

\begin{exercise}[Cavalieri's principle]
Let $E \subseteq \RR^2$ be a measurable set, $\mu^d$ Lebesgue on $\RR^d$, and $E_x = \{y \in \RR: (x, y) \in E\}$.
Show that
$$\mu^2(E) = \int_{-\infty}^\infty \mu^1(E_x)~dx$$
(so that, in particular, $x \mapsto \mu^1(E_x)$ exists almost everywhere and is measurable).
\end{exercise}

\begin{exercise}
Let $f$ be the function $f(x, y) = y^{-2}$ for $x < y$ and $f(x, y) = x^{-2}$ for $y < x$.
Show that $f$ is defined almost everywhere and measurable, and the iterated integrals $\int_0^1\int_0^1 f(x,y)~dx~dy$ and $\int_0^1\int_0^1 f(x,y)~dy~dx$ are finite, but $f \notin L^1([0, 1]^2)$.
What went wrong?
\end{exercise}

\begin{exercise}[weak law of large numbers]
Let $X_n$ be a countable sequence of iid random variables of type $\RR$.
Assume that $\Var X_n$ makes sense and $EX_n = 0$. Show that
$$\lim_{n \to \infty} \frac{1}{n} \sum_{j=1}^n X_j = 0$$
in probability using Chebyshev's inequality, Exercise \ref{Chebyshev}.
\end{exercise}

\begin{exercise}[Stone-Weierstrass theorem for polynomials]
One form of the Stone-Weierstrass theorem is the statement that for every continuous function $f: [0, 1] \to \RR$, there exists a sequence of polynomials that converge to $f$ in $L^\infty$.
Surprisingly, this deterministic statement has a simple probabilistic proof, which we now outline.

Fix $x \in [0, 1]$.
Show that there is a probability space $(\Omega, P)$ which admits iid random variables $X_j$ with $P(X_j = 1) = x$ and $P(X_j = 0) = 1 - x$.
(Hint: One constructive way to do this is to say that $\Omega$ is the Cantor set $\prod_j \{0, 1\}$.)

Let $\overline X_n = \sum_{j \leq n} X_j/n$ be the average of the first $n$ random variables $X_j$ and show that $B_n(x) = E(f(\overline X_n))$ is a polynomial in $x$.
For every $\varepsilon > 0$ there is a $\delta > 0$, which does not depend on $x$, such that $|x - y| < \delta$ implies $|f(x) - f(y)| < \varepsilon$.
Conclude that
$$|B_n(x) - f(x)| \lesssim \varepsilon + P(|\overline X_n - x| > \delta)$$
where the constant is allowed to depend on $f$ but not $x$.
Use Chebyshev's inequality, Exercise \ref{Chebyshev}, to conclude the proof.
\end{exercise}

\chapter{Differentiation and regularity}

\section{Decomposition of signed measures}

\section{Differentiation of measures}

As an application, we define the conditional expectation of a random variable.
Recall from elementary probability theory that if $A$ is an event (which is not almost surely false) and $X$ is a random variable, then the conditional expectation of $X$ given $A$ is
\begin{equation}
\label{conditional expectation event}
E(X|A) = \frac{E(1_AX)}{P(A)},
\end{equation}
the expected value of $X$ if we rescale $A$ to be the entire probability space.
However, in probability theory, one often needs to discuss the conditional expectation of $X$ with respect to not just an event, but an entire $\sigma$-algebra of events.
More precisely, let $\mathcal F$ be a $\sigma$-algebra.
If $A \in \mathcal F$ and we define $E(X|A)$ by (\ref{conditional expectation event}), then we forget everything $X$ except its mean on $A$.
The conditional expectation of $X$ on $\mathcal F$, by definition, will be a random variable that only remembers the conditional expectations of $X$ with respect to every event in $\mathcal F$.

\begin{definition}
Let $(\Omega, \Sigma, P)$ be a probability space, $\mathcal F \subseteq \Sigma$ a $\sigma$-algebra, and $X \in L^1(\Omega \to \RR)$ a random variable.
The \dfn{conditional expectation} of $X$ given $\mathcal F$ is a measurable function
$$E(X|\mathcal F): (\Omega, \mathcal F) \to \RR$$
such that
$$E(1_A E(X|\mathcal F)) = E(1_A X)$$
whenever $A \in \mathcal F$.
\end{definition}

\begin{example}
A \dfn{measurable partition} of $\Omega$ is a set of mutually exclusive events $A_i$ such that $\bigcup_i A_i = \Omega$.
If $(A_i)$ is a measurable partition and $\mathcal F$ is the smallest $\sigma$-algebra containing every $A_i$, then $E(X|\mathcal F)$ is constant on each $A_i$, namely
$$E(X|\mathcal F)|A_i = E(1_{A_i} X)$$
is the mean of $X$ on $A_i$.
\end{example}

\begin{corollary}
Let $(\Omega, \Sigma, P)$ be a probability space, $\mathcal F \subseteq \Sigma$ a $\sigma$-algebra, and $X \in L^1(\Omega \to \RR)$ a random variable.
The conditional expectation $E(X|\mathcal F)$ is well-defined in the sense that it exists, and if $Y$ is also a conditional expectation, then $E(X|\mathcal F) = Y$ almost surely.
\end{corollary}
\begin{proof}
Let $\mu$ be the measure
$$\mu(A) = E(1_A X)$$
defined for $A \in \mathcal F$.
Then $\mu$ is absolutely continuous with respect to $P$, so it has a Radon-Nikodym derivative; we set
$$E(X|\mathcal F) = \frac{d\mu}{dP}.$$
Then
$$E(1_A E(X|\mathcal F)) = \int_A \frac{d\mu}{dP} ~dP = \int_A ~d\mu = \mu(A) = E(1_A X)$$
as desired.

For the uniqueness, assume $Y$ is also a conditional expectation and let $A$ be the event that $Y \neq E(X|\mathcal F)$.
Then $A \in \mathcal F$ so
$$E(1_A|Y - E(X|\mathcal F)|) = E(1_A|X - X|) = 0.$$
But $|Y - E(X|\mathcal F)| > 0$ on $A$ so this implies $E(1_A) = 0$, thus $A$ is almost surely false.
\end{proof}

\begin{exercise}
Let $X \in L^1$ be a random variable and $\mathcal F$ a $\sigma$-algebra. Show that if the pullback $\sigma$-algebra induced by $X$ is independent of $\mathcal F$ then
$$E(X|\mathcal F) = E(X).$$
Show that
$$E(E(X|\mathcal F)) = E(X).$$
Show that if $X$ is $\mathcal F$-measurable then $E(X|\mathcal F) = X$.
\end{exercise}

\begin{exercise}
Verify that the monotone and dominated convergence theorems, and Fatou lemma, are valid when $EX_n$ is replaced with $E(X_n|\mathcal F)$, $\mathcal F$ a $\sigma$-algebra.
\end{exercise}

\section{Existence of Radon measures}

\section{Differentation of vector-valued functions}

\section{Vitali's covering lemma}

\begin{definition}
If $B$ is a ball, say $B = B(x, r)$, we let $kB$ denote the \dfn{dilated ball} $kB = B(x, kr)$.
\end{definition}
\begin{lemma}
Let $X$ be a metric space and let $\mathcal B$ be a finite set of balls in $X$. Then there is a subset $\mathcal B_0$ of $\mathcal B$ consisting of disjoint balls such that
$$\bigcup_{B \in \mathcal B} B \subseteq \bigcup_{B_0 \in \mathcal B_0} 3B_0.$$
\end{lemma}
TODO prove me
\begin{theorem}[Vitali's covering lemma]
Let $X$ be a separable metric space and let $\mathcal B$ be a set of balls in $X$. Let
$$R(\mathcal B) = \sup_{B(x, r) \in \mathcal B} r$$
be the supremum of radii of the balls in $\mathcal B$. If $R(\mathcal B) < \infty$ then for every $\varepsilon > 0$ there is a countable subset $\mathcal B_0(\varepsilon)$ of $\mathcal B$ consisting of disjoint balls such that
\begin{equation}
\label{Vitali formula}
\bigcup_{B \in \mathcal B} B \subseteq \bigcup_{B_0 \in \mathcal B_0(\varepsilon)} (3 + \varepsilon)B_0.
\end{equation}
\end{theorem}
TODO Prove me

\begin{exercise}
Show that there is a counterexample to Vitali's covering lemma when $R(\mathcal B)$ is infinite.
\end{exercise}

\begin{exercise}
Show that a version of Vitali's covering lemma holds for any metric space.
That is, show that if $X$ is a metric space and $\mathcal B$ is a set of balls in $X$ such that $R(\mathcal B) < \infty$, then for every $\varepsilon > 0$ there is a subset (not necessarily countable) $\mathcal B_0(\varepsilon)$ of $\mathcal B$ consisting of disjoint balls such that (\ref{Vitali formula}) holds.
You will need to use some kind of set-theoretic machinery to pull this off.
\end{exercise}

\section{The maximal inequality}

\begin{theorem}[weaktype Hardy-Littlewood maximal inequality]
Let $d \geq 1$ and $f \in L^1(\RR^d)$. Let $\mu$ denote Lebesgue measure. Then for every $\lambda > 0$,
$$\mu(\{Mf > \lambda\}) \leq 3^d \frac{||f||_{L^1(\RR^d)}}{\lambda}.$$
\end{theorem}
TODO prove me

\begin{exercise}
Let $f \in L^1(\RR^d)$.
Show that if $Mf \in L^1(\RR^d)$ then $f = 0$.
It may help to first try this when $f$ has compact support.
\end{exercise}

\section{The Lebesgue differentation theorem}

\section{The fundamental theorem of calculus}

\chapter{H\"older duality and $L^p$ norms}
Previously we have considered a menagerie of different modes of convergence: pointwise convergence, almost pointwise convergence, uniform convergence, nearly uniform convergence, convergence in measure, convergence in $L^1$, convergence in $L^\infty$...
In this chapter we introduce many more.

It is worth asking why we would bother to do this.
Our previously considered modes of convergence served the purpose of allowing us to ``approximate", in various senses, arbitrary measurable functions by simple functions, or other functions that are similarly easy to understand.
However, these notions of convergence were rather badly behaved.
For example, we say that a mode of convergence $M$ is \dfn{topologizable} if there is a topology $T$ such that a sequence of functions converges in $T$ iff it converges in $M$.
Almost pointwise convergence, for one, is not topologizable.
In particular, one cannot find a Banach space $B$ such that almost pointwise convergence is equivalent to convergence in $B$.
The only modes of convergence that we have considered so far which are induced by the norm of a Banach space are convergence in $L^1$, uniform convergence, and convergence in $L^\infty$.

But why do we like Banach spaces? Well, Banach spaces have an algebraic structure, since they are vector spaces.
More critically, if $B$ is a Banach space with norm $||\cdot||$, and $f \in B$, then $||f||$ can reasonably viewed as the ``size" of $f$.
In applications, being able to size functions is crucial.
Many theorems in PDE amount to proving that if a function $f$, that we can think of as ``initial data" for some dynamical system, is ``small enough" (in the sense that $||f|| < \delta$ for some $\delta$ that does not depend on $f$), then the dynamical system stabilizes to $0$.
As a concrete example, models of the spread of an infection inside a human body often have the property that if the initial data $f$ is small enough (thus very few virions are present in the body), then the infection will die out.

Another useful feature of Banach spaces is the notion of duality.
Given a Banach space $B$ of functions, one can introduce the dual space $B^*$ of bounded linear maps $B \to \CC$; then $B^*$ is a Banach space, whose elements can often be canonically identified with functions that we want to think of as ``dual to" the functions in $B$.
One then has an ``inner product"
$$\langle \cdot, \cdot\rangle: B^* \times B \to \CC$$
where, if $f$ is the function which is canonically identified with a linear map $\lambda \in B^*$, and $g \in B$, then
$$\langle f, g\rangle = \lambda(g).$$
Under favorable circumstances, this inner product will behave very similarly to the inner products that one learns about in linear algebra.
For example, two functions $f, g$ are said to be \dfn{orthogonal} provided that $\langle f, g\rangle = 0$.
One can then generalize such tools as the spectral theorem and the Cauchy-Schwarz inequality, so that we will be able to bring the power of linear algebra to bear on measurable functions.

In this chapter we will introduce $p$-norms for $p \in (1, \infty)$, which are the norms defined on Banach spaces $L^p$, and generalize both $L^1$ and $L^\infty$.
The duality theory for $L^p$ is known as \dfn{H\"older duality}.
H\"older duality is especially effective when $p = 2$, since there is a canonical isomorphism $L^2 \to (L^2)^*$, and it is the case $p = 2$ that will be especially important when we consider applications in the following chapter.

Throughout, we fix a measured space $(X, \mu)$ and a Banach space $B$ to serve as a codomain.
Later we will need to assume that $\mu$ is $\sigma$-finite, but for now the general setting will be quite sufficient.
Recall that we identify two functions which are equal almost everywhere, and that if we really need to refer to a particular representative of an equivalence class $f$, we call it a ``version" of the function $f$.
This identification will be critical for our Banach spaces to be well-defined!

\section{$L^p$-norms}
Recall that we defined the $L^1$-norm
$$||f||_1 = \int_X ||f||~d\mu.$$
Thus $||f||_1$ could be small even if $||f||$ was quite large or even infinite, as long as the set where $||f||$ was large had a small measure.
We defined the $L^\infty$-norm $||f||_\infty$ to be the infimum of all $M$ such that $||f|| \leq M$ almost everywhere; thus $||f||_\infty$ could be small even if $||f||$ did not tend to $0$ anywhere, as long as $||f||$ did not ever go to infinity.
TODO: Draw a picture.
We seek to consider a weighted average of the two extremes.

\begin{definition}
Let $p \in (1, \infty)$.
The \dfn{$L^p$-norm} of a measurable function $f$ is
\begin{equation}
\label{Lp definition}
||f||_p = \left(\int_X ||f||^p ~d\mu\right)^{1/p}.
\end{equation}
We let $L^p(X \to B, \mu)$, often abbreviated to $L^p$ or similar, be the vector space of all measurable functions $f$ such that $||f||_p < \infty$.
\end{definition}

Here $L$ stands for ``Lebesgue"; thus $L^p$ is sometimes known as a \dfn{Lebesgue space}.
However, the term ``Lebesgue space" also refers in the literature to the measured space $[0, 1]$ with Lebesgue measure.
Worse, while the key fact about $L^p$ spaces is H\"older duality, a ``H\"older space" is a space of continuous functions satisfying a certain inequality.
So, to avoid confusion, we will simply call the spaces that we defined above \dfn{$L^p$ sspaces}.

We will shortly prove that the above definition makes sense, but, assuming that $||\cdot||_p$ is a norm, what does it measure?
If $f$ is a function that we can think of as a ``wave" of amplitude $A$, supported on a set of measure $V$, then one approximately has
\begin{equation}
\label{Lp amplitude}
||f||_p \approx AV^{1/p}.
\end{equation}
Here and throughout we take the very important convention that $1/\infty = 0$.
(To see a precise version of (\ref{Lp amplitude}), if $f$ is the wave $f(x) = Ae^{ix}1_E$ where $E$ is a set of measure $V$, then, for Lebesgue measure,
$$||f||_p = ||Ae^{ix}1_E||_p = A ||1_E||_p = A\mu(E)^{1/p} = AV^{1/p},$$
which partially justifies the intuition (\ref{Lp amplitude}).)
In more advanced courses one introduces the \dfn{Sobolev norms} $W^{s,p}$ which not only takes into account amplitude and support but also frequency; if $f$ has frequency $N$ then $||f||_{s,p} \approx AN^sV^{1/p}$.
In fact, $W^{0,p} = L^p$.
We will discuss the case $p = 2$ in the exercises.

Since $f$ is measurable and $||f||$ is nonnegative, $||f||_p$ is well-defined; either $||f||^p \in L^1(X \to \CC)$, in which case $f \in L^p(X \to B)$, or $||f||_p = \infty$.
We need to check that $||\cdot||_p$ satisfies the definition of a norm, and that $L^p$ is a vector space, in order for the above definition to make sense.

We first check the first two properties of a norm.
\begin{lemma}
One has $||f||_p = 0$ iff $f = 0$, and $||cf||_p = |c|\cdot||f||_p$.
\end{lemma}
\begin{proof}
It is clear that $|c|\cdot||f||_p = ||cf||_p$.
If $f = 0$, then $||f||_p = 0$.
Conversely, if $f \neq 0$ on a positive measure set, say $E$, then
$$||f||_p^p \geq \int_E ||f||^p ~d\mu > 0.$$
(Here we are using the fact that we identify functions which are equal almost everywhere!)
\end{proof}

Thus we just need to check the triangle inequality. Before we do that, however, we will need to prove some inequalities and equations which will turn out to be highly useful in their own right.
We first assert that
\begin{equation}
\label{pull exponent of Lp}
\left|\left|||f||^q\right|\right|_p = ||f||_{pq}^q
\end{equation}
whenever $p, q \in [1, \infty]$ and $f \in L^{pq}$ or $||f||^q \in L^p$; this follows straight from the definitions.

\begin{lemma}
One has
\begin{equation}
\label{exp is convex}
\exp(\theta x + (1 - \theta)y) \leq \theta e^x + (1 - \theta)e^y
\end{equation}
whenever $\theta \in [0, 1]$ and $x, y \in \RR$.
\end{lemma}
\begin{proof}
See Exercise \ref{exp is convex exer}.
\end{proof}

Recall that $[1, \infty]$ is the set of all real numbers $\geq 1$, along with $\infty$.
Here and after we take the convention $1/\infty = 0$ and $1/0 = \infty$.

\begin{definition}
Let $p, q \in [1, \infty]$. If
$$\frac{1}{p} + \frac{1}{q} = 1,$$
we say that $p, q$ are \dfn{H\"older duals}, and write $q = p^*$.
\end{definition}

For example, $1^* = \infty$, and $2^* = 2$. One checks at once that $p^*$ is unique, that $p^{**} = p$, and that if $p < q$ then $q^* < p^*$.

\begin{theorem}[Young's product inequality]
If $p \in (1, \infty)$ and $q = p^*$ then for every $a,b \geq 0$,
$$ab \leq \frac{a^p}{p} + \frac{b^q}{q}.$$
\end{theorem}
\begin{proof}
By (\ref{exp is convex}) one has
$$ab = \exp(\log a + \log b) = \exp\left(\frac{\log a^p}{p} + \frac{\log b^q}{q}\right) \leq \frac{\exp(\log a^p)}{p} + \frac{\exp(\log b^q)}{q} = \frac{a^p}{p} + \frac{b^q}{q};$$
here we are taking $\theta = 1/p$ and $1 - \theta = 1/q$, and letting $\log$ denote the natural logarithm.
\end{proof}

\begin{theorem}[H\"older's inequality]
Let $p, q \in [1, \infty]$.
Let $f \in L^p(X \to \CC)$, $g \in L^q(X \to \CC)$, and $q = p^*$.
Then $fg \in L^1(X \to \CC)$ and
\begin{equation}
\label{Holder inequality}
||fg||_1 \leq ||f||_p \cdot ||g||_q.
\end{equation}
\end{theorem}
\begin{proof}
Without loss of generality, we can assume that $p \leq q$.
If $p = 1$ then $q = \infty$, and this is just the triangle inequality for $L^1$ and $L^\infty$.
Otherwise, $1 < p < q < \infty$, so Young's inequality for products applies.

Let $F = f/||f||_p$ and $G = g/||g||_q$. Then $||F||_p = ||G||_q = 1$.
By Young's inequality for products,
\begin{align*}||FG||_1 &= \int_X ||FG|| \leq \int_X \frac{||F||^p}{p} + \frac{||G||^q}{q}\\
&= \frac{||F||_p^p}{p} + \frac{||G||_q^q}{q} = \frac{1}{p} + \frac{1}{q}  = 1.
\end{align*}
Multiplying both sides by $||f||_p \cdot ||g||_q$ we see that
$$||fg||_1 = ||F||f||_p \cdot G||g||_q||_1 \leq ||f||_p ||g||_q.$$
This is what we wanted to prove.
\end{proof}

To motivate H\"older's inequality, suppose that $f$ is a wave of amplitude $A_1$ and supported on a set of measure $V_1$.
Suppose that $g$ has amplitude $A_2$ and supported on a set of measure $V_2$.
Then the left-hand side of (\ref{Holder inequality}) is maximized when one has ``constructive interference", which is only possible when $f$ and $g$ are supported on the same set, thus $V_1 = V_2$.
In that case $fg$ has amplitude $A_1A_2$ and support on a set of measure $V_1^{1/p}V_2^{1/p^*} = V_1^{1/p+1/p^*} = V_1$.
This is exactly what H\"older's inequality would predict.

\begin{theorem}[Minkowski's triangle inequality]
Let $p \in [1, \infty]$ and $f, g \in L^p$. Then $f + g \in L^p$ and
\begin{equation}
\label{Mink triangle inequality}
||f + g||_p \leq ||f||_p + ||g||_p.
\end{equation}
Thus $L^p$ is a normed space with norm $||\cdot||_p$.
\end{theorem}
\begin{proof}
If $f + g = 0$ then there is nothing to prove.
Otherwise, $||f + g||_p > 0$ and
\begin{align*}
||f + g||_p^p &= \int_X ||f + g||^p = \int_X ||f + g||\cdot ||f + g||^{p-1} \\
&= \int_X ||f||\cdot ||f + g||^{p-1} + \int_X ||g||\cdot ||f + g||^{p-1}\\
&\left|\left|||f||\cdot ||f + g||^{p-1}\right|\right|_1 + \left|\left|||g||\cdot ||f + g||^{p-1}\right|\right|_1.
\end{align*}
Now we apply H\"older's inequality. In fact,
$$\left|\left|||f||\cdot ||f + g||^{p-1}\right|\right|_1 \leq ||f||_p \cdot \left|\left|||f + g||^{p-1}\right|\right|_{p^*}.$$
But (\ref{pull exponent of Lp}) says that
$$\left|\left|||f + g||^{p-1}\right|\right|_{p^*} = ||f + g||_q^{p - 1}$$
where $q = p^*(p-1)$. Thus
$$||f + g||_p^p \leq (||f||_p + ||g||_p) ||f + g||_q^{p - 1}.$$
But $1/p^* = 1 - 1/p$, so $p = q$. Therefore, dividing both sides by $||f + g||_p^{p - 1}$, one concludes (\ref{Mink triangle inequality}).

We have verified the triangle inequality, so $||\cdot||_p$ is a norm. If $f, g \in L^p$ and $c \in \CC$ then $f + g \in L^p$ by the triangle inequality, and $cf \in L^p$ as we have already shown.
So $L^p$ is a normed vector space.
\end{proof}
Note that the proof of Minkowski's inequality makes sense even for functions which are not valued in $\CC$, since we never actually multiply the functions themselves, only their norms. So $L^p(X \to B)$ is a Banach space even if $B \neq \CC$.

We stop to consider the case that $\mu$ is counting measure.

\begin{definition}
Let $A$ be a set. Let $\nu$ be counting measure on $A$. We define $\ell^p(A) = L^p(A \to B, \nu)$.
If $A = \NN$, we leave $A$ as understood and simply let $\ell^p = L^p(\NN \to B, \nu)$.
Here $\ell^p$ is pronounced ``little LP.""
\end{definition}

Thus $\ell^p$ is the space of sequences $x$ in $B$ with
$$\sum_{n = 1}^\infty |x_n|^p < \infty.$$
This space comes up in many useful examples, and has many nice properties.

Let us state some useful corollaries of H\"older's inequality.
\begin{corollary}[H\"older interpolation]
Let $1 \leq s \leq r \leq t \leq \infty$ and
$$\frac{1}{r} = \frac{\theta}{s} + \frac{1 - \theta}{t}$$
where $\theta \in [0, 1]$. Then, for every $f \in L^s(X \to \CC) \cap L^t(X \to \CC)$, $f \in L^r(X \to \CC)$ and
\begin{equation}
\label{holder interpolation}
||f||_r \leq ||f||_s^\theta \cdot ||f||_t^{1-\theta}.
\end{equation}
\end{corollary}
\begin{proof}
Since
$$\frac{\theta r}{s} + \frac{(1 - \theta)r}{t} = 1,$$
we can use H\"older's inequality to check
$$||f||_r^r = \int_X ||f||^{\theta r} \cdot ||f||^{(1 - \theta)r} \leq \left|\left|||f||^{\theta r}\right|\right|_{\frac{s}{\theta r}} \cdot \left|\left|||f||^{(1 - \theta) r}\right|\right|_{\frac{t}{(1 - \theta)r}};$$
taking $r$th roots of both sides and using (\ref{pull exponent of Lp}), we prove (\ref{holder interpolation}).
\end{proof}

\begin{corollary}[H\"older's inequality with induction]
\label{Holder induction}
Let $p_1, \dots, p_m, r \in [1, \infty]$ with
$$\frac{1}{r} = \sum_{j=1}^m \frac{1}{p_j}.$$
Then
$$\left|\left|\prod_{j=1}^m f_j\right|\right|_r \leq \prod_{j=1}^m ||f_j||_{p_j}$$
for any $f_1, \dots, f_m$.
\end{corollary}
\begin{proof}
See Exercise \ref{Holder induction exer}.
\end{proof}

\begin{corollary}[Cauchy-Schwarz inequality]
Whenever $f, g \in L^2(X \to \CC)$ one has
\begin{equation}
\label{CS 1}
||fg||_1 \leq ||f||_2 \cdot ||g||_2.
\end{equation}
In particular, if $v, w$ are vectors in $\CC^d$, then
\begin{equation}
\label{CS 2}
|\langle v, w\rangle|^2 \leq \langle v, v\rangle \cdot \langle w, w\rangle.
\end{equation}
\end{corollary}
\begin{proof}
The first claim (\ref{CS 1}) is just H\"older's inequality when $p = 2$.
The second claim (\ref{CS 2}) is (\ref{CS 1}) specialized to $\CC^d = \ell^p(\{1, \dots, d\} \to \CC)$.
\end{proof}

\begin{corollary}[H\"older comparison]
\label{Holder comparison}
Suppose that $p \leq q$ and $f$ is measurable $X \to \CC$.
If $\mu$ is a finite measure, then
\begin{equation}
\label{Holder comparison 1}
||f||_p \leq \mu(X)^{1/p-1/q} ||f||_q
\end{equation}
and so $L^q \subseteq L^p$.
On the other hand, if $\mu$ is a granular measure, then $L^p \subseteq L^q$ and $||f||_q \lesssim_{p,q} ||f||_p$.
\end{corollary}
\begin{proof}
The inequality (\ref{Holder comparison 1}) is equivalent to
$$\left|\left|1 ||f||^p\right|\right|_1 \leq ||1||_{q/(q-p)} \cdot \left|\left| ||f||^p\right|\right|_{q/p}$$
by (\ref{pull exponent of Lp}) and the fact that $||1||_{q/(q-p)}^p = \mu(X)^{1/p-1/q}$.
Thus (\ref{Holder comparison 1}) is a consequence of H\"older's inequality.
We leave the proof of the case when $\mu$ is granular as Exercise \ref{granular comparison}.
\end{proof}

H\"older comparison is especially useful when $\mu$ is a probability measure, in which case it can be interpreted as the statement that every bounded random variable has a finite standard deviation and finite expected value, or when $\mu$ is counting measure, in which case it can be interpreted as saying that every absolutely summable sequence is bounded.

Let us finish the section by giving an example of Banach-valued $L^p$ spaces which frequently come up in applications.
Let $T > 0$. An \dfn{evolution equation} (say, on an open set $U \subseteq \RR^d$) is a partial differential equation satisfied by functions $u: [0, T] \times U \to \CC$ relating the ``time derivatives" of $u$ (i.e. those in the domain $[0, T]$) to the ``space derivatives" (those in $U$).
For instance, the Schr\"odinger equation
$$-i\frac{\partial u}{\partial t} + \Delta u = f,$$
where $f$ is given, $t$ is the time variable $\in [0, T]$, $\Delta$ is the Laplace operator on $U$, so
$$\Delta v(t, x_1, \dots, x_d) = \sum_{i=1}^d \frac{\partial^2 v}{\partial x_i^2} (t, x_1, \dots, x_d), $$
and $i^2 = -1$, is an evolution equation.
In the theory of evolution equations it is frequently useful to define a function $u(t): U \to \CC$ by $u(t)(x) = u(t, x)$, so we think of $u$ not as a function of two variables $[0, T] \times U \to \CC$ but a function on $[0, T]$ which returns functions on $U$.
In this case we often assume that there is a $q \in [1, \infty]$ such that for every $t \in [0, T]$, $u(t) \in L^q(U)$.
So we view $u$ as a function $[0, T] \to L^q(U)$, and we will often assume there is a $p \in [1, \infty]$ such that $u \in L^p([0, T] \to L^q(U))$.
This motivates the following definition.

\begin{definition}
A \dfn{mixed norm} is a norm of the form
$$||u||_{L^p([0, T] \to L^q(U))} = \left(\int_0^T ||u(t)||_{L^q(U)}^p~dt\right)^{1/p}$$
defined on functions $u: [0, T] \to L^q(U \to \CC)$.
\end{definition}

Later in the text we will have exercises extending the results in the text to spaces with mixed norms.

\begin{exercise}
\label{exp is convex exer}
Prove (\ref{exp is convex}) using the fact that $\exp' = \exp$.
\end{exercise}

\begin{exercise}
\label{Holder induction exer}
Prove Corollary \ref{Holder induction}.
\end{exercise}

\begin{exercise}
\label{granular comparison}
Complete the proof of Corollary \ref{Holder comparison}.
\end{exercise}

\begin{exercise}
Suppose that $f \in \bigcap_{p \in [1, \infty]} L^p$. Show that
$$||f||_\infty = \lim_{p \to \infty} ||f||_p.$$
To do this, try using Corollary \ref{Holder comparison}.
\end{exercise}

\begin{definition}
Let $V$ be a vector space.
A map $||\cdot||: V \to [0, \infty)$ is called a \dfn{quasinorm} if for every $f \in V$ and $c \in \CC$, $||f|| = 0$ iff $f = 0$, $||cf|| = |c|\cdot||f||$, and one has a \dfn{quasitriangle inequality} $||f + g|| \lesssim ||f|| + ||g||$.
\end{definition}

\begin{exercise}
\label{Lp quasinorm}
One can also define $||f||_p$ when $p \in (0, 1)$, but then $||\cdot||_p$ is not well-behaved.
In fact, define the \dfn{$L^p$-quasinorm} by (\ref{Lp definition}) for $p \in (0, 1)$.
Show that $||\cdot||_p$ is in fact a quasinorm, but the triangle inequality does not hold.
\end{exercise}

\begin{exercise}
Let $f \in \bigcap_{p \in (0, \delta)} L^p$, where $L^p$ is meant in the sense of Exercise \ref{Lp quasinorm} and $\delta > 0$ is a small constant.
Let $C$ be the carrier of $f$. Show that
$$\mu(C) = \lim_{p \to 0} ||f||_p.$$
Thus we may define the \dfn{$L^0$-quasinorm} $||f||_0 = \mu(C)$.
Show that the $L^0$-quasinorm is a quasinorm, but the triangle inequality does not hold.
\end{exercise}

\begin{exercise}
This exercise is an example of a common phenomenon in PDE and physics: if $p$ is chosen correctly, then $||u(t)||_{L^p}$ can often be viewed as the ``energy" of the scalar field $u(t)$. Here $u: [0, T] \to L^p(U)$, and $U \subseteq \RR^d$ is an open set.
Consider the heat equation
$$\partial_t u - \Delta u = f,$$
where $f$ is given and $u$ is unknown. The \dfn{heat energy} of $u$ at time $t$ is $||u(t)||_{L^2(U)}$.

Show that if $u$ is a smooth solution to the homogeneous heat equation $\partial_t u - \Delta u = 0$ such that $u = 0$ on the boundary $\partial U$, then whenever $t \leq t'$,
$$||u(t')||_{L^2(U)} \leq ||u(t)||_{L^2(U)}.$$
(Hint: What is the derivative of $t \mapsto ||u(t)||_{L^2(U)}$?)
Conclude that if $\overline U$ is compact,
$$\partial_t u - \Delta u = \partial_t v - \Delta v$$
on $U$, and $u = v = 0$ on $\partial U$, then $u = v$ almost everywhere (and hence everywhere, since $u,v$ are smooth).
\end{exercise}

\begin{exercise}[Dirichlet's principle]
\label{Dirichlet problem}
Let $U$ be a bounded open subset of $\RR^d$, and let $f: \partial U \to \RR$ be a continuous function defined on the boundary of $U$.
\dfn{Dirichlet's problem} for the Laplace equation
\begin{equation}
\label{Laplace equation}
\Delta u = 0
\end{equation}
is to find a smooth function $u$ such that (\ref{Laplace equation}) holds on $U$ and $u = f$ on $\partial U$.
Define the \dfn{Dirichlet energy} of $u$ to be
$$E(u) = ||\nabla u||_{L^2(U)}.$$
Let $\mathcal A$ be given by
$$\mathcal A = \{u \in C^2(\overline U) \cap L^2(U): u|\partial U = f\}$$
where $C^2(\overline U)$ is the space of continuous functions $\overline U \to \RR$ such that $u|U$ is twice-differentiable.
\begin{enumerate}
\item Show that $u$ is a solution of Dirichlet's problem iff $u \in \mathcal A$ and $u$ minimizes the Dirichlet energy $E(u)$ among elements of $\mathcal A$.
(Hint: For one direction, you should use the Cauchy-Schwarz inequality; for the other, let $g(t) = E(u + tv)$ where $v \in \mathcal A$, and show that $0 = g'(0)$.)
\item Show that if $f = 0$ and $u$ is a solution of Dirichlet's problem then $E(u) = 0$.
\item Show that there is at most one solution to Dirichlet's problem.
\end{enumerate}
Later, when we have more advanced techniques at our disposal, we will actually solve Dirichlet's problem (Exercise \ref{Dirichlet problem 2}).
\end{exercise}

\section{Convergence in $L^p$}
We now show that $L^p$ is a Banach space.
First we need to relate convergence in $L^p$ to other modes of convergence, especially convergence in measure.

\begin{theorem}[Markov's inequality]
For any measurable function $f$ and $\varepsilon > 0$,
\begin{equation}
\label{Markov}
\mu(\{||f|| \geq \varepsilon\}) \leq \left(\frac{||f||^p}{\varepsilon}\right)^p.
\end{equation}
\end{theorem}
\begin{proof}
Let
$$E = \{x \in X: ||f|| \geq \varepsilon\}.$$
Then
\begin{equation}
\label{Markov pf}
\varepsilon^p 1_E \leq ||f||^p.
\end{equation}
Indeed, if $x \in E$ then $\varepsilon^p 1_E(x) = 0$; otherwise $\varepsilon^p 1_E(x) = \varepsilon^p \leq ||f(x)||^p$.
Integrating both sides of (\ref{Markov pf}) $d\mu$ we get (\ref{Markov}).
\end{proof}

We now remind the reader what convergence in a normed space means: one has $f_n \to f$ in a normed space $V$ provided that for every $\varepsilon > 0$ and every $n$ large enough, $||f_n - f||_V < \varepsilon$.
Similarly, $(f_n)_n$ is Cauchy in $V$ provided that for every $\varepsilon > 0$ and every $n, m$ large enough, $||f_n - f_m||_V < \varepsilon$.

\begin{corollary}
If $f_n \to f$ in $L^p$ then $f_n \to f$ in measure, and there is a subsequence which converges to $f$ pointwise.
Moreover, if $(f_n)_n$ is Cauchy in $L^p$, then $(f_n)_n$ is Cauchy in measure, and there is a subsequence which is Cauchy almost everywhere.
\end{corollary}
\begin{proof}
By hypothesis and Markov's inequality, one has
$$\mu(\{||f_n - f||_p \geq \varepsilon\}) \leq \frac{||f_n - f||^p_p}{\varepsilon^p}$$
which implies convergence in measure.
The proof of Cauchyness in measure is similar, replacing $f$ with $f_m$ in the above inequality.
Convergence almost everywhere follows from the fundamental theorem of integration.
\end{proof}

\begin{theorem}
$L^p$ is a Banach space.
\end{theorem}
\begin{proof}
Suppose that $(f_n)_n$ is Cauchy in $L^p$; then there is a subsequence $(f_{n_k})_k$ and a $f$ such that
$$\lim_{k \to \infty} f_{n_k} = f$$
almost everywhere. Therefore for every $n$ and $x$,
$$||f(x) - f_m(x)||^p = \lim_{k \to \infty} ||f_{n_k}(x) - f_m(x)||^p.$$
Therefore by Fatou's lemma,
$$||f(x) - f_m(x)||_p^p \leq \lim_{k \to \infty} \int_X ||f_{n_k}(x) - f_m(x)||^p~d\mu = \lim_{k \to \infty} ||f_{n_k} - f_m||_p^p.$$
Taking the limit as $m \to \infty$ of both sides and using the fact that $(f_n)_n$ was Cauchy in $L^p$,
$$\lim_{m \to \infty} ||f(x) - f_m(x)||_p^p \leq \lim_{k \to \infty} \lim_{m \to \infty} ||f_{n_k} - f_m||_p^p = 0.$$
This implies that $f_m \to f$ in $L^p$; in particular, $f \in L^p$.
\end{proof}

TODO: Monotone and dominated convergence

TODO: ISF is dense

TODO: Separability

\begin{exercise}[strongtype Hardy-Littlewood maximal inequality]
Let $p \in (1, \infty]$, $f \in L^p(\RR^d)$, and let $Mf$ denote the Hardy-Littlewood maximal function of $f$.
Show that
$$||Mf||_{L^p(\RR^d)} \lesssim_{p,d} ||f||_{L^p(\RR^d)}$$
using the weaktype Hardy-Littlewood maximal inequality.
\end{exercise}

\section{Duality and representation}
We now come to the important notion of H\"older duality, which we should motivate before stating.

``Duality" is a funny word that many mathematicians use, but only a few would dare try to give a precise definition of.
For our purposes, we can think of an ``algebraic" object $X$ (a ring, an abelian group, et cetra) as being ``dual" to a ``geometric" object $X^*$ (a topological space, a manifold, et cetra) if there is a ``good bijection" between ``good" maps $X \to Y$ (say homomorphisms) and ``good" maps $Y^* \to X^*$ (continuous maps, smooth maps, et cetra), and another good bijection between good maps $Y \to X$ and good maps $X^* \to Y^*$.
The data consisting of the good bijections, for every such pair $(X, X^*)$, is then known as a ``duality theory".
We leave all the words in scare quotes undefined; the reader who is familiar with modern algebra may try to replace them with precisely defined terms, perhaps using the language of category theory or universal algebra.
However, there is a good chance that the resulting notion will not quite be satisfied by H\"older duality, because in the edge cases $p = 1$ and $p = \infty$, H\"older duality is rather ill-behaved.

One duality theory that every mathematician is familiar with is duality on finite-dimensional vector spaces.
Finite-dimensional vector spaces are both ``algebraic" and ``geometric", and indeed if $V$ is a finite-dimensional vector space over a field $K$, then there is an isomorphism $V \to V^*$, where $V^*$ is the finite-dimensional vector space of all linear maps $V \to K$.
If $V$ consists of column vectors over $K$, then $V^*$ can be canonically identified with a space of row vectors over $K$.
For any linear map $V \to W$ one obtains its adjoint map $W^* \to V^*$.
In particular, if we select an isomorphism $V \to V^*$, then we can talk about the self-adjoint maps $V \to V$, which have especially nice properties (for example, being orthogonally diagonalizable).
Moreover, there is a ``canonical" isomorphism $V \to V^{**}$.
Here we again use scare quotes for a word that we will refuse to define precisely.

We try to recover the same ideas in higher generality, replacing finite-dimensional vector spaces with $L^p$ spaces.
Since every finite-dimensional vector space over $\CC$ is indeed isomorphic to $\ell^p(\{1, \dots, n\} \to \CC)$ for some $n$ and any $p$, this is indeed a generalization.

Throughout, we will assume that $\mu$ is a $\sigma$-finite measure valued in $\CC$ and that $B$ is a Hilbert space with inner product denoted
$$(f, g) \mapsto f \overline g.$$
(TODO: Explain this? Is this allowed by mixed norm duality??)
Actually, since $\mu$ is valued in $\CC$, it is no loss of generality to assume that $\mu$ is nonnegative; so when convenient we will take $\mu = \mu$.

\begin{definition}
Let $X$ be a normed space.
The \dfn{dual space} $X^*$ of $X$ is the Banach space of all linear maps $X \to \CC$ such that
\begin{equation}
\label{bounded covector}
|Tf| \lesssim ||f||_X,
\end{equation}
with the norm
$$||T||_{X^*} = \sup_{||f||_X \leq 1} ||Tf||.$$
An element of $X^*$ is known as a \dfn{linear functional} or a \dfn{covector} on $X$.
\end{definition}

To check that $X^*$ is indeed a Banach space, one needs to use the fact that $\CC$ is itself a Banach space; see Exercise \ref{dual space is banach}.

Recall that $p^*$ is the H\"older dual of $p$; we want a canonical isomorphism
$$L^{p^*} \cong (L^p)^*$$
whenever possible.

\begin{lemma}
Let $p \in [1, \infty]$.
One has an injective linear map $\lambda: L^{p^*} \to (L^p)^*$ defined by
\begin{equation}
\label{isomorphism of holder duals}
\lambda(g)(f) = \int_X f\overline g ~d\mu.
\end{equation}
\end{lemma}
\begin{proof}
By H\"older's inequality,
$$|\lambda(g)(f)| = ||fg||_1 \leq ||f||_p \cdot ||g||_q,$$
which implies (\ref{bounded covector}).
\end{proof}

We will henceforth omit the mention of $\lambda$ whenever possible, and write
$$\langle f, g\rangle = \lambda(g)(f)$$
whenever $f \in L^{p^*}$ and $g \in L^p$.

\begin{theorem}[H\"older duality, part I]
Let $p \in [1, \infty]$.
Suppose that $\lambda$ is as in (\ref{isomorphism of holder duals}).
Then $||\lambda g||_{(L^p)^*} = ||g||_{p^*}$.
Moreover, if $p < \infty$, $\lambda$ is an isomorphism.
\end{theorem}
TODO

\begin{corollary}
If $p \in [1, \infty]$, there is an injective linear map $\varphi: L^p \to (L^p)^{**}$ defined by
$$\langle \varphi(f), g\rangle = \langle g, f\rangle$$
which preserves norms. Moreover, if $p \in (1, \infty)$ then $\varphi$ is an isomorphism.
\end{corollary}
TODO

Henceforth, we simply write $L^p = (L^p)^{**}$ and $(L^p)^* = L^{p^*}$ (whenever these spaces are isomorphic!) to emphasize that these isomorphisms are in some sense ``natural"; they do not depend on a choice of basis.
In particular, we will always identify a function $f \in L^{p^*}$ with the corresponding linear map $f: L^p \to \CC$; to avoid writing awkward things like $f(g)$, we will continue to use $\langle f, g\rangle$ to mean the evaluation of $f$ at $g \in L^p$ when thinking of $f$ as a linear map.

\begin{corollary}
For every bounded linear map $\psi: L^2 \to \CC$ there is a unique $f \in L^2$ such that for every $g \in L^2$, $\langle f, g\rangle = \psi(g)$.
In particular, $\langle \cdot, \cdot \rangle$ is an inner product, making $L^2$ into a Hilbert space (TODO).
\end{corollary}

\begin{theorem}[H\"older duality, part II]
Let $p, q \in (1, \infty)$. Then for every bounded linear map $T: L^p \to L^q$ there is a unique bounded linear map $T^*: L^{q^*} \to L^{p^*}$ satisfying
$$\langle Tf, g\rangle = \langle f, T^*g\rangle.$$
\end{theorem}
\begin{definition}
The map $T^*$ is called the \dfn{adjoint} of $T$.
\end{definition}
TODO proof





\begin{exercise}
\label{dual space is banach}
Prove that if $X$ is a normed space, then $X^*$ is Banach.
\end{exercise}

\begin{exercise}
Show that $(\ell^1)^{**} \neq \ell^1$.
To do this, first show that if $(L^p)^*$ is separable, then $L^p$ is separable.
\end{exercise}

\begin{exercise}
Show that $(\ell^1)^{**} \neq \ell^1$ directly, by filling in the following outline.
Let $\mu: 2^\NN \to \{0, 1\}$ be an additive (but not $\sigma$-additive) function such that for every finite set $A \subset \NN$, $\mu(A) = 0$.
Here $\mu$ can be built using Zorn's lemma\footnote{Any proof of that $(\ell^1)^{**} \neq \ell^1$ must use the axiom of choice somehow, because in Solovay's model of set theory, wherein there are no nonmeasurable functions, there are also no elements of $(\ell^1)^{**}$ which are not elements of $\ell^1$.} or a similar substitute.
If $A \subseteq \NN$, one can define
$$\langle \mu, 1_A\rangle = \mu(A)$$
and then extend this definition to $\langle \mu, x\rangle$, whenever $x \in \ell^\infty$.
If $\mu$ is induced by an element of $\ell^1$, however, one can conclude a contradiction.
\end{exercise}

\section{Compactness of the unit ball}
An annoying technical difficulty with $L^p$ spaces is that, unlike $\CC^d$, the unit ball of $L^p$ is not compact (Exercise \ref{unit ball compactness}).
This is rather problematic: in many situations in analysis, one is given a sequence and needs to extract a limit point from the sequence.
In this section we use H\"older duality introduce a new topology on $L^p$ in which the unit ball is compact, but which does not arise from a norm.

\begin{definition}
Let $p \in (1, \infty)$. We say that a sequence $(f_n)_n \in L^p$ \dfn{converges weakly} in $L^p$ to $f \in L^p$ provided that
$$\lim_{n \to \infty} \langle f_n, g\rangle = \langle f, g\rangle$$
for every $g \in L^{p^*}$.
\end{definition}

To avoid confusion, we will say that a sequence \dfn{converges strongly} in $L^p$ if it converges in norm.
The words ``strong" and ``weak" are motivated by the following lemma:

\begin{lemma}
Let $p \in (1, \infty)$. If a sequence converges strongly in $L^p$, then it converges weakly in $L^p$.
\end{lemma}
\begin{proof}
One has
$$\langle f_n - f, g \rangle \leq ||f_n - f||_p ||g||_{p^*}$$
for every $g \in L^{p^*}$.
\end{proof}

The idea of weak convergence is the following. Say that $f(x)$ is the temperature of a bucket of water at point $x$.
Then one measures $f(x)$ by taking a thermometer, which we model by $g$, chosen so that the thermometer picks up the temperature in a small ball near $x$ (so $g$ has compact support centered near $x$).
Then the thermometer returns $\langle f, g\rangle$.
So $f_n \to f$ weakly in $L^p$ if for every thermometer $g \in L^{p^*}$, the thermometer $g$ thinks that the error $f_n - f$ is negligible.

We now show that weak convergence is induced by a topology, so it is in some sense ``better behaved" than, say, convergence almost pointwise.

\begin{definition}
Let $p \in (1, \infty)$ and $g \in L^{p^*}$.
We define the \dfn{weakstar seminorm}
$$p_g(f) = |\langle f, g\rangle|.$$
The \dfn{weakstar topology} on $L^p$ is the topology induced by the weakstar seminorms $\{p_g: g \in L^{p^*}\}$.
\end{definition}

The term ``weakstar" is motivated by the fact that the weakstar topology will induce weak convergence, and that the weakstar topology is induced by duality (hence ``star").

There are several suspicious things about this definition. First, we check that $p_g$ is a seminorm. Indeed, one has a triangle inequality
$$p_g(f_1 + f_2) = |\langle f_1 + f_2, g\rangle| = |\langle f_1, g\rangle + \langle f_2, g\rangle| \leq p_g(f_1) + p_g(f_2)$$
and also $p_g(cf) = cp_g(f)$.
We recall that a set of seminorms induces a topology: the open neighborhoods of $f_0 \in L^p$ are generated by sets of the form
$$B_g(f_0, \varepsilon) = \{p_g(f_0 - f) < \varepsilon\}$$
which are \dfn{open balls} for the seminorm $g$.

\begin{lemma}
A sequence (or net) converges weakly in $L^p$ iff it converges in every weakstar seminorm of $L^p$, which happens iff it converges in the weakstar topology of $L^p$.
\end{lemma}
\begin{proof}
The first equivalence is due to the definition of the weakstar seminorm; the latter is a general fact about topologies induced by seminorms.
\end{proof}

Now we come to the key fact about the weakstar topology.

\begin{theoremx}[Banach-Alaoglu compactness]
The closed unit ball of $L^p$ is compact in the weakstar topology.
\end{theoremx}

The general proof uses a black box in the form of Tychonoff's theorem\footnote{The general proof must use a particularly strong form of the axiom of choice, as most results about compactness of very large spaces must, so this is unavoidable.} so we start by proving a special case, which is the particularly useful one in practice.

\begin{theorem}[Alaoglu's sequential compactness theorem]
Suppose that $L^{p^*}$ is separable. Then for every bounded sequence $(f_n)_n$ in $L^p$, there is a $f \in L^p$ such that a subsequence $(f_{n_k})_k$ converges to $f$ weakly in $L^p$.
\end{theorem}
\begin{proof}
Let $D$ be a countable dense subset of the unit sphere $\{g \in L^{p^*}: ||g||_{p^*} = 1\}$ of $L^{p^*}$.
Let
$$d(f_1, f_2) = \sum_{g \in D} 2^{-n} p_g(f_1 - f_2).$$
Since $p_g(f_1 - f_2) \leq ||g||_{p^*} ||f_1 - f_2||_p$ and $||g||_{p^*} \leq 1$, we can sum the geometric series to conclude that $d(f_1, f_2) \leq 1$.
We claim that $d$ is a semimetric.\footnote{One can use Exercise \ref{weakstar is hausdorff} to show that $d$ is actually a metric, but we won't need this.}
We just need to check the triangle inequality, and indeed,
$$d(f_1, f_3) = \sum_{g \in D} 2^{-n} p_g(f_1 - f_3) \leq \sum_{g \in D} \frac{p_g(f_1 - f_2) + p_g(f_2 - f_3)}{2^n} = d(f_1, f_2) + d(f_2, f_3)$$
since $p_g$ is a seminorm.

\begin{lemma}
\label{weakstar semimetric}
A sequence converges in $d$ iff it converges weakly in $L^p$.
\end{lemma}
\begin{proof}
If $f_n \to f$ weakly in $L^p$ then for every $g \in L^{p^*}$, $p_g(f_n - f) \to 0$, so $d(f_n, f) \to 0$.

Conversely, if $(f_n)_n$ is a sequence in $L^p$ and $f \in L^p$, and $d(f_n, f) \to 0$, then $p_g(f_n - f) \to 0$ for every $g \in D$.
But if $||g||_{p^*} = 1$ is arbitrary, and $g_m \in D$ have $g_m \to g$, then
$$\lim_{n \to \infty} p_g(f_n - f) = \lim_{m \to \infty} \lim_{n \to \infty} p_{g_m}(f_n - f) = 0$$
so that $p_g(f_n - f) \to 0$ for every $g$ in the unit sphere, and hence in all of $L^{p^*}$ by rescaling.
\end{proof}

We now use a variant of Cantor's diagonal argument to show that the unit ball of $L^p$ under the semimetric $d$ is compact, which, along with Lemma \ref{weakstar semimetric}, implies Alaoglu's theorem.
Fix $(f_n)_n$, say $||f_n||_p \lesssim 1$, and an enumeration $(g_m)_m$ of $D$.
Then
$$|\langle f_n, g_1\rangle| \lesssim ||g_1||_{p^*} = 1$$
so by compactness of the closed unit ball of $\CC$, there is a subsequence $(f_{n_k^1})_k$ such that $(\langle f_{n_k^1}, g_1\rangle)_k$ is a Cauchy sequence.

Suppose we have defined $(f_{n_k^j})_k$; then $|\langle f_{n_k^j}, g_1\rangle| \lesssim 1$ so there is a subsequence $(f_{n_k^{j+1}})_k$ of $(f_{n_k^j})_k$ such that $(\langle f_{n_k^{j+1}}, g_{j+1}\rangle)_k$ is a Cauchy sequence.
Moreover, since $(f_{n_k^{j+1}})_k$ is a subsequence of $(f_{n_k^\ell})_k$ whenever $\ell \leq j$, $(\langle f_{n_k^{j+1}}, g_\ell\rangle)_k$ is also a Cauchy sequence.

Let $f_{n_k} = f_{n_k^k}$. Then for any $j$, after finitely many entries $(f_{n_k})_k$ is a subsequence of $(f_{n_k^j})_k$, so $(\langle f_{n_k}, g_j\rangle)_k$ is a Cauchy sequence, and hence we can set
$$\langle f, g_j\rangle = \lim_{k \to \infty} \langle f_{n_k}, g_j\rangle.$$
This defines $f$ as a map $D \to \CC$; then $f$ extends to a bounded linear map $L^{p^*} \to \CC$ uniquely, since $D$ was dense in the unit sphere of $L^{p^*}$.
By H\"older duality, this implies that $f \in (L^p)^{**} = L^p$.
By construction, $d(f_{n_k}, f) \to 0$, so the unit ball of $L^p$ is compact under the semimetric $d$.
\end{proof}

\begin{proof}[Proof of the Banach-Alaoglu theorem]
Let $B$ be the closed unit ball of $L^p$ and $B^*$ the closed unit ball of $L^{p^*}$.
Then any $f \in B$ maps $B^*$ into a closed subset of $D = \{z \in \CC: |z| \leq 1\}$.
Thus $B$ is a closed subset of the space $D^{B^*}$ of functions $B^* \to D$.
Moreover, the definition of the weakstar topology is exactly the definition of the product topology when restricted to $D^{B^*}$.
So $D^{B^*}$ is compact by Tychonoff's theorem and hence $B$, a closed subset of $D^{B^*}$, is as well.
\end{proof}

One application of compactness theorems, which we discuss in the exercises, is to show that certain PDE have solutions.
The idea is to consider a set of ``admissible functions" $\mathcal A$, show that $\mathcal A$ is compact in some function space $X$, and then show that an admissible function $u \in \mathcal A$ is a solution iff $u$ minimizes the norm $||u||_X$.
A famous example of this is the Riemann mapping theorem, which says that for every simply connected open set $U \subseteq \CC$ there is a holomorphic bijection with holomorphic inverse $U \to \{z \in \CC: z < 1\}$.
We sketch the relevant part of the proof of the Riemann mapping theorem in Exercises \ref{Ascoli} and \ref{Montel}, and the solution of Dirichlet's problem in Exercise \ref{Dirichlet problem 2}.

For the latter, we need a definition that we will use in some more exercises later on, and is of fundamental importance in applications.
Recall that $\nabla^iu$ is the vector of all partial derivatives of order $i$ of $u$, so $\nabla^iu: U \to \CC^{d^i}$ if $U \subseteq \RR^d$ is open and $u: U \to \CC$.
In particular, $\nabla^0u = 0$.
Since $\CC^{d^i}$ is a Banach space (of dimension $d^i$), one can consider the norms $||\nabla^iu||_{L^p}$.

\begin{definition}
Let $U \subseteq \RR^d$ be an open set and $s \in \NN$.
The \dfn{Sobolev norm} is the norm
$$||u||_{H^s(U)} = \sum_{i=0}^s ||\nabla u||_{L^2}.$$
The space $H^s(U)$ is the completion of the space of smooth functions $u: U \to \CC$ such that $||u||_{H^s(U)} < \infty$.
\end{definition}
In particular, a sequence $(u_n)_n$ converges (strongly) in $H^s$ (say, to $u$) if for every $i \in \{0, \dots, s\}$, $\nabla^iu \to u$ strongly in $L^2$.
One can also define weak convergence in $H^s$ by simply requiring that the derivatives converge weakly in $L^2$.

\begin{exercise}
\label{unit ball compactness}
Let $X$ be a Banach space. Show that the unit ball of $X$ is compact (in the norm topology, not the weakstar topology) iff $X$ is finite-dimensional.
\end{exercise}

\begin{exercise}
\label{weakstar is hausdorff}
Show that the weakstar topology is Hausdorff; that is, if $f_1, f_2 \in L^p$, then there are $g_1, g_2 \in L^{p^*}$ and a $\varepsilon > 0$ such that $B_{g_1}(f_1, \varepsilon) \cap B_{g_2}(f_2, \varepsilon)$ is empty.
\end{exercise}

\begin{exercise}[Riemann-Lebesgue]
Show that if $f_n(x) = \sin nx$, then $f_n \to 0$ weakly in $L^2([0, 2\pi])$ but not strongly.
\end{exercise}

\begin{exercise}
Show that if $f_n = 1_{\{n\}}$, then $f_n \to 0$ weakly in $\ell^2$ but not strongly.
\end{exercise}

\begin{exercise}[Banach-Saks]
Let $(x_n)_n$ be a bounded sequence in $L^2$. Show that there is a subsequence $(x_{n_k})_k$ and a $x \in L^2$ such that
$$\lim_{n \to \infty} \frac{1}{N} \sum_{k=1}^N x_{n_k} = x$$
strongly in $L^2$.
\end{exercise}

\begin{exercise}[Arzel\`a-Ascoli]
\label{Ascoli}
Modify the proof of Alaoglu's sequential compactness theorem to show that, if $X$ is a compact metric space, then $C(X)$ (with $L^\infty$ norm) satisfies the following result: a subset $A \subseteq C(X)$ is compact iff $A$ is closed, bounded, and \dfn{equicontinuous} in the sense that for every $\varepsilon > 0$ there is a $\delta > 0$ such that for every $f \in A$ and every $x_1,x_2 \in X$ if $d(x_1, x_2) < \delta$ then $|f(x_1) - f(x_2)| < \varepsilon$. (Here $\delta$ does not depend on $f$ or $x_1, x_2$.)
\end{exercise}

\begin{exercise}[Montel's little theorem -- for those who know complex analysis]
\label{Montel}
Let $U$ be an open subset of $\CC$, and let $\mathcal H(U)$ be the space of holomorphic functions $U \to \CC$.
Suppose that $\mathcal F \subset \mathcal H(U)$ is locally uniformly $L^\infty$; that is, for every compact set $K \subset U$ there is a $M_K > 0$ such that for every $f \in \mathcal F$, $||f|K||_\infty \leq M_K$.
(Hint: You may need to use Cauchy's integral formula and Exercise \ref{Ascoli}.)
Show that every sequence in $\mathcal F$ has a subsequence which converges in $L^\infty_l$.
\end{exercise}

\begin{exercise}[Banach-Alaoglu in Hilbert spaces]
\label{Banach-Alaoglu-Sobolev}
Let $H$ be any Hilbert space. Show that the unit ball of $H$ is weakstar compact.
\end{exercise}

\begin{exercise}[solving Dirichlet's problem]
\label{Dirichlet problem 2}
Let $U$ be an open subset of $\RR^d$ such that the boundary $\partial U$ is a smooth manifold, and let $f: \partial U \to \RR$ be a continuous function.
If you're not comfortable with smooth manifolds, you may assume that $U$ is a ball, in which case $\partial U$ is a sphere.
We are in the position to show that Dirichlet's problem, as defined in Exercise \ref{Dirichlet problem}, has a solution, if we are willing to take a result known as \dfn{Weyl's lemma} as a black box.

Let $\mathcal A$ be the admissible set, and let $E$ be the Dirichlet energy, defined in \ref{Dirichlet problem}.
Proceed as follows:
\begin{enumerate}
\item Let $(u_n)_n$ be a sequence of functions in $\mathcal A$ such that $E(u_n) \to \inf_{v \in \mathcal A} E(v)$.
Show that $(u_n)_n$ is a bounded sequence in $H^1$.
\item Show that if $(v_n)_n$ is a sequence of functions which converge in $H^1$ to a function $v \in H^1$, then $E(v_n) \to E(v)$.
\item Invoke Exercise \ref{Banach-Alaoglu-Sobolev}.
\item Show that if $u$ is smooth, then $u$ solves Dirichlet's problem iff for every smooth function $v$ which is zero in an open set containing $\partial U$,
\begin{equation}
\label{weak Dirichlet problem}
\langle u, \Delta v\rangle_{L^2} = 0.
\end{equation}
The problem of finding a $u \in L^2(U)$ (not necessarily smooth) such that for every smooth $v$ which is zero near $\partial U$, (\ref{weak Dirichlet problem}) holds, is called the \dfn{weak Dirichlet problem}.
\item Invoke Weyl's lemma, which says that if $u$ solves the weak Dirichlet problem and $\partial U$ is a smooth manifold, then $u$ is smooth.
\end{enumerate}
The above proof outline is quite common in PDE and its applications.
\end{exercise}


\section{Interpolation of operators}
TODO

\begin{exercise}[Riesz-Thorin interpolation in mixed norms]
Let $p_1,p_2,q_1,q_2,r \in [1, \infty]$. Let $T: L^{r_1} + L^{r_2} \to L^{p_0}(X \to L^{q_0}) + L^{p_1}(X \to L^{q_1})$ be a linear operator.
Establish the Riesz-Thorin inequality
$$||T||_{L^{r_\theta} \to L^{p_\theta}(X \to L^{q_\theta})} \leq ||T||_{L^{r_0} \to L^{p_0}(X \to L^{q_0})}^{1 - \theta} ||T||_{L^{r_1} \to L^{p_1}(X \to L^{q_1})}^\theta$$
whenever $\theta \in [0, 1]$.
\end{exercise}

\section{The mean ergodic theorem}
Let us give an application of the above theory to ergodic theory.

Throughout we fix a measure-preserving system $(\Omega, P, T)$.
Recall that by definition this consists of a probability space $(\Omega, P)$ and a measure-preserving map $T: \Omega \to \Omega$.
The measure-preserving system is ergodic if, for every event $A$, if $T^{-1}A \subseteq A$, then $A$ is either almost surely true, or almost surely false.

\begin{definition}
The \dfn{Koopman operator} $U$ acts on $L^2$ by $Uf = f \circ T$.
\end{definition}

Recall that a linear operator $L$ on an inner-product space is said to be an isometry if $\langle Lf, Lg\rangle = \langle f, g\rangle$.

\begin{lemma}
If $f \in L^2$ then
$$E(Uf) = Ef.$$
In particular, $U$ is unitary.
\end{lemma}
\begin{proof}
This is obvious if $f = 1_A$.
We can extend to simple functions by taking linear combinations, then use monotone convergence.
\end{proof}

\begin{definition}
The \dfn{time average} of $f$ is
$$A_nf = \frac{1}{n} \sum_{j=0}^{n-1} U^jf.$$
The \dfn{space average} of $f$ is $Ef$.
\end{definition}

The idea of time and space averages is as follows. Fix $x$, the state of the universe today. Then $T$ represents the passing of time from today to tomorrow.
Every day, we measure the random variable $f$, and their average after $n$ days is $A_nf(x)$.
Our goal will be to show that $A_nf \to Ef$ as long as $(\Omega, P, f)$ is ergodic, so in order to approximate the expected value of $f$, we can just keep testing $f$ every day over a long period of time and then take their mean.

To do this, we need two general facts about contractions on Hilbert spaces.
\begin{lemma}
Let $H$ be a Hilbert space, $U: H \to H$ a bounded linear operator such that $||U|| \leq 1$.
If $Ug = g$ then $U^*g = g$.
\end{lemma}
\begin{proof}
If $Ug = g$ then
$$0 = ||U^*g - g||^2 = ||U^*g||^2 - ||g||^2 \leq ||Ug||^2 - ||g||^2 = 0$$
so the inequalities collapse and $U^*g = g$.
\end{proof}

\begin{lemma}
Let $H$ be a Hilbert space, $U: H \to H$ a bounded linear operator such that $||U|| \leq 1$.
Let $V = \{f \in H: Uf = f\}$ and let $\Pi: H \to V$ be the orthogonal projection. Then
\begin{equation}
\label{invariant projection}
\lim_{n \to \infty} \frac{1}{n} \sum_{j=0}^{n-1} U^jf = \Pi(f).
\end{equation}
\end{lemma}
\begin{proof}
Consider the orthogonal decomposition
$$U = V \oplus V^\perp.$$
We can break up into the cases $f \in V$ and $f \in V^\perp$.
If $f \in V$ then obviously both sides of (\ref{invariant projection}) are $f$.
If $f \in V^\perp$, $\Pi(f) = 0$.
Also
$$||\frac{1}{n} \sum_{j=0}^{n-1} U^jf|| \leq ||f||$$
since $U$ is unitary, so the map $S_nf = n^{-1} \sum_{j=0}^{n-1} U^jf$ is bounded.
Therefore
$$g_n = \frac{S_n^*S_nf}{n^2}$$
is a bounded sequence. Since $H$ has a weakstar compact unit ball (Exercise \ref{Banach-Alaoglu-Sobolev}, though in the applications we need this is just the Banach-Alaoglu theorem in $L^2$), $g_n$ has a weakstar limit $g$.
Now
$$(1 - U^*)(S_n^*/n) = \frac{1}{n} \sum_{j=0}^{n-1} (1 - U^*)(U^*)^{j-1} = \frac{1 - (U^*)^n}{n}$$
satisfies
$$||(1 - U^*)(S_n^*/n)|| \lesssim n^{-1}$$
so $(1 - U^*)g_n \to 0$ and hence $(1 - U^*)g = 0$.
By the previous lemma, $Ug = g$. Therefore $f \perp g$, so $\Pi(f) = 0$.
\end{proof}

\begin{theorem}[mean ergodic theorem]
Let $f \in L^2$ and let $V = \{g \in L^2: Ug = g\}$.
Let $\Pi: L^2 \to V$ be the orthogonal projection.
Then
$$\lim_{n \to \infty} A_nf = \Pi(f)$$
in $L^2$.
\end{theorem}
\begin{proof}
Expanding out the definitions of $A_n$ and $\Pi$, we get (\ref{invariant projection}).
\end{proof}

This theorem is mainly interesting in the case that $(\Omega, P, T)$ is an ergodic system.
In that case, the only random variables in $V$ are constant almost surely, so $\Pi(f)$ is a constant.
TODO: Conditional expectation arguement -> $\Pi = E$.


\chapter{Harmonic analysis}

We now sketch some of the applications of measure theory to harmonic analysis as an example.
It is reasonable to take the results that we are using, most notably Fubini's theorem and the Riesz-Markov representation theorem, as a black box and peruse this section before we prove them, to get motivation for the utility of such results.

\section{Haar measures}
We begin by introducing measure theory on abelian groups. Recall that a group is called abelian if its group operation is commutative.
In that case we will usually write its operations additively; that is, if $G$ is an abelian group, we write $g_1 + g_2$ for the composition of $g_1$ and $g_2$, we let $-g$ denote the inverse of an element $g$, and let $0$ denote the identity of $G$, so that $g - g = 0$.

\begin{definition}
A \dfn{locally compact abelian group} $G$ is an abelian group $(G, +)$ equipped with a topology, under which it is locally compact and Hausdorff, $+$ is a continuous function $G \times G \to G$, and $g \mapsto -g$ is continuous.
\end{definition}

We note that the finite product of locally compact abelian groups is a locally compact abelian group.
Thus $\RR^d$ is a locally compact abelian group, as is the $d$-dimensional lattice $\ZZ^d$, and the $d$-dimensional torus $\Torus^d$.
In addition, any finite abelian group is a locally compact abelian group for the discrete topology (wherein every set is open).

We may define, for any set $A \subseteq G$, its translate
$$A + y = \{x + y \in G: x \in A\}.$$

\begin{definition}
A \dfn{Haar measure} on $G$ is a nonnegative Radon measure $\mu$ on $G$ with the following properties:
\begin{enumerate}
\item \dfn{Translation invariance}: For every Borel set $B$ and every $x \in G$, $\mu(B+x) = \mu(B)$.
\item \dfn{Normalization}: If $G$ is compact, then $\mu(G) = 1$.
\end{enumerate}
If $G$ is compact, we call $\mu$ a \dfn{Haar probability measure}.
\end{definition}

Let us give examples of Haar measure.
First, Lebesgue measure is a Haar measure on $\RR$ and on $\Torus$, and counting measure is a Haar measure on $\ZZ$.
On finite abelian groups $G$, we define the \dfn{uniform probability measure} $\mu(A) = |A|/|G|$ where $|\cdot|$ denotes cardinality.
The uniform probability measure of a finite abelian group is Haar.

Recall that if $G_1, G_2$ are abelian groups, then one can form a group $G_1 \oplus G_2$, called the direct sum of $G_1,G_2$, on the set $G_1 \times G_2$ by pointwise operations.
\begin{lemma}
\label{Haar product measure}
The finite product of Haar measures is a Haar measure on the direct sum.
\end{lemma}
\begin{proof}
See Exercise \ref{Haar product measure exercise}.
\end{proof}
Thus we have Haar measures on, for example, $\Torus^{d_1} \times \ZZ^{d_2}$.
One can extend this to infinite products, but the statement and proof become much trickier, for algebraic reasons (direct sum and direct product no longer coincide), set-theoretic reasons (the Borel and Baire $\sigma$-algebras no longer coincide, and one needs to use Tychonoff's theorem to show that the infinite product of compact spaces is compact), and topological reasons (the infinite product of locally compact spaces is not locally compact).
Since we will only ever need Haar measure in finite dimensions, we dodge these issues by restricting to finite products.

We now show that every locally compact abelian group has an essentially unique Haar measure.
\begin{theorem}
Let $G$ be a locally compact abelian group.
Then there is a Haar measure $\mu$ on $G$.
If $G$ is compact, then $\mu$ is unique.
Otherwise, if $\nu$ is another Haar measure, then there is a $c > 0$ such that $\nu = c\mu$.
\end{theorem}
TODO: Prove Haar's theorem using the Riesz-Markov theorem.

Henceforth if $G$ is a group, we will omit reference to its Haar measure and Borel $\sigma$-algebra whenever possible, writing $dx$ instead of $d\mu(x)$ in integrals for example, and $L^1(G)$ to mean $L^1(G, \mu)$.
Of course if $G$ is not compact then one could always rescale its Haar measure, but this is rarely important, so we might as well choose whatever normalization is convenient.

If $G$ is compact, then since Haar measure is a probability measure, we can refer to the expected value of a function $f \in L^1(G)$.
\begin{definition}
Let $\mu$ be a probability measure on a measurable space $X$, and $f \in L^1(X, \mu)$.
Define the \dfn{expected value} of $f$,
$$Ef = \int_X f~d\mu.$$
In this case we may refer to $f$ as a \dfn{random variable} drawn from $X$, and refer to $\mu(E)$ as the \dfn{probability} of $E$ whenever $E \subseteq X$ is measurable.
\end{definition}
Though we will not treat probability theory in detail, it will be at times convenient to use the language of probability theory when thinking about compact abelian groups.

\begin{exercise}
\label{Haar product measure exercise}
Prove Lemma \ref{Haar product measure}.
\end{exercise}

\begin{exercise}
Let $\mu$ be Lebesgue measure, and let $\nu$ be a Haar measure for the positive real numbers under multiplication.
Compute the Radon-Nikodym derivative of $\nu$ with respect to $\mu$.
\end{exercise}

\begin{exercise}
Let $G$ be a compact abelian group with Haar measure $\mu$, $E \subseteq G$ a Borel set such that $\mu(E) > 0$.
Show that for every $N \in \NN$ there are $g_1, \dots, g_N \in G$ such that
$$\mu\left(\bigcup_{n=1}^N g_n + E\right) \geq 1 - (1 - \mu(E))^N.$$
(Hint: what is the expected value of $\mu\left(\bigcup_{n=1}^N g_n + E\right)$?)
\end{exercise}

\section{The Fourier transform}
To motivate what follows, we first consider $\Torus$ and consider a smooth function $f: \Torus \to \CC$.
Such a function is in $L^\infty$ since $\Torus$ is compact, thus in $L^2$ since $\Torus$ has finite measure.
To ease notation, we identify $\Torus$ with $[0, 1)$ and $f$ with a periodic function on $[0, 1]$.

In applications, it is frequently useful to decompose $f$ into a linear combination of waves, namely
\begin{equation}
\label{fourier series}
f(x) = \sum_{\xi=-\infty}^\infty \hat f(\xi) e^{2\pi ix\xi}.
\end{equation}
For example, if the function $\hat f: \ZZ \to \CC$ has finite support, then $f$ really is just a linear combination of plane waves $e_\xi(x) = e^{2\pi i x\xi}$, which are extremely easy to work with in calculus since they are eigenfunctions of the derivative operator $u \mapsto u'$.
On the other hand, the waves $e_\xi$ are an orthonormal basis of $L^2(\Torus)$; that is,
$$\langle e_\xi, e_\eta\rangle = \int_\Torus e^{2\pi i x(\xi - \eta)} ~dx = \delta_\xi^\eta,$$
so the representation (\ref{fourier series}) converges for the norm of $L^2(\Torus)$, and $\hat f$ exists and is unique for any $f \in L^2(\Torus)$.
We can recover $\hat f$ from $f$ by taking the orthogonal projections
\begin{equation}
\label{fourier series 2}
\hat f(\xi) = \langle f, e_\xi\rangle = \int_\Torus f(x) e^{-2\pi ix\xi} ~dx.
\end{equation}
Putting together (\ref{fourier series}) and (\ref{fourier series 2}), we obtain the \dfn{Fourier inversion formula}
\begin{equation}
\label{fourier series 3}
f(x) = \sum_{\xi = -\infty}^\infty \int_\Torus f(y) e^{2\pi i(x-y)}~dy
\end{equation}
which is valid for any $f \in L^2(\Torus)$. Though at first this just seems like a trick using the structure of $L^2(\Torus)$, it suggests some sort of ``duality" between $\Torus$ and $\ZZ$.
Moreover, these ideas work in much higher generality.

Recall that if $G,H$ are abelian groups, a \dfn{morphism} $\psi: G \to H$ is a map $\psi$ such that for any $g_1, g_2 \in G$,
\begin{equation}
\label{morphism of groups}
\psi(g_1 + g_2) = \psi(g_1) + \psi(g_2).
\end{equation}
By $\CC^*$ we mean the group of nonzero complex numbers under multiplication. Thus $\CC^*$ is a locally compact abelian group.
We will write the group operation of $\CC^*$ multiplicatively, even though $\CC^*$ is abelian. Thus morphisms into $\CC^*$ satisfy the relation
$$\psi(g_1 + g_2) = \psi(g_1)\psi(g_2)$$
rather than (\ref{morphism of groups}).
We let $U(1)$ denote the subgroup of $\CC^*$ consisting of numbers of absolute value $1$; so $U(1)$ is isomorphic to $\Torus$, but is written multiplicatively rather than additively.
\begin{definition}
Let $G$ be a locally compact abelian group.
By a \dfn{character} of $G$ we mean a continuous morphism $G \to U(1)$.
\end{definition}
If $\xi_1, \xi_2$ are characters on a locally compact abelian group $G$, we define their sum
$$(\xi_1 + \xi_2)(g) = \xi_1(g)\xi_2(g).$$
It is straightforward to check that $\xi_1 + \xi_2$ is a character on $G$, and that $+$ defines the operation of an abelian group $\hat G$.

We want to be able to do measure theory on $\hat G$, so we need to turn it into a locally compact abelian group.
We recall that a sequence of continuous functions $f_n$ is said to converge uniformly provided that $f_n$ converges in $L^\infty$.
\begin{definition}
Let $\psi_n$ be a sequence of characters of a locally compact abelian group $G$.
We say that $\psi_n$ \dfn{converges locally uniformly} to a character $\psi$ if for every compact set $K \subseteq G$, the restrictions $\psi_n|K$ converge to $\psi|K$ uniformly on $K$.
\end{definition}
We now give $\hat G$ a suitable topology, by declaring that $\psi_n \to \psi$ in the topology of $\hat G$ iff $\psi_n \to \psi$ locally uniformly.

\begin{definition}
Let $G$ be a locally compact abelian group.
The \dfn{Pontryagin dual} $\hat G$ of $G$ is the locally compact abelian group of characters of $G$ under addition and locally uniform convergence.
\end{definition}

Later we will prove that $\widehat{\hat G} = G$. First, let us compute the Pontryagin duals of some familiar groups.

\begin{example}
Let $G$ be a finite abelian group. We claim that $G$ is isomorphic to $\hat G$. To see this, we first appeal to the classification of finite abelian groups to write
$$G \cong \frac{\ZZ}{n_1} \oplus \cdots \oplus \frac{\ZZ}{n_k}.$$
Here $\ZZ/n$ denotes the cyclic group of order $n$.
It is a straightforward exercise in group theory to see that this implies that
$$\hat G \cong \widehat{\frac{\ZZ}{n_1}} \oplus \cdots \oplus \widehat{\frac{\ZZ}{n_k}}$$
(indeed, it follows from the universal property of $\oplus$), so it suffices to check the claim when $G = \ZZ/n$.

Let $g$ be the generator of $\ZZ/n$ and let $kg = g + \cdots + g$ ($k$ copies of $g$).
A character $\xi: \ZZ/n \to \CC^*$ is determined by $\xi(g)$, and $1 = \xi(ng) = \xi(g)^n$ since $\ZZ/n$ is cyclic.
Therefore $\xi(g)$ is an $n$th root of unity $e^{2\pi i\ell/n}$.
If $\xi_j(g) = e^{2\pi i \ell_j/n}$, then $\xi_1(g) + \xi_2(g) = e^{2\pi i(\ell_1 + \ell_2)/n}$.
Since $\xi \mapsto \xi(g)$ is an injective function between two sets of the same cardinality, it is a bijection.
The map $\xi \mapsto \xi(g)$ therefore gives an isomorphism between $\widehat{\ZZ/n}$ and the group of $n$th roots of unity of $\CC^*$ under multiplication, the latter of which is isomorphic to $\ZZ/n$ since it is generated by $e^{2\pi i/n}$ and has $n$ elements.
\end{example}

\begin{example}
TODO: Duality of $\Torus$ and $\ZZ$.
\end{example}

We leave the following important duality result to the reader.
\begin{theorem}
The map $\eta: \RR \to \hat \RR$ defined by $\eta(\xi)(x) = e^{2\pi ix\xi}$ is an isomorphism.
\end{theorem}

Motivated by the duality of $\Torus$ and $\ZZ$, we now define the Fourier transform, a generalization of the Fourier series to arbitrary locally compact abelian groups.
\begin{definition}
Let $G$ be a locally compact abelian group, and $f \in \ISF(G)$. The \dfn{Fourier transform} $\hat f$ of $f$ is defined by
$$\hat f(\xi) = \int_G f(x) \xi(-x)~dx.$$
We extend the Fourier transform to all of $L^2(G)$ by density.
\end{definition}
It is not obvious that the above definition makes sense. Certainly if $f \in \ISF(G)$ then the definition of $\hat f$ is uncontroversial, but why does it extend to $L^2(G)$?
This happens because of the following theorem:
\begin{theorem}[Plancherel]
TODO:https://www.math.ucla.edu/~tao/247b.1.07w/notes9.pdf
need to prove Fourier inversion first
\end{theorem}


\section{Pontryagin duality}

\section{The Fourier transform on $\RR^d$}

blah blah

\begin{exercise}
If $\mu$ is a Borel probability measure on $\RR$, we can define its \dfn{Fourier transform} by
$$\hat \mu(\xi) = \int_{-\infty}^\infty e^{-ix\xi} ~d\mu(x).$$
Assume that $\mu$ is absolutely continuous, and its Radon-Nikodym derivative with respect to Lebesgue measure is denoted $\mu'$. Show that
$$\mu'(x) = \frac{1}{2\pi} \int_{-\infty}^\infty e^{ix\xi} \hat \mu(\xi)~d\xi.$$
(Hint: Let $\varphi$ be a suitably chosen Schwartz function and let $F(x) = \mu((-\infty, x])$ be the \dfn{cumulative distribution function} of $\mu$. Show that
$$F(x) = \lim_{\varepsilon \to 0} \frac{1}{2\pi} \int_{-\infty}^x \int_{-\infty}^\infty e^{iy\xi} \varphi(\varepsilon^2 \xi^2) \hat \mu(\xi) ~d\xi ~dy$$
and commute the limit with the iterated integral.)
Conclude that you have given an alternative proof of the Radon-Nikodym theorem for Lebesgue measure.
\end{exercise}

\begin{exercise}[Hausdorff-Young inequality]
Show that if $p^*$ is the H\"older dual to $p$ and $p \in [1, 2]$ then for every Schwartz function $f$,
$$||\hat f||_{L^{p^*}(\RR^d)} \leq ||f||_{L^p(\RR^d)},$$
so the Fourier transform can be extended to a linear map $L^p(\RR^d) \to L^{p^*}(\RR^d)$.
\end{exercise}

\begin{exercise}[restriction estimates]
Suppose that $p \in [1, 2]$ and $q \in [1, \infty]$.
Let $\sigma$ denote Lebesgue measure on the unit sphere $S^{d-1}$ (defined in Exercise \ref{Lebesgue measure on sphere}).
Suppose that, for every Schwartz function $f$, the \dfn{restriction estimate}
$$||\hat f||_{L^q(S^{d-1}, \sigma)} \lesssim ||f||_{L^p(\RR^d)}$$
holds.
Show that for every $f \in L^p(\RR^d)$, the restriction $\hat f|S^{d-1}$ is defined for $\sigma$-almost every point of $S^{d-1}$.
Restriction estimates are an active area of research in harmonic analysis; the above restriction estimate is valid whenever $p = 2$ and $q \in [1, 4d/(3d+1)]$.
\end{exercise}

\begin{exercise}
\label{general Sobolev space}
Let $s \in \RR$. Define the \dfn{Sobolev measure} $\mu_s$ so that its Radon-Nikodym derivative with respect to Lebesgue measure is $(1 + |\xi|^s)^2$.
Show that for any $s \in \NN$ and $u \in H^s(\RR^d)$ one has
$$||u||_{H^s} \lesssim ||u||_{L^2(\mu_s)} \lesssim ||u||_{H^s}.$$
So we define the \dfn{Sobolev norm} $H^s$, $s$ any real number, by setting $||u||_{H^s} = ||u||_{L^2(\mu_s)}$.
This allows us to define the \dfn{Sobolev space} $H^s$ in general.
\end{exercise}

\begin{exercise}
This Exercise should be done after Exercise \ref{general Sobolev space}.
Let $s \in \RR$. Show that there is an isomorphism $(H^s)^* \to H^{-s}$ -- so while we can think of $H^s$ as its own dual (since $H^s$ is a Hilbert space), we can also think of $H^{-s}$ and $H^s$ as dual spaces.
\end{exercise}

\begin{exercise}
Let $a: \RR^2 \to \CC$ be a smooth function such that $a \in L^\infty$ and all partial derivatives of $a$ are in $L^\infty$.
Define the \dfn{pseudodifferential operator}
$$Af(x) = \int_{-\infty}^\infty a(x, \xi) \hat f(\xi) e^{ix\xi}~d\xi.$$
We call $A$ the \dfn{Kohn-Nirenberg quantization} of $a$, and $a$ the \dfn{symbol} of $A$.
Show that $Af$ exists whenever $f \in \Sch(\RR)$ and $A$ maps $\Sch(\RR)$ to itself.
Show that the Kohn-Nirenberg quantization $a(x, \xi) = x$ satisfies $Af(x) = xf(x)$, and the Kohn-Nirenberg quantization of $a(x, \xi) = \xi$ satisfies $Af = f'$, up to a multiplicative constant.
\end{exercise}

\section{Applications to quantum mechanics}
The following three sections are independent of each other. We include this section first because it is arguably the easiest of the three.
Here we prove the uncertainty principle of Heisenberg, which says that one cannot know both the position and the momentum of a subatomic particle.

In quantum mechanics, one typically models a particle $P$ with one degree of freedom by a Schwartz function $f$, its \dfn{wavefunction}, such that $||f||_{L^2} = 1$.
If $A \subseteq \RR$ is Borel, the probability of measuring that $P$ is inside $A$ is $||f||_{L^2(A)}$.
Moreover, the momentum of $P$ also has a wavefunction, given by $\hat f$; the probability of measure that the momentum of $P$ is inside $A$ is $||\hat f||_{L^2(A)}$.

We now introduce the \dfn{position} operator $Xf(x) = xfx$ and \dfn{momentum} operator $Df(x) = f'(x)/2\pi i$. By Lemma TODO, $D$ is the conjugation of $X$ by the Fourier transform, as one might expect. Notice that $X,D$ both preserve Schwartz space.

Now if we have two operators $A,B$ on Schwartz space, we can introduce their \dfn{commutator} $[A,B] = AB - BA$. The commutator measures how badly $A,B$ fail to commute.
In the case of position and momentum, the answer is ``quite badly".

\begin{theorem}[von Neumann's canonical commutation relations]
One has
$$[X, D] = -\frac{1}{2\pi i}.$$
\end{theorem}
This can be easily verified by the reader using the product rule for differentiation.

We now recall that the expected value of a random variable is its mean value. We leave it as an exercise to check that the expected value of the position of a particle with wavefunction $f$ is
$$\int_{-\infty}^\infty x|f(x)|^2~dx.$$
Similarly,
$$\int_{-\infty}^\infty \xi|\hat f(\xi)|^2~d\xi$$
is the expected value of the momentum.
In statistics, one defines the variance of a random variable $A$ to be the difference between the expected value of $A^2$ and the expected value of $A$, squared.
This is a measure of how far a ``typical" measurement will deviate from the expected value.
TODO: Move to probability ch?

TODO: Heisenberg

\section{Applications to PDE}
TODO: Elliptic equation have solutions

\section{Applications to number theory}
In this section we use the theory that we have developed thus far to prove the famous functional equation for the Riemann zeta function.
The proof technique is of great importance to number theory, where it leads one into the theory of modular forms, $L$-functions, the Langlands program, and Tate's thesis.
However, the author confesses complete ignorance of such matters, and refers the brave reader to TODO:Cite.

We start by recalling the basic definitions from number theory.
\begin{definition}
The \dfn{Riemann zeta function} is the function
$$\zeta(s) = \sum_{n=1}^\infty n^{-s},$$
defined when $\Re s > 1$.
\end{definition}
Then $\zeta$ is holomorphic in the half-plane $\Omega = \{s \in \CC: \Re s > 1\}$.
Indeed, the summands $n^{-s}$ are holomorphic in $s$ and the partial sums converge locally uniformly in $\Omega$ (that is, converge in $L^\infty(K)$ for any compact $K \subset \Omega$), and the locally uniform limit of holomorphic functions is holomorphic (TODO:Cite a complex analysis book).
This function is interesting to number theorists because of the following theorem.

\begin{theorem}[Euler's product formula]
For every $s \in \Omega$,
$$\zeta(s) = \prod_p \frac{1}{1 - p^{-s}},$$
where the product ranges over all prime numbers $p$.
\end{theorem}
\begin{proof}
We induct on the primes. First,
$$\frac{1}{2^s} \zeta(s) = \sum_{n \equiv 0 \mod 2} n^{-s}$$
so
$$\zeta(s)\left(1 - \frac{1}{2^s}\right) = \sum_{n \not \equiv 0 \mod 2} n^{-s}.$$
Now suppose that $q$ is a prime and
\begin{equation}
\label{partial euler product}
\zeta(s) \prod_p 1 - \frac{1}{p^s} = \sum_n n^{-s}
\end{equation}
where the product is taken over all primes $p < q$, and the sum is taken over all $n$ such that for each prime $p < q$, $n \not \equiv 0 \mod p$.
Then
$$\frac{1}{q^s} \zeta(s) \prod_p 1 - \frac{1}{p^s} = \sum_n n^{-s}$$
where the product is again taken over all primes $p < q$ and the sum is taken over all $n$ such that $n \equiv 0 \mod q$ and for each prime $p < q$, $n \not \equiv 0 \mod p$.
Therefore (\ref{partial euler product}) holds when the product is taken over all primes $p \leq q$ and the sum is taken over all $n$ such that for every $p \leq q$, $n \not \equiv 0 \mod p$.
This completes the induction.
Taking $q \to \infty$ in (\ref{partial euler product}) we see that
$$\zeta(s) \prod_p 1 - \frac{1}{p^s} = 1$$
where the product is taken over all primes $p$ and the infinite product converges by a monotone convergence argument (since $\sum_n n^{-s}$, the sum taken over all natural numbers $n$, converges). Indeed, $1 \not \equiv 0 \mod p$ for any prime $p$, but any $n \geq 2$ eventually divides some prime.
The claim now follows.
\end{proof}

Now recall that the \dfn{gamma function} is the function
$$\Gamma(z) = \int_0^\infty x^{z-1} e^{-x} ~dx$$
which converges if $\Re z > 0$.
\begin{definition}
Define the \dfn{Riemann xi function}
$$\xi(s) = \pi^{-s/2} \Gamma(s/2) \zeta(s).$$
\end{definition}

\begin{theorem}[Riemann's functional equation]
For any $s \in \Omega$,
\begin{equation}
\label{functional equation}
\xi(s) = \xi(1-s).
\end{equation}
Therefore $\xi(s)$, and hence $\zeta(s)$, can be defined for any $s \neq 1$, and $\zeta$ extends to a holomorphic function on $\CC \setminus \{1\}$.
\end{theorem}
Riemann's functional equation was first conjectured by Euler, and is one of the cornerstones of number theory.
One of the most fundamental open problems in mathematics is the \dfn{Riemann hypothesis}, which asserts that if $s$ is a zero of $\zeta$ with $\Re s \in [0, 1]$, then $\Re s = 1/2$.
If the Riemann hypothesis were true, then it would give sharp bounds on the growth of the prime-counting function.

We prove (\ref{functional equation}) later in this section; the holomorphy claim is easy to check for any student of complex analysis once (\ref{functional equation}) is established.
First we relate (\ref{functional equation}) to harmonic analysis.

We shall recall some algebraic machinery.
The trivial group is denoted $0$; for any group $G$, there are unique morphisms $0 \to G$ and $G \to 0$, namely the trivial morphism, which we leave unlabeled when clear from context.
We let $0$ denote the trivial morphism between any two groups when we do need to specify it.

A \dfn{short exact sequence} of abelian groups is a commutative diagram
$$\begin{tikzcd}
0 \arrow[r] & A \arrow[r,"\alpha"] & B \arrow[r,"\beta"] & C \arrow[r] & 0
\end{tikzcd}$$
where $A,B,C$ are abelian groups, all the arrows are morphisms, and the kernel of any arrow is the image of the arrow before it.
This is equivalent to requiring that $\alpha$ is injective, $\beta$ is surjective, and the image of $\alpha$ is the kernel of $\beta$, thus for any $b \in B$, $\beta(b) = 0$ iff there is an $a \in A$ with $b = \alpha(a)$.
Whenever $B$ is a subgroup of $A$, we get a short exact sequence
\begin{equation}
\label{quotient SES}
\begin{tikzcd}
0 \arrow[r] & B \arrow[r,"\iota"] & A \arrow[r,"q"] & \frac{A}{B} \arrow[r] & 0
\end{tikzcd}
\end{equation}
where $\iota$ is the inclusion map $\iota(b) =b$ and $q$ is the quotient map.

If $\alpha: A \to B$ is a continuous morphism between locally compact abelian groups, then we can define its Pontraygin dual $\hat \alpha: \hat B \to \hat A$ by
$$\hat \alpha(\xi) = \xi \circ \alpha.$$
Note that this is not the same as taking the Fourier transform of $\alpha$; we will always use Roman letters for functions and Greek letters for morphisms, to avoid confusion.
If $B \subseteq A$, and $\iota: B \to A$ is the inclusion morphism $\iota(b) = b$, then $\hat \iota(\xi) = \xi \circ \iota = \xi|B$, thus $\hat \iota$ is the restriction map $\hat A \to \hat B$.

\begin{theorem}
\label{duality is exact}
Pontraygin duality is \dfn{exact} in the sense that whenever one has a diagram of locally compact abelian groups and continuous morphisms between them
$$\begin{tikzcd}
A \arrow[r,"\alpha"] & B \arrow[r, "\beta"] & C
\end{tikzcd}
$$
such that the image of $\alpha$ is the kernel of $\beta$, then the image of $\hat \beta$ is the kernel of $\hat \alpha$.
\end{theorem}
\begin{proof}
Let $H = \hat \beta(\hat C)$. Then $\hat \beta \circ \hat \alpha = \widehat{\beta \circ \alpha} = \hat 0 = 0$. Therefore $H \subseteq \ker \hat \alpha$.
Applying the Pontraygin duality theorem, we see that if $H \subset \ker \hat \alpha$ then $\widehat{\ker \hat \alpha} = \alpha(A)$ is a proper subgroup of $\hat H = \ker \beta$, which is impossible.
\end{proof}

\begin{corollary}
\label{duality is exact 2}
Let $A$ be a locally compact abelian group, $B$ a closed subgroup of $A$.
Then the Pontraygin dual of (\ref{quotient SES}),
$$
\begin{tikzcd}
0 \arrow[r] & \widehat{\frac{A}{B}} \arrow[r,"\hat q"] & \hat A \arrow[r,"\hat \iota"] & \hat B \arrow[r] & 0,
\end{tikzcd}$$
is a short exact sequence of locally compact abelian groups.
\end{corollary}
\begin{proof}
This immediately follows from Theorem (\ref{duality is exact}).
The reader can check that since $B$ is closed, all the morphisms are continuous and $A/B$ is a locally compact abelian group.
\end{proof}

\begin{theorem}[Poisson summation]
Let $B$ be a closed subgroup of a locally compact abelian group $A$.
If $f \in L^1(A)$ let
$$f^B(x + B) = \int_B f(x + y)~dy.$$
Then for any $\xi \in \widehat{A/B}$, $\widehat{f^B}(\xi) = \hat f([\xi])$
where $[\xi](x) = \xi(x + B)$ for any $x \in A$.

If $f^B \in L^1(\widehat{A/B})$, then for almost all $x \in G$
\begin{equation}
\label{abstract poisson summation}
\int_B f(x + y)~dy = \int_{\widehat{A/B}} \hat f([\xi]) [\xi](x) ~d\xi.
\end{equation}
If $f^B$ is continuous and everywhere defined, then (\ref{abstract poisson summation}) is valid for every $x \in G$.
\end{theorem}
\begin{proof}
If $\xi \in \widehat{A/B}$ then $\xi|B = 0$. Indeed, $\xi|B = \hat \iota(\xi) = \hat \iota(\hat q(B)) = 0$, by Corollary \ref{duality is exact 2}.
Therefore $\xi(x + y) = \xi(x)$ for any $(x, y) \in A \times B$.
So
\begin{align*}\widehat{f^B}(\xi) &= \int_{A/B} f^B(x + B) \overline{\xi(x)}~d(x + B)\\& = \iint_{A/B \times B} f(x + y) \overline{\xi(x + y)}~dy~d(x+B) \\&= \int_A f(x)\overline{[\xi](x) + B}~dx = \hat f([\xi]).\end{align*}

Now if $f^B \in L^1(\widehat{A/B})$, then by the Fourier inversion formula,
$$f^B(x + B) = \widehat{\hat f|\widehat{A/B}}(-x + B) = \int_{\widehat{A/B}} \hat f([\xi]) \overline{[\xi](x)}~d\xi$$
almost everywhere, and everywhere under the necessary hypotheses.
Substituting the definition of $f^B$ in the above equation we obtain (\ref{abstract poisson summation})
\end{proof}

\begin{corollary}[Poisson summation on $\RR$]
\label{poisson summation on R}
Let $f$ be a Schwartz function on $\RR$. Then for every $x \in \RR$,
\begin{equation}
\label{poisson summation on R 2}
\sum_{k=-\infty}^\infty f(x + k) = \sum_{\xi = -\infty}^\infty \hat f(\xi) e^{-2\pi ix\xi}.
\end{equation}
\end{corollary}
\begin{proof}
Plugging $\RR$ and $\ZZ$ into (\ref{quotient SES}) we obtain a short exact sequence
$$\begin{tikzcd}
0 \arrow[r] & \ZZ \arrow[r] & \RR \arrow[r] & \Torus \arrow[r] & 0.
\end{tikzcd}$$
Dualizing, we obtain a bijection $\ZZ \to \widehat{\Torus} = \ZZ$.
Since $f$ is Schwartz, $f \in L^1(\RR)$ and $\hat f$ is Schwartz, so that $\hat f|\ZZ \in L^1(\ZZ)$.
Then plugging in $f$ into (\ref{abstract poisson summation}) we obtain (\ref{poisson summation on R 2}).
\end{proof}

\begin{corollary}
Let $f$ be a Schwartz function on $\RR$. Then
\begin{equation}
\label{poisson summation on R simple}
\sum_{k=-\infty}^\infty f(k) = \sum_{\xi = -\infty}^\infty \hat f(\xi).
\end{equation}
\end{corollary}

\begin{definition}
Define, for $\Re z > 0$,
$$\Theta(z) = \sum_{k=-\infty}^\infty e^{-z\pi k^2},$$
the \dfn{Jacobi theta function} of one variable.
\end{definition}

\begin{lemma}
\label{functional equation of the theta function}
For every $\Re z > 0$,
$$\sqrt z \Theta(z) = \Theta(z^{-1}).$$
\end{lemma}
\begin{proof}
By uniqueness of analytic continuation, a theorem of complex analysis, it suffices to check when $\Im z = 0$. Let $f_z(x) = e^{-z\pi x^2}$. Then $\hat f_1 = f_1$ by Lemma TODO, so by Lemma TODO,
$$\sqrt z \hat f_z = f_{1/z}.$$
Moreover, $f_z$ is Schwartz, so the claim now follows by applying (\ref{poisson summation on R simple}).
\end{proof}

\begin{proof}[Proof of (\ref{functional equation})]
Note that $dt/t$ is the Haar measure of $\RR^+$, the positive real numbers under multiplication. One has
$$\xi(s) = \sum_{n=1}^\infty \int_0^\infty n^{-s} t^{s/2} \pi^{-s/2} e^{-t}~\frac{dt}{t} = \sum_{n=1}^\infty \int_0^\infty \left(\frac{t}{n^2\pi}\right)^{s/2}e^{-t}~\frac{dt}{t}.$$
Simplifying, we see that
$$\xi(s) = \int_0^\infty t^{s/2} \frac{\Theta(t) - 1}{2}~\frac{dt}{t} = \left[\int_0^1 + \int_1^\infty \right]t^{s/2} \frac{\Theta(t) - 1}{2}~\frac{dt}{t}.$$
Now $\Theta - 1$ is Schwartz, so the integral over $[1, \infty]$ converges locally uniformly in $s$, hence to an entire function in $s$.
Applying the transform $t \mapsto 1/t$, which preserves the Haar measure of $\RR^+$, and using Lemma \ref{functional equation of the theta function},
$$\int_0^1 t^{s/2} \frac{\Theta(t) - 1}{2}~\frac{dt}{t} = \int_1^\infty t^{-s/2} \frac{\sqrt t \Theta(t) - 1}{2}~\frac{dt}{t}$$
thus
$$\xi(s) = \int_1^\infty t^{s/2} \frac{\Theta(t) - 1}{2}~\frac{dt}{t} + \int_1^\infty t^{(1-s)/2} \frac{\Theta(t) - 1}{2}~\frac{dt}{t} + \frac{1}{2} \left[\int_1^\infty t^{(1-s)/2} \frac{dt}{t} - \int_1^\infty t^{-s/2}\frac{dt}{t} \right].$$
But
$$-\frac{1}{2} \left[\int_1^\infty t^{(1-s)/2} \frac{dt}{t} - \int_1^\infty t^{-s/2}\frac{dt}{t} \right] = \frac{1}{s} + \frac{1}{1-s}.$$
Therefore
\begin{equation}
\label{partial functional equation}
\xi(s) = \int_1^\infty t^{s/2} + t^{(1-s)/2}\frac{\Theta(t) - 1}{2} ~\frac{dt}{t} - \left(\frac{1}{s} + \frac{1}{1-s}\right).
\end{equation}
The right-hand side of (\ref{partial functional equation}) does not change when one replaces $s$ with $1-s$, thus $\xi(s) = \xi(1-s)$.
\end{proof}

\appendix
\chapter{Linear algebra}
\section{Normed spaces}
The reader should be familiar with this material before reading Chapter \ref{measureChapter}.

When one first learns what a ``vector" is, they are told that a vector is comprised of a length and a direction.
However, the algebraic definition of a vector space does not satisfy this property; nothing in the definition of a vector space allows one to canonically assign lengths to vectors.
In this section we correct this matter by introducing a notion of length.

We take all vector spaces to be over the real numbers $\RR$ or the complex numbers $\CC$ (preferably the latter).
We let $[0, \infty)$ denote the nonnegative real numbers.

\begin{definition}
A \dfn{seminormed space} is a vector space $V$ equipped with a function
\begin{align*}V &\to [0, \infty)\\
v &\mapsto ||v||,\end{align*}
known as a \dfn{seminorm}, such that for any $v, w \in V$ and $c$ a scalar,
$$||v + w|| \leq ||v|| + ||w||,$$
the \dfn{triangle inequality}, and
$$||cv|| = |c|\cdot||v||.$$
The quantity $||v||$ is called the \dfn{length} of $v$.

A \dfn{normed space} is a seminormed space $V$ such that the only $v \in V$ such that $||v|| = 0$ is $v = 0$.
A seminorm with this property is called a \dfn{norm}.
\end{definition}

Every vector space can be turned into a seminormed space in a trivial way, namely by setting $||v|| = 0$ for every $v$.
However, we willl have no use for this.

\begin{example}
The most important example of a normed space has as its base space $\RR^d$.
We define
$$||(x_1, \dots, x_d)||_2^2 = \sum_{i=1}^d |x_i|^2,$$
thus $||\cdot||_2$ is the \dfn{Euclidean norm} on $\RR^d$.
Then the triangle inequality is just the usual triangle inequality for Euclidean geometry.
\end{example}

\begin{example}
We can define several other norms on $\RR^d$, closely related to the Euclidean norm $||\cdot||_2$. First we let
$$||(x_1, \dots, x_d)||_\infty = \max_{i=1}^d |x_i|.$$
We then define, for any $p \in [1, \infty),$
$$||(x_1, \dots, x_d)||_p^p = \sum_{i=1}^d |x_i|^p.$$
Thus when $p = 2$ we recover the Euclidean norm, when $p = 1$ we recover the ``sum norm" $||(x_1, \dots, x_d)||_1 = \sum_i |x_i|$, and in the limit $p \to \infty$ we obtain the $||\cdot||_\infty$ norm.
\end{example}

A normed space is a metric space in a natural way, namely the distance between two vectors $v,w$ is defined to be $||v - w||$.
Thus we have access to the usual notion of sequences, convergence, etc. for normed spaces; so the equation
$$\lim_{n \to \infty} v_n = w$$
means that for every $\varepsilon > 0$ there is an $N$ such that for every $n \geq N$, $||v_n - w|| < \varepsilon$.
Similarly a sequence of $v_n$ is Cauchy if for every $\varepsilon > 0$ there is an $N$ such that for every $n, n' \geq N$, $||v_n, v_{n'}|| < \varepsilon$.

The notion of convergence makes sense in seminormed spaces, but it is no longer true that the limit of a sequence need be unique.
In fact, consider the seminorm on $\RR^2$ defined by
$$||(x, y)|| = |x|.$$
Let $(x_n, y_n)_n$ be a sequence in $\RR^2$ and $x \in \RR$. Then for every $\lim_n x_n = x$, then for every $y \in \RR$, $\lim_n (x_n, y_n) = (x, y)$.
In the language of point-set topology, seminormed spaces are not Hausdorff (nor do they even satisfy Axiom $T_0$).

We fix the problem with seminormed spaces by observing that it is always possible to turn a seminormed space into a normed space.
\begin{theorem}
\label{existence of normalization}
For every seminormed space $V$ there is a normed space $V'$, called the \dfn{normalization} of $V$, such that:
\begin{enumerate}
\item There is a surjective linear map $\pi: V \to V'$.
\item For every normed space $W$ and every linear map $T: V \to W$ such that for every $v$, $||Tv|| = ||v||$, there is a linear map $T': V/\ker V \to W$ such that $||T'v|| = ||v||$ and the diagram
\begin{equation}
\label{normification universal}
\begin{tikzcd}
V \arrow[rr,"T"] \arrow[dr,"\pi"] && W\\
& \frac{V}{\ker V} \arrow[ur,"T'"]
\end{tikzcd}
\end{equation}
commutes.
\end{enumerate}
\end{theorem}
In the language of category theory, the diagram (\ref{normification universal}) is called the \dfn{universal property of the normalization}.
In category theory one proves that whenever an algebraic object satisfies a universal property, the object is unique up to a unique choice of isomorphism.
Thus the normalization (and the closely related completion that we discuss in Theorem \ref{completion exists}) is unique.

The reader should omit the proof of Theorem \ref{existence of normalization} on first reading.
\begin{proof}[Proof of Theorem \ref{existence of normalization}]
In fact, we define the \dfn{kernel} of a seminormed space $V$ by $\ker V = \{v \in V: ||v|| = 0\}$.
The kernel is a subspace of $V$, so we can take the quotient space $V/\ker V$ and form a short exact sequence
\begin{equation}
\label{normification exact}
\begin{tikzcd}
0 \arrow[r] & \ker V \arrow[r] & V \arrow[r,"\pi"] & \frac{V}{\ker V} \arrow[r] & 0
\end{tikzcd}
\end{equation}
(so the composite of any two arrows in the diagram (\ref{normification exact}) is the zero map, $\pi$ is the natural projection of $V$ onto $V/\ker V$, and $\ker V$ is the kernel of $\pi$).
We define a norm on $V/\ker V$ by
$$||\pi(v)|| = ||v||.$$
We define the normalization of $V$ to be $V/\ker V$.

To check the universal property, let $T: V \to W$ be a linear map into a normed space $W$ such that $||Tv|| = ||v||$.
In particular, if $v \in \ker V$, $||Tv|| = 0$ so $Tv = 0$ and hence $v \in \ker T$.
Thus we may define $T'(\pi(v)) = Tv$; this is well-defined because if $\pi(v) = \pi(v')$, then $v - v' \in \ker V$ and hence in $\ker T$.
\end{proof}

We conclude this section with a useful consequence of the triangle inequality.
\begin{lemma}[reverse triangle inequality]
For every $v, w$ in a normed space,
$$|||v|| - ||w||| \leq ||v - w||.$$
\end{lemma}
\begin{proof}
One has
$$||v|| = ||v + w - w|| \leq ||v - w|| + ||w||$$
so
$$||v|| - ||w|| \leq ||v - w||.$$
Similarly,
$$||w|| - ||v|| \leq ||v - w||.$$
But $\max(||v|| - ||w||, ||w|| - ||v||) = |||v|| - ||w|||$.
\end{proof}

\section{Banach spaces}
\label{Banach space appendix}
The reader should be familiar with this material before reading Chapter \ref{measureChapter}.

The defining property of $\RR$ is that every Cauchy sequence in $\RR$ converges.
However, this property is not true for normed spaces, as the following example will show.
\begin{example}
Let $C[0, 1]$ denote the vector space of continuous functions $[0, 1] \to \CC$.
We turn $C[0, 1]$ into a normed space by introducing a Euclidean-type norm,
$$||f||_2^2 = \int_0^1 |f(x)|^2 ~dx.$$
It is easy to check that $||f||_2$ is a seminorm, and to see that it is a norm, note that if $\int_0^1 |g| = 0$, then for every $\varepsilon > 0$ there is a partition of $[0, 1]$ into intervals $I_1, \dots, I_n$ such that for every $i$, the length of $I_i$ is $<\varepsilon$ and the midpoint $I_i^*$ of $I_i$ satisfies $|g(I_i^*)| < \varepsilon$.
Thus the set of points $x$ such that $|g(x)| < \varepsilon$ is $\varepsilon$-dense (i.e. for every $y$ there is an $x$ such that $|x - y| < \varepsilon$ and $|g(x)| < \varepsilon$).
Taking $\varepsilon \to 0$ we see that the set of points $x$ such that $g(x) = 0$ is dense (i.e. for every $\delta > 0$ and every $y$ we can find an $x$ with $|x - y| < \delta$ and $g(y) = 0$).
But $g$ is continuous so $g = 0$.

Now define
$$f_n(x) = \begin{cases}
0, &x \leq 1/2 - 1/n\\
n(x - 1/2 - 1/n), &1/2 - 1/n \leq x \leq 1/2 + 1/n\\
2, &x \geq 1/2 + 1/n
\end{cases}.$$
TODO: Draw a picture
To see that $(f_n)_n$ is Cauchy, note that if $m > n$ then
$$||f_n - f_m||_2^2 = \int_{1/2-1/n}^{1/2+1/n} (m(x - 1/2 - 1/m) - n(x - 1/2 - 1/n))^2~dx$$
and the integrand satisfies
$$(m(x - 1/2 - 1/m) - n(x - 1/2 - 1/n))^2 \leq 8.$$
Thus
$$||f_n - f_m||_2^2 \leq \int_{1/2-1/n}^{1/2+1/n} 8~dx = \frac{16}{n}.$$
Therefore
$$||f_n - f_m||_2 \leq \frac{4}{\sqrt n} \to 0$$
as $n \to \infty$. However, it is not too hard to check that if
$$f(x) = \begin{cases}
0, x \leq 1/2\\
1, x > 1/2
\end{cases}$$
then
$$\lim_{n \to \infty} ||f_n - f||_2 = 0;$$
yet $f$ is not continuous, and $||\cdot||_2$ is a norm, so $f_n$ cannot converge to any continuous function.
\end{example}

\begin{definition}
A \dfn{Banach space} is a normed space for which every Cauchy sequence converges.
\end{definition}

\begin{example}
The $p$-norms $||\cdot||_p$ that we defined on $\RR^d$ turn $\RR^d$ into a Banach space.
This is an exercise in the fact that every Cauchy sequence on $\RR$ converges.
\end{example}

The advantage of working in Banach spaces rather than general normed spaces is that it is meaningful to talk about infinite sums in Banach spaces. Indeed, if $(x_n)_n$ is a sequence of elements in a Banach space $X$, we define
\begin{equation}
\label{banach space series}
\sum_{n=1}^\infty x_n = \lim_{N \to \infty} \sum_{n=1}^N x_n
\end{equation}
whenever the limit on the right-hand side of (\ref{banach space series}) makes sense; thus, $y = \sum_n x_n$ if for every $\varepsilon > 0$, there is an $N$ such that
$$\left|\left|y - \sum_{n=1}^N x_n\right|\right| < \varepsilon.$$
In fact, the right-hand side of (\ref{banach space series}) makes sense as long as the partial sums are Cauchy; thus, for every $\varepsilon > 0$, there is an $N$ such that
$$\left|\left|\sum_{n=N}^\infty x_n\right|\right| < \varepsilon.$$
By the triangle inequality, it in fact suffices to show that for every $\varepsilon > 0$ there is an $N$ such that
\begin{equation}
\label{absolute convergence}
\sum_{n=N}^\infty ||x_n|| < \varepsilon
\end{equation}
to show that the $(x_n)_n$ are summable.
\begin{definition}
Let $(x_n)_n$ be a sequence in a Banach space. If for every $\varepsilon > 0$ there is an $N$ such that (\ref{absolute convergence}) holds, we say that $(x_n)_n$ is \dfn{absolutely convergent} or \dfn{absolutely summable}.
\end{definition}

Just as we had a universal way to turn any seminormed space into a normed space, its normalization, we have a universal way to turn any normed space (hence any seminormed space) into a Banach space by adding limits to each of its Cauchy sequences.
\begin{theorem}
\label{completion exists}
For every normed space $V$ there is a Banach space $W$, called the \dfn{completion} of $V$, such that:
\begin{enumerate}
\item There is an injective linear map $\iota: V \to W$ such that for every $v$, $||\iota(v)|| = ||v||$.
\item The image of $\iota$ is dense in $W$.
\item The completion satisfies the \dfn{universal property of the completion}: for any Banach space $X$ and any linear map $T: V \to X$ such that for every $v$, $||Tv|| = ||v||$, then there is a linear map $T': W \to X$ such that the diagram
$$\begin{tikzcd}
V \arrow[rr,"T"] \arrow[dr,"\iota"] && X\\
& W \arrow[ur,"T'"]
\end{tikzcd}$$
commutes.
\end{enumerate}
\end{theorem}
As with the normalization, the completion is unique for category-theoretic reasons, and the reader should omit the proof of this theorem on first reading.
\begin{proof}
To do this, let $V$ be a normed space and let $\Cau (V)$ be the vector space of all Cauchy sequences in $V$.
(We let $x$ denote a Cauchy sequence $(x_n)_n$.)
Then $\Cau (V)$ is a seminormed space, where
$$||x|| = \lim_{n \to \infty} ||x_n||.$$
(To see that the limit exists, note that if $x$ is a Cauchy sequence then $n \mapsto ||x_n||$ is a Cauchy sequence in $\RR$, so it converges.)
Let $W$ be the normalization of $\Cau (V)$ and $\pi: \Cau (V) \to W$ the natural projection.

We claim that $W$ is the completion of $V$.
First, $W$ is a Banach space, because if $x \in \Cau (W)$, then we can choose $\widetilde x \in \Cau (\Cau (V))$ such that for every $n$,
$$\pi(\widetilde x_n) = x_n.$$
Now $\widetilde x_n$ is a Cauchy sequence, say $(\widetilde x_{n,m})_m$. If we replace $\widetilde x_n$ with a subsequence (in $m$) of $\widetilde x_n$, $\pi(\widetilde x_n)$ will not change.
Thus we might as well assume that for any two $m,m'$,
$$||\widetilde x_{n,m} - \widetilde x_{n,m'}|| < \frac{1}{n}.$$
Now let
$$\widetilde y_n = \widetilde x_{n,n}.$$
We want $x_n \to \pi(\widetilde y)$ but it's not obvious that $\widetilde y$ is a Cauchy sequence.

Let $\varepsilon > 0$, so there is an $N > \varepsilon^{-1}$ such that for every $n, n' \geq N$,
$$||x_n - x_{n'}|| < \varepsilon$$
and for any $j$,
\begin{align*}
  ||\widetilde y_n - \widetilde y_{n'}|| &= ||\widetilde x_{n,n} - \widetilde x_{n',n'}||\\
  &\leq ||\widetilde x_{n,n} - \widetilde x_{n,j}|| + ||\widetilde x_{n,j} - \widetilde x_{n',j}|| + ||\widetilde x_{n',j} - \widetilde x_{n',n'}||\\
  &\leq \frac{1}{n} + ||\widetilde x_{n,j} - \widetilde x_{n',j}|| + \frac{1}{n'}\\
  &< 2\varepsilon + ||\widetilde x_{n,j} - \widetilde x_{n',j}||.
\end{align*}
But
$$\lim_{j \to \infty} ||\widetilde x_{n,j} - \widetilde x_{n',j}|| = 0$$
and since $j$ was large enough we can take $||\widetilde x_{n,j} - \widetilde x_{n',j}|| < \varepsilon$. Then
$$||\widetilde y_n - \widetilde y_{n'}|| \lesssim \varepsilon.$$
Therefore $\widetilde y \in \Cau (V)$, and we can define
$$y = \pi(\widetilde y).$$

We similarly choose $N > \varepsilon^{-1}$ such that for every $n, n' \geq N$,
$$||\widetilde y_n - \widetilde y_{n'}|| < \varepsilon.$$
Then
$$||\widetilde x_{n',n} - \widetilde y_n|| \leq ||\widetilde x_{n',n} - \widetilde x_{n',n'}|| + ||\widetilde y_{n'} - \widetilde y_n|| \lesssim \varepsilon.$$
But
$$\lim_{m \to \infty} ||\widetilde x_{n,m} - \widetilde y_m|| = ||x_n - y||$$
so $\lim_n x_n = y$.

We can define
\begin{equation}
\label{inclusion into completion}
\iota(v) \mapsto \pi(v, v, v, \dots).
\end{equation}
Clearly the limit of the Cauchy sequence on the right-hand side of (\ref{inclusion into completion}) is $v$, so $||\iota(v)|| = ||v||$.

To see that $\iota(V)$ is dense in $W$, let $x \in W$ and choose $\widetilde x \in \Cau (V)$ with $\pi(\widetilde x) = x$.
Now $\widetilde x$ is a Cauchy sequence in $V$, so let
$$y_n = \iota(\widetilde x_n);$$
then $y \in \Cau (W)$, and the reader can check that $\lim_n y_n = x$.

To check the universal property, let $T: V \to X$ be a linear map of $V$ into a Banach space $X$ such that $||Tv|| = ||v||$.
Thus $T$ is a bounded linear map (c.f. Definition \ref{bounded linear map}). First define $T'(\iota(v)) = v$ for every $v$, thus $T'$ is defined on the dense subspace $V'$ of $W$.
But then $T'$ is continuous, so it extends uniquely to a linear map by Lemma \ref{linear extension}. We leave it to the reader to check $||T'w|| = ||w||$.
\end{proof}

\section{Linear maps}
Though we will use this material before then, the reader need not familiarize themself with this material until Chapter TODO.
\begin{definition}
\label{bounded linear map}
Let $T: V\to W$ be a linear map between normed spaces. We say that $T$ is a \dfn{bounded linear map} if there is a $C>0$ such that for every $v \in V$,
$$||Tv|| \leq C||v||.$$
The infima of all choices of $C$ is called the \dfn{operator norm} of $T$, denoted $||T||$.
We denote by $B(V \to W)$ the space of bounded linear maps.
\end{definition}

\begin{lemma}
Let $V,W$ be normed spaces.
Then the operator norm is a norm on $B(V \to W)$.
\end{lemma}
We leave the routine proof to the reader.

\begin{lemma}
\label{linear extension}
Let $T: V \to W$ be a bounded linear map between normed spaces, and suppose that $V$ is a dense subspace of a normed space $X$.
Then there is a unique extension of $T$ to a bounded linear map $X \to W$, which has the same operator norm.
\end{lemma}
\begin{proof}
Let $x \in X$, and let $(x_n)_n$ be a sequence in $V$ with $\lim_n x_n = x$.
Define $Tx = \lim_n Tx_n$.
We let $||T||_V$ denote the operator norm of $T$ with domain $V$ and $||T||_X$ with domain $X$.

To see that this is well-defined, suppose that $\lim_n x_n' = x$ as well. Then
$$\lim_{n \to \infty} ||Tx_n - Tx_n'|| \leq \lim_{n \to \infty} ||T||_V \cdot||x_n - x_n'|| = 0$$
since $x_n \to x$ and $x_n' \to x$.
Thus $Tx$ does not depend on the choice of Cauchy sequence which approximates $x$.
Similarly,
$$||Tx|| = \lim_{n \to \infty} ||Tx_n|| \leq \lim_{n \to \infty} ||T||_V \cdot||x_n|| = ||T||_V ||x_n||.$$
Thus $||T||_X \leq ||T||_V$, but $V$ is a subspace of $X$ so clearly $||T||_V \leq ||T||_X$.

To check that $T$ is linear on $X$, note that $T$ is continuous and hence can be commuted with limits. This means that
$$T(x + y) = \lim_{n \to \infty} T(x_n + y_n) = \lim_{n \to \infty} Tx_n + Ty_n = Tx + Ty$$
where $(x_n)_n$ and $(y_n)_n$ are appropriately chosen Cauchy sequences.
The proof that $T(cx) = cTx$ is similar.
\end{proof}

\section{Properties of Banach spaces}
\begin{definition}
Let $B$ be a Banach space and let $X \subseteq B$. We say that $X$ is \dfn{separable} if there is a countable dense subset of $X$.
\end{definition}

If $X$ is separable and $Y \subseteq X$, then $Y$ is separable; in fact, if $C$ is countable and dense in $X$, then $C \cap Y$ is countable and dense in $Y$.

\begin{example}
$\CC^n$ is separable, since $\{(\alpha_1 + i\beta_1, \dots, \alpha_n + i \beta_n): \alpha_i, \beta_i \in \QQ\}$ is countable and dense in $\CC^n$.
In particular any finite-dimensional space is separable. Moreover, most spaces that we consider will turn out to be separable.
\end{example}

\begin{example}
\label{nonseparable space}
Let $X$ be the space of all bounded functions $\CC \to \CC$, where
$$||f - g|| = \sup_{z \in \CC}|f(z) - g(z)|.$$
Then $X$ is not separable. In fact, if $z \in \CC$, let $1_z(z) = 1$ and $1_z(w) = 0$ if $w \neq z$.
Then $Y=\{1_z: z \in \CC\}$ is an uncountable subset of $X$ such that for every $z_1 \neq z_2$, $||1_{z_1} - 1_{z_2}|| =1$.
So $Y$ is discrete and uncountable, and hence cannot be separable.
\end{example}

\section{Convexity}



\chapter{Foundations}
In this appendix we treat the foundations of math: set theory, category thoery, and point-set topology.
We omit the proofs, not because they are uninteresting or unworthy of being learned, but because these topics are not analysis; this is an analysis book, and it is reasonable to use material that is not analysis as a black box.

\section{Axiomatic set theory}
We assume familiarity with naive set theory; this will suffice for everything in this text except for a few examples, which require more sophisticated set-theoretic techniques that we record here.
We refer the reader to CITE:Kunen for more details.

Let us record the first few axioms of set theory.
It will be convenient to assume that \emph{every} mathematical object is a set.
This is no loss of generality, because one can define the natural numbers by declaring that $0 = \emptyset$ and for every natural number $n$, $n = \{0, \dots, n - 1\}$.
The definition of real numbers in terms of Dedekind cuts, where each real number $x$ is by definition the set $\{y \in \QQ: y < x\}$, is similar.
More generally, any mathematical object can be encoded as a set in some appropriate way.

The first three axioms are presumably uncontroversial to anyone who has studied naive set theory.

\begin{axiom}[extensionality]
For all sets $x, y, z$, if $z \in x$ implies $z \in y$, and $z \in y$ implies $z \in x$, then $x = y$.
\end{axiom}
\begin{axiom}[pairing]
For all sets $x, y$, there exists a set $z$, usually denoted $\{x, y\}$, such that for every set $w$, $w \in z$ iff $w = x$ or $w = y$.
\end{axiom}
\begin{axiom}[union]
For all sets $x, y$, there exists a set $z$, usually denoted $x \cup y$, such that for every set $w$, $w \in z$ iff $w \in x$ or $w \in y$.
\end{axiom}

Now to avoid Russell's paradox, and avoid other logic technicalities we want to forbid that a set include itself.
\begin{axiom}[foundation]
For all sets $x$ such that there is a set $w \in x$, there is a set $y \in x$ such that for all sets $z \in y$, $z \notin x$.
\end{axiom}
If $x \in x$, then by pairing, $\{x\}$ is a set, and this contradicts foundation.

A \dfn{first-order formula} with $N$ free variables in the language of set theory is a string consisting only of the symbols $\exists,\forall,\to,\neg,\in,(,)$, and variables $x_1,x_2,\cdots, y_1,\dots,y_N$ that refer to sets, which is meaningful (so the formula $)\forall \implies()$ is not a first-order formula), such that the $x_i$ always appear after a quantifier $\forall$ or $\exists$, and the $y_i$ never do.
Plugging in sets for the $y_i$ gives a statement which is either true or false.
For example, $\forall x_1((x_1 \in y_1) \to (x_1 \in y_2))$ is a formula which asserts that $y_1 \subseteq y_2$.

First-order formulae allow us to assert the existence of subsets.
\begin{axiom}[restricted comprehension schema]
For all sets $x$, first order-formulae $\varphi$ with $N+1$ free variables, and sets $w_1, \dots, w_N$, there is a set $y$ such that $z \in y$ iff $z \in x$ and $\varphi(z, w_1, \dots, w_N)$ is true.
\end{axiom}
Henceforth we adopt the usual notation $\subseteq$, $\subset$, $\{y \in x: \varphi(y)\}$, etc.
We can also now define the empty set $\emptyset$ and various other interesting sets.

Already we have developed enough to study finite sets.
For example, we can define intersection $\cap$ and ordered pairs $(x, y)$ in terms of the notions we introduced in the above axioms.
We can also define functions; a function $f: X \to Y$ is just a set $f$ of ordered pairs $(x, y)$ such that for every $x \in X$ there is exactly one $y \in Y$ such that $(x, y) \in f$ (though we usually write $f(x) = y$ to mean $(x, y) \in f$).
So we can talk about injections and bijections, and ask if two sets have the same cardinality.
\begin{definition}
Let $x, y$ be sets. We say that $x, y$ have the same \dfn{cardinality}, and write $x \cong y$, if there is a bijection $x \to y$.
\end{definition}
\begin{theorem}[Cantor-Bernstein]
Let $x, y$ be sets. Then $x \cong y$ iff there are injections $x \to y$ and $y \to x$.
\end{theorem}
In particular, we can ask if a set is finite, countable, etc.
\begin{definition}
A \dfn{finite set} is a set $x$ such that for every $y \subseteq x$, if $x \cong y$, then $x = y$.
Otherwise, the set $x$ is an \dfn{infinite set}.
\end{definition}
However, it is not obvious (and in fact, may even be false) that there is an infinite set at this stage.
\begin{axiom}[infinity]
There exists a set $x$, usually denoted $\NN$, such that $\emptyset \in x$ and for all sets $y \in x$, $\{y \cup \{y\}\} \in \NN$.
\end{axiom}
From $\NN$ we may construct $\ZZ$, $\QQ$, and other familiar countable objects.
\begin{definition}
A set $x$ is a \dfn{countable set} if there is an injection $x \to \NN$.
Otherwise, the set $x$ is an \dfn{uncountable set}.
\end{definition}
Again we get stuck; it is not obvious (and may be false) that there can be uncountable sets.

The axioms that follow are highly dangerous. They assert the existence of deeply infinitary sets, whose elements cannot be easily described.
This is the essence of the paradoxical examples that we will use axiomatic set theory to prove the existence of.
Famously, Lebesgue rejected the axiom of choice (while implicitly using weak forms of it); modern constructivists, finitists, and intuitionists reject some or all of the following axioms (or even the axiom of infinity).
\begin{axiom}[power set]
For every set $x$, there exists a set $y$, usually denoted $2^x$, such that for all sets $z$, $z \in y$ iff $z \subseteq x$.
\end{axiom}
The axioms that we have developed up to this point define what is known as \dfn{Zermelo set theory}.

There is clearly an injection $x \to 2^x$, given by $y \mapsto \{y\}$.
\begin{theorem}[Cantor's diagonal argument]
For every set $x$, there is no injection $2^x \to x$.
\end{theorem}
In particular, $2^\NN$ is uncountable.
We may now prove the existence of $\RR$, $2^\RR$, the topology of $\RR$, and so on. For example, we have:
\begin{theorem}[Dedekind]
There exists a set $\RR$, whose elements are nonempty proper subsets $x$ of $\QQ$ such that for each $q \in x$, if $r \in \QQ$ and $r < q$ then $r \in x$, and there is an $s \in x$ such that $s > x$.
There exists a ring structure on $\RR$ which turns $\RR$ into an ordered field of characteristic $0$ such that for every set $X \in 2^\RR$, $\sup X$ is well-defined.
Moreover, $\RR$ is unique up to unique isomorphism of ordered fields.
\end{theorem}
We now pause to introduce the notion of \dfn{transfinite induction}, which we will use a few times.
\begin{definition}
A \dfn{transitive set} is a set $x$ such that $x \subset 2^x$.
\end{definition}
Thus every element of a transitive set is also a subset of $x$.
\begin{definition}
\label{ordinal dfn}
An \dfn{ordinal} is a transitive set $x$ such that for every $y \in x$, $y$ is an ordinal.
\end{definition}
This definition may seem circular -- but it is not. $\emptyset$ is an ordinal, usually denoted $0$ when we think of it as an ordinal, and every natural number is an ordinal (why?), but so is $\NN$, which we usually denote $\omega$ when we think of it as an ordinal.
From there we keep going: given an ordinal $\alpha$ we define its \dfn{successor} $\alpha + 1 = \alpha \cup \{\alpha\}$.
Not every ordinal is a successor or $0$; for example $\omega$ was not. Such ordinals are known as \dfn{limits}.
They are limit points in the order topology.
\begin{theorem}[transfinite induction]
\label{transfinite induction}
Fix a limit ordinal $\kappa$. Let $X$ be a set of ordinals such that:
\begin{enumerate}
\item $0 \in X$.
\item For every ordinal $\alpha \in X$, $\alpha + 1 \in X$.
\item If $\delta < \kappa$ is a limit ordinal and for every $\alpha < \delta$, $\alpha \in X$, then $\delta \in X$.
\end{enumerate}
Then $X = \kappa$.
\end{theorem}
The trivial example of transfinite induction is when $\kappa = \omega$; then there are no limit ordinals to consider and the theorem collapses down to induction on $\NN$.
From this we can introduce \dfn{transfinite recursion}.
Suppose that $\kappa$ is a limit ordinal, and we want to define sets $x_\alpha$ for every $\alpha < \kappa$. Then we just have to:
\begin{enumerate}
\item Define $x_0$.
\item Show that if we can define $x_\alpha$, then we can define $x_{\alpha + 1}$.
\item Show that for every limit ordinal $\delta < \kappa$, if we can for every $\alpha < \delta$ define $x_\alpha$, then we can define $x_\delta$.
\end{enumerate}
Then the theorem of transfinite induction will imply that, for every $\alpha < \kappa$, $x_\alpha$ is defined.

The set of all countable ordinals is an uncountable ordinal (in fact, the smallest uncountable ordinal), which we denote $\omega_1$.

If $X$ is a set of ordinals, then $X$ has a least element; this is similar to the fact that every set of natural numbers has a least element.
\begin{definition}
An ordinal $\kappa$ is a \dfn{cardinal} if $\kappa$ is the least element of $\{\alpha: \alpha \cong \kappa\}$.
\end{definition}
The idea is that cardinals should be canonical representatives of the equivalence class of all sets with a given cardinality.

We let $\aleph_0$ be the least infinite cardinal (thus $\aleph_0 = \omega$), and for every cardinal $\aleph_n$, we define $\aleph_{n+1}$ to be the least cardinal greater than $\aleph_n$.
We would like to continue this recursion and let $\aleph_\omega$ be the least cardinal greater than $\aleph_n$ for every $n \in \NN$.
It is not possible to define $\aleph_\omega$ yet, but we can do so with the help of a new axiom schema.

\begin{axiom}[replacement schema]
For every set $X$, every first-order formula with $N+2$ free variables $\varphi$, and all sets $w_1, \dots, w_N$, if for every $x \in X$ there is exactly one set $y$ such that $\varphi(x, y, w_1, \dots, w_N)$ is true, then there is a set $z$ such that $y \in z$ iff there is an $x \in X$ such that $\varphi(x, y, w_1, \dots, w_N)$ is true.
\end{axiom}
In other words, if $F$ is a function which can be explicitly defined by a first-order formula in terms of $N$ parameters $w_1, \dots, w_N$, then the image of $F$ is a set.
It follows from the replacement schema that $\aleph_\alpha$ is defined for every ordinal $\alpha$.

Zermelo set theory along with the replacement schema is known as \dfn{Zermelo-Fraenkel set theory}.

Zermelo-Fraenkel set theory cannot prove that every set is in bijection with a cardinal, or that every vector space has a basis.
To prove that every set is in bijection with a cardinal, Zermelo introduced the so-called axiom of choice.

\begin{axiom}[choice]
\label{axiom of choice}
For every surjection $f: X \to Y$ there is an injection $g: Y \to X$ such that for every $y \in Y$, $f(g(y)) = y$.
\end{axiom}
In other words if $f: X \to Y$ is a surjection then for every $y \in Y$ we may choose $x \in X$ so that $f(x) = y$.
This follows from Zermelo-Fraenkel set theory if we only have to choose finitely many $x$, but in general, $X$ may be uncountable, so that we may have to make uncountably many choices when we define $g$.

The above axioms comprise \dfn{Zermelo-Fraenkel set theory with choice}.
Throughout the text, we assume Zermelo-Fraenkel set theory with choice.

\begin{theorem}[Zermelo's well-ordering theorem]
\label{well-ordering theorem}
For every set $x$ there is a unique cardinal $\kappa$ such that $x \cong \kappa$.
\end{theorem}

\begin{definition}
For every set $x$, the unique cardinal $\kappa$ such that $x \cong \kappa$ is called the \dfn{cardinality} of $x$.
We denote the cardinality of $x$ by $\card x$.
\end{definition}

\begin{proof}[Proof of Zermelo's well-ordering theorem]
Uniqueness is obvious since $\cong$ is an equivalence relation.
So we need a cardinal $\kappa$ and a bijection $f: \kappa \to x$.

Let $\lambda$ be a cardinal. We first build a function $f_\lambda: \lambda \to x$ by transfinite recursion, using the axiom of choice.
Choose $y \in x$ and set $f_\lambda(0) = y$.
Suppose $\alpha < \lambda$ and we have defined $f_\lambda(\beta)$ for $\beta < \alpha$.
Choose $z \in x$ such that for every such $\beta$, $f_\lambda(\beta) \neq z$, if such a $z$ exists; otherwise set $f_\lambda(\beta) = y$.
By transfinite recursion, this defines a function $f_\lambda$. If $f_\lambda$ is a bijection we can set $\kappa = \lambda$ and we're done.

Otherwise suppose $f_\lambda$ is not injective. Then there is an ordinal $\beta < \lambda$ (so in particular, $\card \beta < \lambda$) such that $f_\lambda|\beta$ is injective and $\beta$ is maximal possible (so in particular, $f_\lambda|\beta$ is surjective), by construction of $f_\lambda$.
Let $\kappa = \card \beta$ and choose $g: \beta \to \kappa$.
Then set $f = (f_\lambda|\beta) \circ g^{-1}$.

Finally suppose $f_\lambda$ is not surjective. Let $\delta = \card 2^\lambda$ and consider $f_\delta$ instead.
If the process of passing from $\lambda$ to $\delta$ does not halt, then there are arbitrarily large cardinals $\delta$ which admit injections $\delta \to x$, so the universe of all sets embeds in $x$.
This breaks Russell's paradox.
\end{proof}

Note that while we technically don't need Zermelo's well-ordering theorem to prove the Cantor-Bernstein theorem, it is an immediate consequence.

\begin{definition}
\label{beth dfn}
We define $\beth_0 = \aleph_0$, and for every $\alpha$, $\beth_{\alpha + 1}$ to be the cardinality of $2^{\beth_\alpha}$.
If $\delta$ is a limit ordinal we let $\beth_\delta$ be the cardinality of $\bigcup_{\alpha < \delta} \beth_\alpha$.
\end{definition}

By Cantor's diagonal argument, $\beth_\alpha < \beth_\beta$ whenever $\alpha < \beta$.

\begin{theorem}
\label{cardinal arithmetic trivial}
Let $\lambda \leq \kappa$ be infinite cardinals.
Suppose that $X$ is a set of cardinality $\lambda$, whose elements are sets of cardinality $\kappa$. Then $\bigcup_{x \in X} x$ has cardinality $\kappa$.
Moreover, if $\lambda < \kappa$ and $\kappa = \beth_\alpha$ for some $\alpha$, then the Cartesian product of $\lambda$ many copies of $\kappa$ has cardinality $\kappa$.
\end{theorem}

In particular, if $\lambda$ is countable or $\lambda = \beth_1$, then a union of $\lambda$ many sets of cardinality $\beth_1$ has cardinality $\beth_1$.

\begin{theorem}
\label{cardinality of topology}
Let $\mathcal T$ be the set of all open subsets of $\RR$; then $\mathcal T$ has cardinality $\beth_1$.
\end{theorem}

Another consequence of Zermelo's well-ordering theorem is Zorn's lemma, which is frequently useful.
The point is to allow us to build up ``deeply infinitary" objects (that cannot be completed in $\omega$ many steps!) without explicitly using transfinite recursion.
Of course the proof will be by transfinite recursion, but mathematicians who are not logicians tend to find the transfinite terrifying, and use Zorn's lemma as something of a black box.

\begin{definition}
Let $\PP$ be a partially ordered set. A \dfn{chain} $\mathcal C$ in $\PP$ is a set such that for every $x, y \in \mathcal C$, $x \leq y$ or $y \leq x$.
\end{definition}

\begin{theorem}[Zorn's lemma]
Let $\PP$ be a partially ordered set such that every chain in $\PP$ has an upper bound.
Then $\PP$ has a maximal element.
\end{theorem}
\begin{proof}
Let $\kappa = \card \PP$ and choose a bijection $f: \kappa \to \PP$.
We will define an ordinal $\delta$ and an injection $g: \delta + 1 \to \PP$ as follows.
Let $g(0) = f(0)$. If $g(\alpha)$ has been defined and is not maximal, there is a $\beta < \kappa$ such that $f(\beta) > g(\alpha)$; choose the least such $\beta$, and set $g(\alpha + 1) = f(\beta)$.
If $g(\alpha)$ has been defined for all $\alpha < \gamma$, then let $\mathcal C_\gamma = \{g(\alpha): \alpha < \gamma\}$; then $\mathcal C_\gamma$ is a chain, so it has an upper bound, which we define to be $g(\gamma)$.

If the above process stops at some $\delta$, then $g(\delta)$ is maximal in $\PP$.
Otherwise, there are arbitrarily large ordinals $\delta$ such that there are injections $\delta \to \PP$, hence $\delta \to \kappa$.
In particular we could take $\delta = \card 2^\kappa$ and get an injection $2^\kappa \to \kappa$, a contradiction.
\end{proof}

\section{Universal properties}
This section has nothing to do with measure theory.
It solely exists to justify certain algebraic handwaves in the appendices.
The reader who is interested in category theory should read TODO:Cite Aluffi and Riehl, and most other readers, except those who are completely ignorant of algebra, should ignore this section entirely.

To avoid technicalities we adjoin a new axiom to the Zermelo-Fraenkel set theory with the axiom of choice to obtain a weak form of \dfn{Tarski-Grothendieck set theory}.

\begin{definition}
A transitive set $U$ is a \dfn{universe} if $\NN \in U$, $U$ is closed under pairing and power set, and for every subset $V \subset U$ of strictly less cardinality than $U$, $\bigcup_{x \in V} x \in U$.
\end{definition}
\begin{axiom}[universe]
There exists a universe.
\end{axiom}
Henceforth we fix a universe $U$.
One can show that universes are closed under every relevant operation that mathematicians might care about, so any object that will ever appear in this book is contained in $U$.
For example $\RR \in U$, any measurable subset of $\RR$ is in $U$, and any Banach space we ever consider is in $U$.
\begin{definition}
A \dfn{small set} is an element of $U$.
\end{definition}
So anything that we will ever have reason to care about, except in this section, is small.

\begin{definition}
A \dfn{category} $C$ is a set, whose elements are called \dfn{objects}, along with small sets $\Hom(x, y)$ for all objects $x, y \in C$, whose elements are called \dfn{morphisms} from $x$ to $y$, equipped with \dfn{composition} operations
\begin{align*}
\Hom(x, y) \times \Hom(y, z) &\to \Hom(x, z)\\
(\varphi, \psi) &\mapsto \psi \varphi
\end{align*}
such that:
\begin{enumerate}
\item For every object $x \in C$, $\Hom(x, x)$ contains a morphism $1_x$ which is an \dfn{identity} in the sense that for all $\varphi \in \Hom(x, y)$, $\varphi = \varphi 1_x$ and for every $\psi \in \Hom(y, x)$, $\psi = 1_x \psi$.
\item Composition is \dfn{associative} in the sense that $\psi(\varphi\rho) = (\psi\varphi)\rho$ whenever $\psi\varphi$ and $\varphi\rho$ are defined.
\end{enumerate}
\end{definition}

For example $U$ forms a category, whose objects are small sets, and whose morphisms are defined by letting $\Hom(x, y)$ be the set of all functions $x \to y$.
We dare not define a category whose objects consist of all sets, due to Russell's paradox; but we will abuse terminology and call $U$ the category of sets all the same. We denote it by $\Set$.
Similarly we define $\Grp$, the category of (small) groups where the morphisms are group homomorphisms, and $\Vect(K)$, the category of (small) vector spaces over a (small) field $K$ where the morphisms are linear maps.

It can be convenient to draw diagrams of morphisms, which are graphs where the nodes are objects, an edge from $x$ to $y$ is a morphism in $\Hom(x, y)$, and the diagram \dfn{commutes} if for any two objects $x, y$ in the diagram and any two paths $\varphi_1\cdots\varphi_n$ and $\psi_1\cdots\psi_m$ from $x, y$, $\varphi_1\cdots\varphi_n = \psi_1\cdots\psi_m$.
For example, the diagram
$$\begin{tikzcd}
x_1 \arrow[r,"\varphi_1"] \arrow[d,"\psi_1"] & x_2 \arrow[d,"\psi_2"]\\
y_1 \arrow[r,"\varphi_2"] & y_2
\end{tikzcd}$$
commutes iff $\psi_1\varphi_2 = \psi_1\varphi_2$.

\begin{definition}
Let $C$ be a category, $x,y \in C$ objects, and $\varphi \in \Hom(x, y)$.
We say that $\varphi$ is an \dfn{isomorphism}, and $x,y$ are \dfn{isomorphic}, if there is a $\psi \in \Hom(y, x)$ which is an \dfn{inverse} to $\varphi$ in the sense that $\varphi\psi = 1_y$ and $\psi\varphi = 1_x$.
\end{definition}

\begin{definition}
Let $C$ be a category and $x \in C$ an object.
We say that $x$ is \dfn{initial} in $C$ if for every $y \in C$ there is a unique morphism in $\Hom(x, y)$.
Similarly we say that $x$ is \dfn{final} if for every $y$ there is a unique morphism in $\Hom(y, x)$.
Either way, we say that $x$ is \dfn{terminal}.
\end{definition}

If $x$ and $y$ are terminal, then there is a \emph{unique} isomorphism between $x$ and $y$.
In category theory one cannot distinguish between two objects between which there is a unique isomorphism, so we abuse terminology and say that $x = y$, even if $x,y$ are not equal in the sense of the axiom of extensionality.
Thus a terminal object, if it exists, is unique.
For example, the trivial vector space is the unique terminal object in $\Vect$.

\begin{definition}
Let $P$ be a property held by objects $x$ in a certain category $C$.
We say that $P$ is a \dfn{universal property} if, for every $x$ that holds property $P$, $x$ is terminal in $C$.
\end{definition}

Therefore an object with a universal property is unique.

We can now make rigorous our handwaving about the universal property of the completion.
Let $V$ be a normed space. We define a category $C(V)$, whose objects are norm-preserving linear maps $V \to X$ into a Banach space $X$, and whose morphisms $\varphi$ are commutative diagrams of linear maps
$$\begin{tikzcd}&X \arrow[dd,"\varphi"]\\
V \arrow[ur] \arrow[dr]\\
&Y.\end{tikzcd}$$
The initial object of $V$ is the inclusion map $V \to W$, where $W$ is the completion of $V$.
Therefore the completion is well-defined if it exists (which it does, by Theorem \ref{completion exists}).
Thus we can take the universal property as the definition of the completion, and take Theorem \ref{completion exists} as just an indication that this definition makes sense; we can then forget about such hideous objects as $\Cau(\Cau(V))$.

We paraphrase the above universal property by saying that the completion of $V$ is the initial Banach space which contains a copy of $V$.
A similar argument shows that $\RR$ is uniquely defined as the initial complete metric space which contains a copy of $\QQ$.

\section{Point-set topology}
We briefly sketch ideas from point-set topology that we will need.
We refer the reader to TODO:Cite Munkres or Bradley for reference.

\begin{definition}
A \dfn{topology} $\mathcal T$ in a set $X$ is a set of subsets of $X$ such that:
\begin{enumerate}
\item $\emptyset, X \in \mathcal T$.
\item If $\mathcal U \subseteq \mathcal T$, then the union $\bigcup_{U \in \mathcal U} U$ of all elements of $\mathcal U$ is also in $\mathcal T$.
\item If $U_1, \dots, U_n \mathcal T$ then $U_1 \cap \cdots \cap U_n \in \mathcal T$.
\end{enumerate}
A pair $(X, \mathcal T)$ is called a \dfn{topological space} and usually just denoted $X$.
Elements of $\mathcal T$ are called \dfn{open sets}.
The complement of an open set is called a \dfn{closed set}.
If $x \in X$, a \dfn{neighborhood} of $x$ is an open set containing $x$.
\end{definition}

It follows that the arbitrary union and finite intersection of open sets is open, and the arbitrary intersection and finite union of closed sets.
The point of a topology is that if $K$ is a closed set, $K$ is closed under taking limits, as we will see.

The obvious examples of topologies on a set $X$ are the discrete topology (wherein every set is open) and the indiscrete topology (wherein the only open sets are $\emptyset, X$).

\begin{definition}
A set $\mathcal B$ of subsets of a set $X$ is called a \dfn{basis} if for all $B_1, \dots, B_n \in \mathcal B$, $B_1 \cap \cdots \cap B_n \in \mathcal B$.
\end{definition}

Every basis generates a topology whose elements are arbitrary unions of sets in the basis.

\begin{definition}
A \dfn{semimetric} $d$ on a set $X$ is a function $d: X \times X \to [0, \infty)$ such that:
\begin{enumerate}
\item For all $x$, $d(x, x) = 0$.
\item For all $x,y$, $d(x, y) = d(y, x)$.
\item The \dfn{triangle inequality}: For all $x,y,z$, $d(x, y) \leq d(x, z) + d(z, x)$.
\end{enumerate}
If the only pairs $(x, y)$ such that $d(x, y) = 0$ are those with $x=y$, we say that $d$ is a \dfn{metric} and call $X = (X,d)$ a \dfn{metric space}.
We call sets of the form $B(x, \varepsilon) = \{y \in X: d(x, y) < \varepsilon\}$, where $\varepsilon > 0$ and $x \in X$, \dfn{open balls}.
\end{definition}

The open balls of a semimetric on $X$ form a basis of subsets of $X$, so every semimetric induces a topology, whose open sets are unions of open balls.

\begin{example}
Every seminorm induces a semimetric by $d(x, y) = ||x - y||$.
In particular, $\RR^d$ has a norm (namely its absolute value), so $\RR^d$ is a topological space.
\end{example}

We now describe two different constructions of spaces: product spaces and subspaces.

\begin{definition}
Let $\mathcal X$ be a set of topological spaces. The \dfn{product space} $\prod \mathcal X$ is the space $X$ which has $\prod \mathcal X$ as a set, and has the smallest topology $\mathcal T$ such that for every open set $U \subseteq Y$, $Y \in \mathcal X$, $\pi: X \to Y$ the canonical projection, $\pi^{-1}(U) \in \mathcal T$.
\end{definition}

For example $X \times Y$ is a product space. The open sets are generated by those of the form $U \times V$ where $U \subseteq X$ and $V \subseteq Y$ are open.

\begin{definition}
Let $X$ be a topological space and $Y \subseteq X$ a subset.
We say that $U \subseteq Y$ is \dfn{open} in $Y$ (or \dfn{relatively open}) if there is an open set $V \subseteq X$ such that $U = V \cap Y$.
With respect to that topology, we call $Y$ a \dfn{subspace} of $X$.
\end{definition}

So a subspace is a topological space in its own right.

Topological spaces allow us to define continuity in a high level of abstraction. This agrees with the usual definition of a continuous function $[0, 1] \to \RR$.

\begin{definition}
Let $X,Y$ be topological spaces and $f: X \to Y$. We say that $f$ is \dfn{continuous} if for every $U \subseteq Y$ open, $f^{-1}(Y)$ is open.
\end{definition}

\begin{lemma}
Let $X,Y$ be metric spaces and $f: X \to Y$. Then $f$ is continuous iff for every $\varepsilon > 0$ and $x \in X$, there is a $\delta > 0$ such that for every $x' \in X$, if $d(x, x') < \delta$, then $d(f(x), f(x')) < \varepsilon$.
\end{lemma}

\begin{lemma}
Let $\mathcal X$ be a set of topological spaces. Then $X = \prod \mathcal X$ satisfies the \dfn{universal property of products} in the category of topological spaces: for every $Y \in \mathcal X$, $\pi_Y: X \to Y$ the canonical projection, $\pi_Y$ is continuous, and for every topological space $Z$, if we are given maps $f_Y: Z \to Y$ for every $Y$, there is a unique map $f: Z \to X$ such that $\pi_Y \circ f = f_Y$.
\end{lemma}

We now want to talk about limits. Unfortunately at the level of abstraction we are working at, this proves quite tricky.

\begin{definition}
A \dfn{directed set} is a partially ordered set $\PP$ such that for all $\alpha_1, \dots, \alpha_k \in \PP$, $\sup(\alpha_1, \dots, \alpha_k)$ exists.
\end{definition}

For example $\NN$ is directed, and in fact so is any ordinal. A topology, equipped with the relation $\subseteq$, is also directed.

\begin{definition}
Let $\PP$ be a directed set and $X$ a topological space.
A \dfn{net} in $X$, indexed by $\PP$, is a function $\PP \to X$. If $x$ is a net, we usually write $x_\alpha$ instead of $x(\alpha)$.
A \dfn{sequence} is a net indexed by $\NN$.
\end{definition}

\begin{definition}
Let $\PP$ be a directed set and $X$ a topological space. Let $x$ be a net in $X$ indexed by $\PP$. Let $x^* \in X$.
We say that $x^*$ is the \dfn{limit} of $x$ if for every neighborhood $U$ of $x$, there is an $\alpha \in \PP$ such that for every $\beta \geq \alpha$, $x_\beta \in U$.
In this case we write $\lim_\gamma x_\gamma = x^*$ or $x_\gamma \to x^*$ if it is clear from context that $\gamma$ is a dummy variable.
If $x$ has a limit we say that $X$ \dfn{converges}.
\end{definition}

For example, in a metric space, $x_n \to x$ iff for every $\varepsilon > 0$ there is a $N \in \NN$ such that for all $n > N$, $d(x_n, x) < \varepsilon$.

\begin{lemma}
Let $f: X \to Y$. Then $f$ is continuous iff for every net $x_\gamma \to x^*$ in $X$, $f(x_\gamma) \to f(x^*)$ in $Y$.
\end{lemma}

\begin{definition}
We say that a function $h: S \to \PP$ is \dfn{cofinal} if for every $\alpha \in \PP$ there is a $\beta$ in the image of $h$ such that $\beta \geq \alpha$.
We say that a function $f: \PP \to \PP$ between directed sets is \dfn{monotone} if for every $\alpha \leq \beta$ in $\PP$, $f(\alpha) \leq f(\beta)$.
\end{definition}

\begin{definition}
Let $X$ be a topological space.
Let $x$ be a net indexed by $\PP$ and $x'$ a net indexed by $\PP'$.
We say that $x'$ is a \dfn{subnet} of $x$ if there is a monotone cofinal function $f: \PP \to \PP'$ such that $x'_\alpha = x_{f(\alpha)}$.
A \dfn{subsequence} is a sequence which is a subnet of a subsequence.
\end{definition}

\begin{lemma}
Let $X$ be a topological space.
A set $K \subseteq X$ is closed iff for every net $x$ in $K$ which converges in $X$, $x$ converges in $K$.
Moreover, given a set $A \subseteq X$, the smallest closed set $K$ containing $A$ is the set of all limits of nets in $A$.
\end{lemma}

Subsequences are significantly easier to work with than subnets, as one can eliminate the need to worry about cofinality; $y$ is a subsequence of $x$ iff there is an increasing sequence $n$ of natural numbers such that $x_{n_k} = y_k$ for all $k \in \NN$.

At this point our definition of limit has three problems:
\begin{enumerate}
\item We want to eliminate the need to choose $\PP$ whenever possible, and just work with $\PP = \NN$.
\item We want to be able to guarantee that if a net has a limit $x^*$, then $x^*$ is unique.
\item We want to be able to guarantee that every net has a subnet which converges.
\end{enumerate}

These are the essences of the definitions of a first-countable, Hausdorff, and compact space respectively.

\begin{definition}
Let $X$ be a topological space and $x \in X$.
A \dfn{fundamental system of neighborhoods} at $x$ is a set $\mathcal U$ of open sets $U \ni x$ such that for every open set $V \ni x$ there is a $U \in \mathcal U$ with $U \subseteq V$.
If, for every $x \in X$, $x$ has a countable fundamental system of neighborhoods, then we say that $X$ is a \dfn{first-countable space}.
\end{definition}

\begin{lemma}
Let $X$ be a first-countable space.
A set $K \subseteq X$ is closed iff for every sequence $x$ in $K$ which converges in $X$, $x$ converges in $K$.
Moreover, given a set $A \subseteq X$, the smallest closed set $K$ containing $A$ is the set of all limits of sequences in $A$.
\end{lemma}

\begin{lemma}
Every metric space is first-countable, and a product of countably many first-countable spaces is first-countable.
\end{lemma}

Now we discuss Hausdorffness.

\begin{lemma}
Let $X$ be a topological space. The following are equivalent:
\begin{enumerate}
\item For every two points $x_1, x_2 \in X$, there are open sets $U_1 \ni x_1$, $U_2 \ni x_2$ such that $U_1 \cap U_2$ is empty.
\item The \dfn{diagonal} $\Delta(X) = \{(x, x): x \in X\}$ is a closed subset of $X \times X$.
\item For every sequence $x \in X$, $x$ has at most one limit.
\end{enumerate}
Here $X \times X$ is viewed as a product space.
\end{lemma}

This lemma motivates a definition.

\begin{definition}
A \dfn{Hausdorff space} is a topological space such that for every two points $x_1, x_2 \in X$, either $x_1 = x_2$ or there are open sets $U_1 \ni x_1$, $U_2 \ni x_2$ such that $U_1 \cap U_2$ is empty.
If $X$ is a Hausdorff space, we also say that $X$ satisfies \dfn{Axiom $T^2$}.
\end{definition}

There are other properties called Axiom $T^s$, where if $s' \leq s$ then $T^s$ implies $T^{s'}$. For example:

\begin{definition}
Let $X$ be a topological space. We say that $X$ satisfies:
\begin{enumerate}
\item \dfn{Axiom $T^0$}, if for every $x_1, x_2 \in X$, either $x_1 = x_2$ or there is an open set $U$ such that $x_1 \in U$ and $x_2 \notin U$.
\item \dfn{Axiom $T^1$}, if for every $x \in X$, $\{x\}$ is a closed set.
\item \dfn{Axiom $T^4$}, if for every two closed sets $K_1, K_2 \subseteq X$, either $K_1 = K_2$ or there are open sets $U_1, U_2$ such that $K_1 \subseteq U_1$, $K_2 \subseteq U_2$, and $U_1 \cap U_2$ is empty.
\end{enumerate}
Axioms of the form Axiom $T^s$ are called \dfn{separation axioms}.
\end{definition}

\begin{lemma}
One has a string of implications: Axiom $T^4$ implies Axiom $T^2$, which implies Axiom $T^1$, which implies Axiom $T^0$.
\end{lemma}

\begin{lemma}
Let $X$ be a semimetric space. The following are equivalent:
\begin{enumerate}
\item $X$ is a metric space.
\item $X$ satisfies Axiom $T^4$.
\item $X$ satisfies Axiom $T^0$.
\end{enumerate}
Moreover, if $R$ is the equivalence relation defined by $x_1 R x_2$ iff $d(x_1, x_2) = 0$, then $X/R$ can be given the structure of a metric space.
\end{lemma}

In particular, every metric space is Hausdorff and every semimetric space can be turned into a metric space by identifying points that are indistinguishable by its topology.

Finally let us discuss compactness.

\begin{definition}
An \dfn{open cover} $\mathcal U$ of a topological space $X$ is a set of open sets such that $\bigcup \mathcal U = X$.
A \dfn{subcover} of $\mathcal U$ is an open cover $\subseteq \mathcal U$.
\end{definition}

\begin{definition}
A \dfn{compact space} is a topological space such that every open cover has a finite subcover.
A \dfn{locally compact space} is a topological space $X$ such that for every $x \in X$ there is an open set $U \ni x$ such that the smallest closed set containing $U$ is compact.
\end{definition}

\begin{lemma}
Let $X$ be a topological space. Then $X$ is compact iff for every net $x$ in $X$, there is a subnet $x'$ such that $x'$ is convergent.
Moreover, if $X$ is first-countable, then we can replace the word ``net" by ``sequence" in the previous sentence.
\end{lemma}

\begin{lemma}
Let $X$ be a topological space. Then:
\begin{enumerate}
\item If $X$ is Hausdorff and $K \subseteq X$ is compact, then $K$ is closed.
\item If $f: X \to Y$ is continuous and $X$ is compact, then $f(X)$ is compact.
\end{enumerate}
In particular, if $X$ is compact, $Y$ is Hausdorff, and $f: X \to Y$ is continuous, then $f$ sends closed sets to closed sets.
\end{lemma}

\begin{theorem}[Heine-Borel]
$\RR^d$ is locally compact, and $K \subseteq \RR^d$ is compact iff $K$ is closed and bounded.
\end{theorem}

\begin{lemma}
If $K$ is a compact space, then $K$ is Hausdorff iff $K$ satisfies Axiom $T^4$.
\end{lemma}

We now arrive at the two nontrivial theorems of point-set topology which will be used in the main text as black boxes.
Since they are so important we sketch their proofs, but since these results rely on the above lemmata which we have not proved, these arguments are incomplete; see TODO:Cite for a complete exposition.

\begin{theorem}[Urysohn lemma and Tietze extension]
\label{Urysohn and Tietze}
Let $X$ be a topological space, $A, K \subseteq X$ are disjoint, and $A$ is closed. Suppose that one of the following is true.
\begin{enumerate}
\item $X$ satisfies Axiom $T^4$ and $K$ is closed.
\item $X$ is a locally compact Hausdorff space and $A$ is compact.
\end{enumerate}
Then:
\begin{enumerate}
\item There is a continuous function $f: X \to [0, 1]$ such that $f|A = 0$ and $f|K = 1$.
\item For every interval $L \subseteq \RR$ and every continuous function $g: K \to L$, there is a continuous function $G: X \to L$ such that $G|K = g$.
\end{enumerate}
\end{theorem}
\begin{proof}
We prove this assuming Axiom $T^4$. The proof assuming that $X$ is a locally compact Hausdorff space follows from the case of Axiom $T^4$ and the previous lemma after a little work, which we omit.

We now prove the existence of $f$.
Let $\overline U$ denote the smallest closed set containing an open set $U$.
Set $U(1/2)$ to be an open set containing $K$ which is disjoint from a neighborhood of $A$, which exists by Axiom $T^4$.
Then $U(1/2)^c$ is closed and so by Axiom $T^4$ we can find $U(1/4)$ open such that $\overline{U(1/4)} \subseteq U(1/2)$.
Similarly we can find $U(3/4)$ open such that $\overline{V(1/2)}$ is contained in the interior of $U(3/4)$.
Repeating this process we define $U(p/2^n)$ for every $0 < p < 2^n$, $n \in \NN$, such that $\overline{U(s)} \subseteq U(r)$.
Now set
$$f(x) = \inf_{x \in U(r)} r$$
if such an $r$ exists, otherwise $f(x) = 1$.
Since $\{p/2^n: 0 < p < 2^n, n \in \NN\}$ is dense in $[0, 1]$, one can check that $f$ is continuous, so $f$ is as desired.

We may assume that $L = [0, 1]$; we omit the details.
We may then set $G|A = 0$, and use the function $f$ to interpolate between $A,K$. We omit the details.
\end{proof}

Note carefully that the above result does not imply that every locally compact Hausdorff space satisfies Axiom $T^4$ -- in fact this is false.

\begin{theorem}[Tychonoff]
Let $\mathcal X$ be a nonempty set of nonempty compact spaces. Let $X = \prod \mathcal X$. Then $X$ is compact and nonempty.
\end{theorem}
\begin{proof}
By Zermelo's well-ordering theorem we may write $\mathcal X = (X_\alpha)_{\alpha < \kappa}$ where $\kappa$ is a cardinal and the $\alpha$ are ordinals.
We proceed by transfinite induction, since $\kappa$ can be viewed as an ordinal.
The base case is $\kappa = 1$, in which case $X = X_0$ is obviously compact.

The inductive case is that $\kappa = \beta + 1$, where $Y = \prod_{\alpha < \beta} X_\alpha$ is compact and $X_\beta$ is compact.
So we must show that $X = Y \times X_\beta$ is compact.
Let $x = (y, z)$ be a net in $X$, where $y$ is a net in $Y$ and $z$ is a net in $X_\beta$.
By compactness there is a subnet $x' = (y', z')$ such that $y'$ is a convergent net in $Y$.
Then by compactness again there is a subnet $x'' = (y'', z'')$ of $x'$ such that $z''$ is a convergent net in $X_\beta$.
But $y'$ is convergent in $Y$ and $y''$ is a subnet of $y'$ so $y''$ is convergent in $Y$.
Therefore $x''$ is convergent in $X$.

The interesting case is the limit case, thus if $\delta < \kappa$ then $Y_\delta = \prod_{\alpha < \delta}$ is compact, and $\kappa$ is not the successor of any ordinal.
In that case $X = \prod_{\alpha < \kappa} X_\alpha$, and if $x$ is a net in $X$ then we can let $y^\delta$ be the projection of $x$ onto $Y_\delta$.
So we can find subnets $z^\delta$ of $y^\delta$ which converge.

Let $\PP$ be the domain of $x$. We may assume that $\PP = \gamma$ for some cardinal $\gamma$, by the lemma:
\begin{lemma}
Let $Q$ be a partially ordered set. Then there is a cardinal $\gamma$ and an injection $f: Q \to \gamma$ such that if $x \leq y$ then $f(x) \leq f(y)$.
\end{lemma}
This is a straightforward consequence of Zorn's lemma, once we use Zermelo's well-ordering theorem to find $\gamma > \card Q$ large enough.
We omit the details.

By replacing $\kappa$ with a larger cardinal $\lambda$, and setting $X_\beta$ to be a point for all $\kappa \leq \beta < \lambda$, we may assume that $\gamma \leq \kappa$.
For every $\alpha$ let $x_\alpha' = z^\alpha_\alpha$.
Then $x'$ converges since $z^\alpha$ does for every $\alpha$.
So $x'$ has a limit. Therefore $X$ is compact.
\end{proof}

Note that the above use of the axiom of choice (as Zermelo's well-ordering theorem and Zorn's lemma) cannot be avoided. There is a theorem of Kelley which says that if we are in Zermelo-Fraenkel set theory possibly without the axiom of choice, but Tychonoff's theorem holds, then so does the axiom of choice.


\newpage
\printindex
\printbibliography

\end{document}
